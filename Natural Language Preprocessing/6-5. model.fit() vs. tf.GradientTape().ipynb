{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzMhEELbrJ8k"
   },
   "source": [
    "# model.fit() vs. tf.GradientTape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oenX4IgQ0BzE"
   },
   "source": [
    "케라스의 model.fit()과 Gradient Tape()를 사용한 구현의 차이를 이해해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tbBWEy2rOw1"
   },
   "source": [
    "## 1. model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "u9EDB3G2rXvk",
    "outputId": "7e666de0-4af8-4b20-9873-895e2611fae3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n# 신경망 모델 만들기\\nmodel = tf.keras.models.Sequential()\\n# 완전 연결층을 추가\\nmodel.add(tf.keras.layers.Dense(1))\\n# 옵티마이저와 손실 함수를 지정합니다.\\nmodel.compile(optimizer = 'sgd', loss = 'mse')\\n# 훈련 데이터를 사용하여 에포크 횟수만큼 훈련\\nmodel.fit(x_train, y_train, epochs = 10)\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 신경망 모델 만들기\n",
    "model = tf.keras.models.Sequential()\n",
    "# 완전 연결층을 추가\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "# 옵티마이저와 손실 함수를 지정합니다.\n",
    "model.compile(optimizer = 'sgd', loss = 'mse')\n",
    "# 훈련 데이터를 사용하여 에포크 횟수만큼 훈련\n",
    "model.fit(x_train, y_train, epochs = 10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3K5LBZKqrpCJ"
   },
   "source": [
    "위 코드를 조금 복잡하게 작성하면 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AbxmKiXrd0F"
   },
   "source": [
    "## 2. tf.GradientTape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__5VDeenvXIN"
   },
   "source": [
    "tape_gradient() 메서드는 자동 미분 기능을 수행합니다.  \n",
    "자동 미분에 대해서 실습을 통해 이해해봅시다. 임의로 2w^2+5라는 식을 세워보고, w에 대해 미분해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LI4sHiGufUe"
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(2.)\n",
    "\n",
    "def f(w):\n",
    "  y = w**2\n",
    "  z = 2*y + 5\n",
    "  return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVYs_MgsvKbv"
   },
   "source": [
    "이제 gradients를 출력하면 w가 속한 수식을 w로 미분한 값이 저장된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "QBXlVmHLusJ2",
    "outputId": "193828c5-36ce-43c9-fa96-15a5784a6d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "  z = f(w)\n",
    "\n",
    "gradients = tape.gradient(z, [w])\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "NiLOCKiQrgCo",
    "outputId": "c91820ba-a402-474e-b2fa-dadfeb501357"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'\\n# 훈련할 가중치 변수를 선언\\nw = tf.Variable(tf.zeros(shape=(1)))\\nb = tf.Variable(tf.zeros(shape=(1)))\\n\\n# 경사 하강법 옵티마이저 설정\\noptimizer = tf.optimizer.SGD(lr = 0.01)\\n# 에포크만큼 훈련\\nnum_epochs = 10\\nfor step in range(num_epochs):\\n   \\n    # 예측을 해서 손실을 구하는 과정입니다. (자동 미분을 위해 연산 과정을 기록합니다.)\\n    # tape_gradient() 메서드를 사용하면 그래디언트를 자동으로 계산할 수 있도록 합니다.\\n    with tf.GradientTape() as tape:\\n        z_net = w * x_train + b # 정방향 계산\\n        z_net = tf.reshape(z_net, [-1])\\n        sqr_errors = tf.square(y_train - z_net)\\n        mean_cost = tf.reduce_mean(sqr_errors) # 손실을 계산\\n\\n    # 경사하강법으로 파라미터를 업데이트하는 과정입니다.\\n    # 1. 가중치에 대한 그래디언트 계산\\n    grads = tape.gradient(mean_cost, [w, b])\\n\\n    # 2. 가중치를 업데이트\\n    # apply_gradients() 메서드에는 그래디언트와 가중치를 튜플로 묶은 리스트를 전달해야 합니다.\\n    # 보통 zip()을 주로 사용합니다.\\n    optimizer.apply_gradient(zip(grads, [w, b]))\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 훈련할 가중치 변수를 선언\n",
    "w = tf.Variable(tf.zeros(shape=(1)))\n",
    "b = tf.Variable(tf.zeros(shape=(1)))\n",
    "\n",
    "# 경사 하강법 옵티마이저 설정\n",
    "optimizer = tf.optimizer.SGD(lr = 0.01)\n",
    "# 에포크만큼 훈련\n",
    "num_epochs = 10\n",
    "for step in range(num_epochs):\n",
    "   \n",
    "    # 예측을 해서 손실을 구하는 과정입니다. (자동 미분을 위해 연산 과정을 기록합니다.)\n",
    "    # tape_gradient() 메서드를 사용하면 그래디언트를 자동으로 계산할 수 있도록 합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        z_net = w * x_train + b # 정방향 계산\n",
    "        z_net = tf.reshape(z_net, [-1])\n",
    "        sqr_errors = tf.square(y_train - z_net)\n",
    "        mean_cost = tf.reduce_mean(sqr_errors) # 손실을 계산\n",
    "\n",
    "    # 경사하강법으로 파라미터를 업데이트하는 과정입니다.\n",
    "    # 1. 가중치에 대한 그래디언트 계산\n",
    "    grads = tape.gradient(mean_cost, [w, b])\n",
    "\n",
    "    # 2. 가중치를 업데이트\n",
    "    # apply_gradients() 메서드에는 그래디언트와 가중치를 튜플로 묶은 리스트를 전달해야 합니다.\n",
    "    # 보통 zip()을 주로 사용합니다.\n",
    "    optimizer.apply_gradient(zip(grads, [w, b]))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Learning Spoons 6강 (seq2seq).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
