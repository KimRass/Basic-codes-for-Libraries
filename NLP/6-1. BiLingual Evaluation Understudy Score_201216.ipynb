{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RBMT : 언어학자 -> SMT : 언어학자를 해고할수록 성능 증가(n-gram)\n",
    "- seq2seq는 사실 문제가 있음 -> attention 필수(기억력의 문제 보정)\n",
    "- 단어 시퀀스에 확률을 할당하기 위한 학습 방법이 이전 단어로부터 다음 단어을 예측하는 것.\n",
    "- seq2seq로 만든 챗봇은 open domain\n",
    "- 마지막 단어의 hidden state = context\n",
    "- beam search : 성능에 영향 큼\n",
    "- 숙제 : 서브클래싱 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJrYyJOqxE5b"
   },
   "source": [
    "## 1. BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXwVevuU2A1t"
   },
   "source": [
    "## Sentence BLEU score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkmVYcvN15Xt"
   },
   "source": [
    "파이썬 자연어 처리 패키지 NLTK는 기계가 생성한 텍스트 데이터에 대해서 성능을 평가하는 BLEU score를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import wget\n",
    "import urllib\n",
    "import sentencepiece as sp\n",
    "import csv\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "DwlomX-d1TSa",
    "outputId": "e733e272-62e5-4542-8778-3e20acdd5b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "ref = [[\"this\", \"is\", \"a\", \"test\"], [\"this\", \"is\" \"test\"]]\n",
    "cand = [\"this\", \"is\", \"a\", \"test\"]\n",
    "score = nltk.translate.bleu_score.sentence_bleu(ref, cand)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVK3sPmU2EZt"
   },
   "source": [
    "## Corpus BLEU score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx0V1kVP20hi"
   },
   "source": [
    "NLTK는 절이나 문장과 같은 다수의 문장의 묶음에 대해서 BLEU를 측정하는 nltk.translate.bleu_score.corpus_bleu()를 제공합니다. 여기서 refs는 \"토큰들의 리스트의 리스트의 리스트\" 삼중 리스트여야 합니다. 또한 cand는 \"토큰들의 리스트의 리스트\"이어야 합니다. 설명만으로는 조금 헷갈리므로 예제를 통해 이해해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "QpDcrpU-26Lu",
    "outputId": "f7fc1f05-e620-4c07-ddec-a647d45b1b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# two refs for one document\n",
    "refs = [[[\"this\", \"is\", \"a\", \"test\"], [\"this\", \"is\" \"test\"]]]\n",
    "cands = [[\"this\", \"is\", \"a\", \"test\"]]\n",
    "score = nltk.translate.bleu_score.corpus_bleu(refs, cands)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P21LWP303yn5"
   },
   "source": [
    "## Cumulative and Individual BLEU score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3xs_bcp34V9"
   },
   "source": [
    "NTLK의 BLEU는 다른 n-gram들에 대해서 가중치를 달리하여 계산할 수 있도록 해줍니다.  \n",
    "예를 들어 unigram에만 가중을 100% 주고, 다른 2, 3, 4-gram에 대해서 가중을 주고 싶지않다면 다음과 같이 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "laqnq_Ta3xys",
    "outputId": "710985a5-23d2-4984-b9fd-a110c3762733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# 1-gram individual BLEU\n",
    "ref = [[\"this\", \"is\", \"small\", \"test\"]]\n",
    "cand = [\"this\", \"is\", \"a\", \"test\"]\n",
    "score = nltk.translate.bleu_score.sentence_bleu(ref, cand, weights=(1, 0, 0, 0))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyeevWR-5Co1"
   },
   "source": [
    "위 예제를 각각의 n-gram에 대해서 수행해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQnnhCfiiaZS"
   },
   "source": [
    "각 개별적인 n-gram 스코어로부터 각각에게 가중을 주어 가중 기하 평균을 구합니다.  \n",
    "이를 BLEU-4라고 부릅니다. 이는 nltk.translate.bleu_score.sentence_bleu나 nltk.translate.bleu_score.corpus_bleu의 기본값입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU-tIuTauHBE"
   },
   "source": [
    "BLEU-1, BLEU-2, BLEU-3, BLEU-4를 각각 구하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "nJkNdjXA6AVO",
    "outputId": "b7e4fbc8-3689-47f9-a33d-bf123939efcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative 1-gram: 0.750000\n",
      "Cumulative 2-gram: 0.500000\n",
      "Cumulative 3-gram: 0.632878\n",
      "Cumulative 4-gram: 0.707107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# cumulative BLEU scores\n",
    "ref = [[\"this\", \"is\", \"small\", \"test\"]]\n",
    "cand = [\"this\", \"is\", \"a\", \"test\"]\n",
    "print(\"Cumulative 1-gram: %f\" % nltk.translate.bleu_score.sentence_bleu(ref, cand, weights=(1, 0, 0, 0)))\n",
    "print(\"Cumulative 2-gram: %f\" % nltk.translate.bleu_score.sentence_bleu(ref, cand, weights=(0.5, 0.5, 0, 0)))\n",
    "print(\"Cumulative 3-gram: %f\" % nltk.translate.bleu_score.sentence_bleu(ref, cand, weights=(0.33, 0.33, 0.33, 0)))\n",
    "print(\"Cumulative 4-gram: %f\" % nltk.translate.bleu_score.sentence_bleu(ref, cand, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7BhqvQ6xLTi"
   },
   "source": [
    "# BLEU 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KegHD8FBxTLi"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoNmktwjxieM"
   },
   "source": [
    "## Count : 단순 카운트 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yi7AfUmRxYgZ"
   },
   "outputs": [],
   "source": [
    "# 단순 카운트 함수\n",
    "def simple_count(tokens, n): # 토큰화 된 cand 문장, n-gram에서의 n 이 두 가지를 인자로 받음.\n",
    "    return Counter(ngrams(tokens, n)) #문장에서 n-gram을 카운트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N87icmStxlB7"
   },
   "source": [
    "단순 카운트 구현 함수 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "KQ0XFwMtxfn4",
    "outputId": "074077bf-7c82-48c0-de5c-aec045a8f476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('the',): 3, ('It',): 1, ('is',): 1, ('a',): 1, ('guide',): 1, ('to',): 1, ('action',): 1, ('which',): 1, ('ensures',): 1, ('that',): 1, ('military',): 1, ('always',): 1, ('obeys',): 1, ('commands',): 1, ('of',): 1, ('party.',): 1})\n"
     ]
    }
   ],
   "source": [
    "cand = \"It is a guide to action which ensures that the military always obeys the commands of the party.\"\n",
    "tokens = cand.split() #단어 토큰화\n",
    "result = simple_count(tokens, 1) #토큰화 된 문장, 유니그램의 개수를 구하고자 한다면 n=1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "BDLpSevYxv2R",
    "outputId": "73335042-8ea6-4968-adbb-702caef95f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('the',): 7})\n"
     ]
    }
   ],
   "source": [
    "cand = \"the the the the the the the\"\n",
    "tokens = cand.split() #단어 토큰화\n",
    "result = simple_count(tokens, 1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sICROdQx5L3"
   },
   "source": [
    "## Count_clip 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-P4OUAhx6uN"
   },
   "outputs": [],
   "source": [
    "def count_clip(cand, ref_list, n):\n",
    "    cnt_ca = simple_count(cand, n)\n",
    "    # Ca 문장에서 n-gram 카운트\n",
    "    temp = dict()\n",
    "\n",
    "    for ref in ref_list: # 다수의 Ref 문장에 대해서 이하 반복\n",
    "        cnt_ref = simple_count(ref, n)\n",
    "        # Ref 문장에서 n-gram 카운트\n",
    "\n",
    "        for n_gram in cnt_ref: # 모든 Ref에 대해서 비교하여 특정 n-gram이 하나의 Ref에 가장 많이 등장한 횟수를 저장\n",
    "            if n_gram in temp:\n",
    "                temp[n_gram] = max(cnt_ref[n_gram], temp[n_gram]) # max_ref_count\n",
    "            else:\n",
    "                temp[n_gram] = cnt_ref[n_gram]\n",
    "\n",
    "    return {\n",
    "        n_gram: min(cnt_ca.get(n_gram, 0), temp.get(n_gram, 0)) for n_gram in cnt_ca\n",
    "        # count_clip=min(count, max_ref_count)\n",
    "        # 위의 get은 찾고자 하는 n-gram이 없으면 0을 반환한다.\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ESVPluYkApk"
   },
   "source": [
    "count_clip 함수는 cand 문장과 ref 문장들, 그리고 카운트 단위가 되는 n-gram에서의 n의 값 이 세 가지를 인자로 입력받아서 countclip을 수행합니다. 여기서는 유니그램 정밀도를 구현하고 있으므로 역시나 n=1로 하여 함수를 실행하면 됩니다.  \n",
    "\n",
    "또한 count_clip 함수 내부에는 기존에 구현했던 simple_count 함수가 사용된 것을 확인할 수 있습니다. Countclip을 구하기 위해서는 Max_Ref_Count값과 비교하기 위해 Count값이 필요하기 때문입니다. Example 2를 통해 함수가 정상 작동되는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mNK2gOXTkD2H",
    "outputId": "b9202545-f96c-4209-fb67-db37fee3167b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('the',): 2}\n"
     ]
    }
   ],
   "source": [
    "cand = \"the the the the the the the\"\n",
    "refs = [\n",
    "    \"the cat is on the mat\",\n",
    "    \"there is a cat on the mat\"\n",
    "]\n",
    "result = count_clip(cand.split(),list(map(lambda ref: ref.split(), refs)),1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDbJMDBGkLM0"
   },
   "source": [
    "동일한 예제 문장에 대해서 위의 simple_count 함수는 the가 7개로 카운트되었던 것과는 달리 이번에는 2개로 카운트되었습니다. 이제 위의 두 함수를 사용하여 예제 문장에 대해서 보정된 정밀도를 연산하는 함수를 modified_precision란 이름의 함수로 구현해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bflMCJdYkkWq"
   },
   "source": [
    "## 보정된 유니그램 정밀도 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEPYNm3HkOvi"
   },
   "outputs": [],
   "source": [
    "def modified_precision(cand, ref_list, n):\n",
    "    clip = count_clip(cand, ref_list, n) \n",
    "    total_clip = sum(clip.values()) # 분자\n",
    "\n",
    "    ct = simple_count(cand, n)\n",
    "    total_ct = sum(ct.values()) #분모\n",
    "\n",
    "    if total_ct==0: # n-gram의 n이 커졌을 때 분모가 0이 되는 것을 방지\n",
    "      total_ct=1\n",
    "\n",
    "    return (total_clip / total_ct) # 보정된 정밀도\n",
    "    # count_clip의 합을 분자로 하고 단순 count의 합을 분모로 하면 보정된 정밀도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "8E0E1N4DkSxg",
    "outputId": "2e92ffd1-f01c-44b4-81fb-2223c10fc9e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "result = modified_precision(cand.split(),list(map(lambda ref: ref.split(), refs)),1) # 유니그램이므로 n = 1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAaanPDnkPtS"
   },
   "source": [
    "소수 값이 나오는데 이는 2/7의 값을 의미합니다. \n",
    "\n",
    "이제부터 설명에서 언급하는 \"정밀도\"는 기본적으로 보정된 정밀도(Modified Precision)라고 가정합니다. 정밀도를 보정하므로서 Ca에서 발생하는 단어 중복에 대한 문제점은 해결되었습니다. 하지만 유니그램 정밀도가 가지는 본질적인 문제점있기에 이제는 유니그램을 넘어 바이그램, 트라이그램 등과 같이 n-gram으로 확장해야 합니다.  \n",
    "\n",
    "앞서 구현한 함수 simple_count, count_clip, modified_precision은 모두 n-gram의 n을 함수의 인자로 받으므로, n을 1대신 다른 값을 넣어서 실습해보면 바이그램, 트라이그램 등에 대해서도 보정된 정밀도를 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgsirDfSkpEF"
   },
   "source": [
    "## 짧은 문장 길이에 대한 패널티(Brevity Penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ9K0Zqzk_xU"
   },
   "source": [
    "Ref가 1개라면 Ca와 Ref의 두 문장의 길이만을 가지고 계산하면 되겠지만 여기서는 Ref가 여러 개일 때를 가정하고 있으므로 r은 \"모든 Ref들 중에서 Ca와 가장 길이 차이가 작은 Ref의 길이\"로 합니다. r을 구하는 코드는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQUUVtYXkhET"
   },
   "outputs": [],
   "source": [
    "def closest_ref_length(cand, ref_list): # Ca 길이와 가장 근접한 Ref의 길이를 리턴하는 함수\n",
    "    ca_len = len(cand) # ca 길이\n",
    "    ref_lens = (len(ref) for ref in ref_list) # Ref들의 길이\n",
    "    closest_ref_len = min(ref_lens, key=lambda ref_len: (abs(ref_len - ca_len), ref_len))\n",
    "    # 길이 차이를 최소화하는 Ref를 찾아서 Ref의 길이를 리턴\n",
    "    return closest_ref_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z3PfH-2lDpS"
   },
   "source": [
    "만약 Ca와 길이가 정확히 동일한 Ref가 있다면 길이 차이가 0인 최고 수준의 매치(best match length)입니다. 또한 만약 서로 다른 길이의 Ref이지만 Ca와 길이 차이가 동일한 경우에는 더 작은 길이의 Ref를 택합니다. 예를 들어 Ca가 길이가 10인데, Ref 1, 2가 각각 9와 11이라면 길이 차이는 동일하게 1밖에 나지 않지만 9를 택합니다. closest_ref_length 함수를 통해 r을 구했다면, 이제 BP를 구하는 함수 brevity_penalty를 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQhnL1IFlFhj"
   },
   "outputs": [],
   "source": [
    "def brevity_penalty(cand, ref_list):\n",
    "    ca_len = len(cand)\n",
    "    ref_len = closest_ref_length(cand, ref_list)\n",
    "\n",
    "    if ca_len > ref_len:\n",
    "        return 1\n",
    "    elif ca_len == 0 :\n",
    "    # cand가 비어있다면 BP = 0 → BLEU = 0.0\n",
    "        return 0\n",
    "    else:\n",
    "        return np.exp(1 - ref_len/ca_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-3GR1lhlNLN"
   },
   "source": [
    "## BLEU 함수 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57DM-GuqlILF"
   },
   "source": [
    "이제 최종적으로 BLEU 점수를 계산하는 함수 bleu_score를 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9veUzn1lGP6"
   },
   "outputs": [],
   "source": [
    "def bleu_score(cand, ref_list, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    bp = brevity_penalty(cand, ref_list) # 브레버티 패널티, BP\n",
    "\n",
    "    p_n = [modified_precision(cand, ref_list, n=n) for n, _ in enumerate(weights,start=1)] \n",
    "    #p1, p2, p3, ..., pn\n",
    "    score = np.sum([w_i * np.log(p_i) if p_i != 0 else 0 for w_i, p_i in zip(weights, p_n)])\n",
    "    return bp * np.exp(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbUorUGolQ4x"
   },
   "source": [
    "위 함수가 동작하기 위해서는 앞서 구현한 simple_count, count_clip, modified_precision, brevity_penalty 4개의 함수 또한 모두 구현되어져 있어야 합니다. 지금까지 구현한 BLEU 코드로 계산된 점수와 NLTK 패키지에 이미 구현되어져 있는 BLEU 코드로 계산된 점수를 비교해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3LGHmUPlUWz"
   },
   "source": [
    "## NLTK의 BLEU Vs. 구현한 BLEU 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "h0uOo_H-lXbz",
    "outputId": "6ad2db98-ac10-4462-b3b0-c2a217fc06ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5045666840058485\n",
      "0.5045666840058485\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "\n",
    "cand = \"It is a guide to action which ensures that the military always obeys the commands of the party\"\n",
    "refs = [\n",
    "    \"It is a guide to action that ensures that the military will forever heed Party commands\",\n",
    "    \"It is the guiding principle which guarantees the military forces always being under the command of the Party\",\n",
    "    \"It is the practical guide for the army always to heed the directions of the party\"\n",
    "]\n",
    "\n",
    "# 이번 챕터에서 구현한 코드로 계산한 BLEU 점수\n",
    "print(bleu_score(cand.split(),list(map(lambda ref: ref.split(), refs))))\n",
    "# NLTK 패키지 구현되어져 있는 코드로 계산한 BLEU 점수\n",
    "print(bleu.nltk.translate.bleu_score.sentence_bleu(list(map(lambda ref: ref.split(), refs)),cand.split()))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Learning Spoons 6강 (seq2seq).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
