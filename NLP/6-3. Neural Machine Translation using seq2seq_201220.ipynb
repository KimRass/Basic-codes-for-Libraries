{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation using seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import wget\n",
    "import urllib\n",
    "import sentencepiece as sp\n",
    "import csv\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02bcxHxJ1QIv"
   },
   "source": [
    "## 1. Character-Level Neural Machine Translation using Functional API using fra-eng dataset\n",
    "- 시퀀스-투-시퀀스(seq-to-seq)는 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 다양한 분야에서 사용되는 모델입니다. 예를 들어 챗봇(Chatbot)과 기계 번역(Machine Translation)이 그러한 대표적인 예인데, 입력 시퀀스와 출력 시퀀스를 각각 질문과 대답으로 구성하면 챗봇으로 만들 수 있고, 입력 시퀀스와 출력 시퀀스를 각각 입력 문장과 번역 문장으로 만들면 번역기로 만들 수 있습니다. 그 외에도 내용 요약(Text Summarization), STT(Speech to Text) 등에서 쓰일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url =\"http://www.manythings.org/anki/fra-eng.zip\"\n",
    "# file = \"fra-eng.zip\"\n",
    "# cur_dir = os.getcwd()\n",
    "# file_dir = os.path.join(cur_dir, file)\n",
    "\n",
    "# shutil.copyfileobj(urllib3.PoolManager().request(\"GET\", url, preload_content=False), open(file_dir, \"wb\"))\n",
    "\n",
    "# zipfile.ZipFile(file_dir, \"r\").extractall(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "seyA5LGZv_uF",
    "outputId": "10397183-5f94-4cd0-c0e7-da785202dc56"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"fra.txt\", names=[\"src\", \"tar\", \"CC\"], sep=\"\\t\")\n",
    "data = data[[\"src\", \"tar\"]]\n",
    "data = data.sample(60000, random_state=777) # 6만개만 저장\n",
    "data = data.reset_index(drop=True)\n",
    "data[\"src\"] = data[\"src\"].str.lower()\n",
    "data[\"tar\"] = data[\"tar\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![seq2seq](https://wikidocs.net/images/page/24996/%EC%9D%B8%EC%BD%94%EB%8D%94%EB%94%94%EC%BD%94%EB%8D%94%EB%AA%A8%EB%8D%B8.PNG)\n",
    "- seq2seq는 크게 두 개로 구성된 아키텍처로 구성되는데, 바로 인코더와 디코더입니다. 인코더는 입력 문장의 모든 단어들을 순차적으로 입력받은 뒤에 마지막에 이 모든 단어 정보들을 압축해서 하나의 벡터로 만드는데, 이를 컨텍스트 벡터(context vector)라고 합니다. 입력 문장의 정보가 하나의 컨텍스트 벡터로 모두 압축되면 인코더는 컨텍스트 벡터를 디코더로 전송합니다. 디코더는 컨텍스트 벡터를 받아서 번역된 단어를 한 개씩 순차적으로 출력합니다.\n",
    "- 디코더는 초기 입력으로 문장의 시작을 의미하는 심볼 `<sos>`가 들어갑니다. 디코더는 `<sos>`가 입력되면, 다음에 등장할 확률이 높은 단어를 예측합니다. 첫번째 시점(time step)의 디코더 RNN 셀은 다음에 등장할 단어로 je를 예측하였습니다. 첫번째 시점의 디코더 RNN 셀은 예측된 단어 je를 다음 시점의 RNN 셀의 입력으로 입력합니다. 그리고 두번째 시점의 디코더 RNN 셀은 입력된 단어 je로부터 다시 다음에 올 단어인 suis를 예측하고, 또 다시 이것을 다음 시점의 RNN 셀의 입력으로 보냅니다. 디코더는 이런 식으로 기본적으로 다음에 올 단어를 예측하고, 그 예측한 단어를 다음 시점의 RNN 셀의 입력으로 넣는 행위를 반복합니다. 이 행위는 문장의 끝을 의미하는 심볼인 `<eos>`가 다음 단어로 예측될 때까지 반복됩니다. 지금 설명하는 것은 테스트 과정 동안의 이야기입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_src = set([char for sent in data[\"src\"] for char in sent])\n",
    "chars_tar = set([char for sent in data[\"tar\"] for char in sent])\n",
    "\n",
    "char2idx_src = {}\n",
    "# char2idx_src[\"UNK\"] = 1\n",
    "char2idx_src.update({char:idx+1 for idx, char in enumerate(chars_src)})\n",
    "idx2char_src = {value:key for key, value in char2idx_src.items()}\n",
    "\n",
    "char2idx_tar = {}\n",
    "# char2idx_tar[\"UNK\"] = 1\n",
    "char2idx_tar[\"<SOS>\"] = 1\n",
    "char2idx_tar[\"<EOS>\"] = 2\n",
    "char2idx_tar.update({char:idx+3 for idx, char in enumerate(chars_tar)})\n",
    "idx2char_tar = {value:key for key, value in char2idx_tar.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정상적으로 정수 인코딩이 수행된 것을 볼 수 있습니다. 아직 정수 인코딩을 수행해야 할 데이터가 하나 더 남았습니다. 디코더의 예측값과 비교하기 위한 실제값이 필요합니다. 그런데 이 실제값에는 시작 심볼에 해당되는 `<sos>`가 있을 필요가 없습니다. 이해가 되지 않는다면 이전 페이지의 그림으로 돌아가 Dense와 Softmax 위에 있는 단어들을 다시 보시기 바랍니다. 그래서 이번에는 정수 인코딩 과정에서 `<sos>`를 제거합니다. 즉, 모든 프랑스어 문장의 맨 앞에 붙어있는 '\\t'를 제거하도록 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input = data[\"src\"].apply(lambda x : [2] + [char2idx_src[char] for char in x] + [3]).tolist()\n",
    "dec_input = data[\"tar\"].apply(lambda x : [2] + [char2idx_tar[char] for char in x] + [3]).tolist()\n",
    "dec_true = data[\"tar\"].apply(lambda x : [char2idx_tar[char] for char in x] + [3]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 문장의 길이는 241입니다.\n",
      "길이가 55 이하인 문장이 전체의 95%를 차지합니다.\n"
     ]
    }
   ],
   "source": [
    "lens_enc = sorted([len(doc) for doc in enc_input])\n",
    "ratio = 0.95\n",
    "for idx, max_len_enc in enumerate(lens_enc):\n",
    "    if idx/len(lens_enc) >= ratio:\n",
    "        break\n",
    "print(f\"가장 긴 문장의 길이는 {np.max(lens_enc)}입니다.\")\n",
    "print(f\"길이가 {max_len_enc} 이하인 문장이 전체의 {ratio:.0%}를 차지합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 문장의 길이는 307입니다.\n",
      "길이가 66 이하인 문장이 전체의 95%를 차지합니다.\n"
     ]
    }
   ],
   "source": [
    "lens_dec = sorted([len(doc) for doc in dec_input])\n",
    "ratio = 0.95\n",
    "for idx, max_len_dec in enumerate(lens_dec):\n",
    "    if idx/len(lens_dec) >= ratio:\n",
    "        break\n",
    "print(f\"가장 긴 문장의 길이는 {np.max(lens_dec)}입니다.\")\n",
    "print(f\"길이가 {max_len_dec} 이하인 문장이 전체의 {ratio:.0%}를 차지합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input = tf.keras.preprocessing.sequence.pad_sequences(enc_input, padding=\"post\", maxlen=max_len_enc)\n",
    "dec_input = tf.keras.preprocessing.sequence.pad_sequences(dec_input, padding=\"post\", maxlen=max_len_dec)\n",
    "dec_true = tf.keras.preprocessing.sequence.pad_sequences(dec_true, padding=\"post\", maxlen=max_len_dec)\n",
    "\n",
    "enc_input = tf.keras.utils.to_categorical(enc_input)\n",
    "dec_input = tf.keras.utils.to_categorical(dec_input)\n",
    "dec_true = tf.keras.utils.to_categorical(dec_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn](https://wikidocs.net/images/page/24996/rnn%EA%B7%BC%ED%99%A9.PNG)\n",
    "- 이미 RNN에 대해서 배운 적이 있지만, 다시 복습을 해보도록 하겠습니다. 하나의 RNN 셀은 각각의 시점(time step)마다 두 개의 입력을 받습니다. (이해가 되지 않는다면, RNN 챕터를 다시 참고하세요.)\n",
    "- 현재 시점(time step)을 t라고 할 때, RNN 셀은 t-1에서의 은닉 상태와 t에서의 입력 벡터를 입력으로 받고, t에서의 은닉 상태를 만듭니다. 이때 t에서의 은닉 상태는 바로 위에 또 다른 은닉층이나 출력층이 존재할 경우에는 위의 층으로 보내거나, 필요없으면 값을 무시할 수 있습니다. 그리고 RNN 셀은 다음 시점에 해당하는 t+1의 RNN 셀의 입력으로 현재 t에서의 은닉 상태를 입력으로 보냅니다.\n",
    "- RNN 챕터에서도 언급했지만, 이런 구조에서 현재 시점 t에서의 은닉 상태는 과거 시점의 동일한 RNN 셀에서의 모든 은닉 상태의 값들의 영향을 누적해서 받아온 값이라고 할 수 있습니다. 그렇기 때문에 앞서 우리가 언급했던 컨텍스트 벡터는 사실 인코더에서의 마지막 RNN 셀의 은닉 상태값을 말하는 것이며, 이는 입력 문장의 모든 단어 토큰들의 정보를 요약해서 담고있다고 할 수 있습니다.\n",
    "- 디코더는 인코더의 마지막 RNN 셀의 은닉 상태인 컨텍스트 벡터를 첫번째 은닉 상태의 값으로 사용합니다. 디코더의 첫번째 RNN 셀은 이 첫번째 은닉 상태의 값과, 현재 t에서의 입력값인 `<sos>`로부터, 다음에 등장할 단어를 예측합니다.\n",
    "\n",
    "#### Teacher Forcing\n",
    "- 모델을 설계하기 전에 혹시 의아한 점은 없으신가요? 현재 시점의 디코더 셀의 입력은 오직 이전 디코더 셀의 출력을 입력으로 받는다고 설명하였는데 decoder_input이 왜 필요할까요?\n",
    "- 훈련 과정에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않고, 이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법을 사용할 겁니다. 그 이유는 이전 시점의 디코더 셀의 예측이 틀렸는데 이를 현재 시점의 디코더 셀의 입력으로 사용하면 현재 시점의 디코더 셀의 예측도 잘못될 가능성이 높고 이는 연쇄 작용으로 디코더 전체의 예측을 어렵게 합니다. 이런 상황이 반복되면 훈련 시간이 느려집니다. 만약 이 상황을 원하지 않는다면 이전 시점의 디코더 셀의 예측값 대신 실제값을 현재 시점의 디코더 셀의 입력으로 사용하는 방법을 사용할 수 있습니다. 이와 같이 RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법을 교사 강요라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Cv1RK5MTxeFC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_enc (InputLayer)          [(None, 55, 59)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_dec (InputLayer)          [(None, 66, 78)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_enc (LSTM)                 [(None, 256), (None, 323584      Input_enc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_dec (LSTM)                 [(None, 66, 256), (N 343040      Input_dec[0][0]                  \n",
      "                                                                 LSTM_enc[0][1]                   \n",
      "                                                                 LSTM_enc[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dense (Dense)                   (None, 66, 78)       20046       LSTM_dec[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 686,670\n",
      "Trainable params: 686,670\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs_enc = tf.keras.Input(shape=(max_len_enc, len(char2idx_src)+1), name=\"Input_enc\")\n",
    "_, h_state, c_state = tf.keras.layers.LSTM(units=256, return_state=True, name=\"LSTM_enc\")(inputs_enc)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태.\n",
    "\n",
    "inputs_dec = tf.keras.Input(shape=(max_len_dec, len(char2idx_tar)+1), name=\"Input_dec\")\n",
    "lstm_dec = tf.keras.layers.LSTM(units=256, return_sequences=True, return_state=True, name=\"LSTM_dec\")\n",
    "z, _, _ = lstm_dec(inputs_dec, initial_state=[h_state, c_state])\n",
    "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
    "dense_dec = tf.keras.layers.Dense(units=len(char2idx_tar)+1, activation=\"softmax\", name=\"Dense\")\n",
    "outputs_dec = dense_dec(z)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs_enc, inputs_dec], outputs=outputs_dec)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cv1RK5MTxeFC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 1.5517 - categorical_accuracy: 0.5810\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.64830, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 307s 818ms/step - loss: 1.5517 - categorical_accuracy: 0.5810 - val_loss: 1.2072 - val_categorical_accuracy: 0.6483\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 1.0774 - categorical_accuracy: 0.6845\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.64830 to 0.72438, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 300s 799ms/step - loss: 1.0774 - categorical_accuracy: 0.6845 - val_loss: 0.9437 - val_categorical_accuracy: 0.7244\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.8719 - categorical_accuracy: 0.7436\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.72438 to 0.76560, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 296s 790ms/step - loss: 0.8719 - categorical_accuracy: 0.7436 - val_loss: 0.7893 - val_categorical_accuracy: 0.7656\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.7473 - categorical_accuracy: 0.7758\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.76560 to 0.79035, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 301s 804ms/step - loss: 0.7473 - categorical_accuracy: 0.7758 - val_loss: 0.6980 - val_categorical_accuracy: 0.7903\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.6690 - categorical_accuracy: 0.7975\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.79035 to 0.80563, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 297s 791ms/step - loss: 0.6690 - categorical_accuracy: 0.7975 - val_loss: 0.6407 - val_categorical_accuracy: 0.8056\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.6165 - categorical_accuracy: 0.8123\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.80563 to 0.81923, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 295s 788ms/step - loss: 0.6165 - categorical_accuracy: 0.8123 - val_loss: 0.5943 - val_categorical_accuracy: 0.8192\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5786 - categorical_accuracy: 0.8233\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.81923 to 0.82587, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 295s 786ms/step - loss: 0.5786 - categorical_accuracy: 0.8233 - val_loss: 0.5719 - val_categorical_accuracy: 0.8259\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5505 - categorical_accuracy: 0.8312\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.82587 to 0.83245, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 291s 775ms/step - loss: 0.5505 - categorical_accuracy: 0.8312 - val_loss: 0.5455 - val_categorical_accuracy: 0.8324\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5287 - categorical_accuracy: 0.8373\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.83245 to 0.83732, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 299s 798ms/step - loss: 0.5287 - categorical_accuracy: 0.8373 - val_loss: 0.5290 - val_categorical_accuracy: 0.8373\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.5107 - categorical_accuracy: 0.8427\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.83732 to 0.83925, saving model to fra-eng-maxlen95per.h5\n",
      "375/375 [==============================] - 344s 919ms/step - loss: 0.5107 - categorical_accuracy: 0.8427 - val_loss: 0.5210 - val_categorical_accuracy: 0.8393\n",
      "Epoch 11/50\n",
      "268/375 [====================>.........] - ETA: 1:23 - loss: 0.4982 - categorical_accuracy: 0.8461"
     ]
    }
   ],
   "source": [
    "model_path = \"fra-eng-maxlen95per.h5\"\n",
    "if os.path.exists(model_path):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "else:\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"auto\", verbose=1, patience=4)\n",
    "    model_path = \"fra-eng-maxlen95per.h5\"\n",
    "    mc = tf.keras.callbacks.ModelCheckpoint(filepath=model_path, monitor=\"val_categorical_accuracy\", mode=\"auto\", verbose=1, save_best_only=True)\n",
    "    \n",
    "    hist = model.fit(x=[enc_input, dec_input], y=dec_true, batch_size=128, epochs=50, validation_split=0.2, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (?) seq2seq 기계 번역기 동작시키기\n",
    "- 앞서 seq2seq는 훈련할 때와 동작할 때의 방식이 다르다고 언급한 바 있습니다. 이번에는 입력한 문장에 대해서 기계 번역을 하도록 모델을 조정하고 동작시켜보도록 하겠습니다.\n",
    "- 전체적인 번역 동작 단계를 정리하면 아래와 같습니다.\n",
    "    1. 번역하고자 하는 입력 문장이 인코더에 들어가서 은닉 상태와 셀 상태를 얻습니다.\n",
    "    2. 상태와 `<SOS>`를 디코더로 보냅니다.\n",
    "    3. 디코더가 `<EOS>`가 나올 때까지 다음 문자를 예측하는 행동을 반복합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우선 인코더를 정의합니다. encoder_inputs와 encoder_states는 훈련 과정에서 이미 정의한 것들을 재사용하는 것입니다. 이제 디코더를 설계해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_enc = model.input[0]\n",
    "_, h_state, c_state = model.layers[2].output\n",
    "\n",
    "inputs_dec = model.input[1]\n",
    "\n",
    "enc_model = tf.keras.Model(inputs=inputs_enc, outputs=[h_state, c_state])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "h_state_bef = tf.keras.Input(shape=(256,))\n",
    "c_state_bef = tf.keras.Input(shape=(256,))\n",
    "# states_bef = [h_state_bef, c_state_bef]\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 initial_state를 이전 시점의 상태로 사용합니다.\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않습니다.\n",
    "lstm_dec = model.layers[3]\n",
    "z, h_state_aft, c_state_aft = lstm_dec(inputs_dec, initial_state=[h_state_bef, c_state_bef])\n",
    "# states_aft = [h_state_aft, c_state_aft]\n",
    "dense_dec = model.layers[4]\n",
    "outputs_dec = dense_dec(units=len(char2idx_tar)+1, activation=\"softmax\")(z)\n",
    "\n",
    "dec_model = tf.keras.Model(inputs=inputs_dec + [h_state_bef, c_state_bef], outputs=[outputs_dec] + [h_state_aft, c_state_aft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ++ll<EOS>\n"
     ]
    }
   ],
   "source": [
    "# 입력으로부터 인코더의 상태를 얻음\n",
    "i = 243\n",
    "enc_states = enc_model.predict(enc_input[i:i+1])\n",
    "\n",
    "# <SOS>에 해당하는 원-핫 벡터 생성\n",
    "prob = np.zeros((1, 1, len(char2idx_tar)+1))\n",
    "prob[0, 0, char2idx_tar[\"<SOS>\"]] = 1\n",
    "\n",
    "stop_cond = False\n",
    "decoded_sent = \"\"\n",
    "# stop_cond이 True가 될 때까지 루프 반복\n",
    "while not stop_cond:\n",
    "    # 이점 시점의 states를 현재 시점의 states로 사용합니다.\n",
    "    output_tokens, h_state, c_state = dec_model.predict([prob] + enc_states)\n",
    "    # 예측 결과를 문자로 변환합니다.\n",
    "    argmax = np.argmax(output_tokens[0, 0])\n",
    "    char = idx2char_tar[argmax]\n",
    "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장합니다.\n",
    "    prob = np.zeros((1, 1, len(char2idx_tar)+1))\n",
    "    prob[0, 0, argmax] = 1\n",
    "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "    decoded_sent += char\n",
    "\n",
    "    # 현재 시점의 states를 다음 시점의 states로 사용하기 위해 저장합니다.\n",
    "    enc_states = [h_state, c_state]\n",
    "    \n",
    "    # \"<EOS>\"에 도달하거나 최대 길이를 넘으면 stop_cond=True를 저장합니다.\n",
    "    if char == \"<EOS>\" or len(decoded_sent) == max_len_dec:\n",
    "        stop_cond = True\n",
    "\n",
    "print(decoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-2.68800613e-02, -2.27703862e-02,  3.70537601e-02,\n",
       "          2.25123856e-02, -3.95601578e-02, -2.87889037e-02,\n",
       "         -9.11046192e-03, -1.50133134e-03,  1.03860544e-02,\n",
       "          4.70931921e-03,  2.15513986e-02, -3.42556983e-02,\n",
       "         -4.46095578e-02,  1.89683549e-02, -1.66797340e-02,\n",
       "         -7.02403188e-02,  1.13514662e-02, -1.60320348e-03,\n",
       "          4.03183475e-02,  4.37728828e-04, -3.02699711e-02,\n",
       "          9.88309085e-03,  2.03280747e-02, -2.83464752e-02,\n",
       "         -9.02975560e-04, -1.70884281e-02, -7.02776806e-03,\n",
       "         -4.59507899e-03,  3.82102164e-03, -7.20903743e-04,\n",
       "         -1.22286929e-02, -1.66077893e-02, -2.52842475e-02,\n",
       "          1.31145325e-02, -2.03367583e-02, -1.32029653e-02,\n",
       "          1.41527057e-02,  3.95208597e-02, -4.02901322e-02,\n",
       "         -1.12701918e-03,  3.76835950e-02,  6.32066047e-03,\n",
       "          7.10277818e-03, -1.89795829e-02, -1.08874030e-03,\n",
       "         -2.24500932e-02,  2.09177081e-02,  3.81160676e-02,\n",
       "          1.44681428e-02,  3.80995893e-03, -4.58791219e-02,\n",
       "         -2.99053243e-03, -2.25609797e-03, -7.44355330e-03,\n",
       "         -1.97991193e-03,  4.73505445e-02,  1.10488769e-03,\n",
       "          2.19257008e-02,  1.22920386e-02, -1.37067167e-02,\n",
       "          2.00364795e-02,  1.81245301e-02,  4.66067642e-02,\n",
       "          1.68498419e-02, -4.15988937e-02,  9.11610760e-03,\n",
       "          3.43360789e-02,  1.36764674e-02, -3.15162987e-02,\n",
       "          4.92967479e-03, -5.07126525e-02,  8.94619524e-03,\n",
       "         -1.85740422e-02, -2.53748912e-02, -2.86151040e-02,\n",
       "         -3.77472863e-02,  3.04099247e-02, -2.22940035e-02,\n",
       "         -8.60116351e-03, -1.05211502e-02, -3.77996475e-03,\n",
       "          3.03763244e-02,  1.04289073e-02,  4.66054268e-02,\n",
       "         -1.99951027e-02, -1.08335456e-02, -1.72589608e-02,\n",
       "          1.88373830e-02, -1.82758458e-02, -3.72348074e-03,\n",
       "          1.31116912e-03,  3.28460000e-02, -1.37517573e-02,\n",
       "          3.48270051e-02,  5.22643607e-03, -1.15483254e-02,\n",
       "         -4.99840360e-03, -4.35661850e-03, -3.49183753e-02,\n",
       "         -8.08991492e-03, -8.16292537e-04, -2.22274987e-03,\n",
       "         -2.11079530e-02, -4.00031125e-03,  1.13163143e-02,\n",
       "         -3.92939076e-02, -3.45523655e-02, -3.23398560e-02,\n",
       "         -1.15560070e-02, -9.80394986e-03, -3.89043125e-03,\n",
       "         -5.84478863e-03, -3.46898250e-02,  2.29946412e-02,\n",
       "         -2.08653091e-03,  1.21268304e-02, -4.09808047e-02,\n",
       "         -1.45084439e-02,  1.87447835e-02, -3.31264809e-02,\n",
       "         -8.72862525e-04, -2.21770741e-02, -7.05517922e-03,\n",
       "         -1.05586117e-02, -2.21765712e-02, -2.40219440e-02,\n",
       "          2.59705284e-03, -2.65895426e-02,  3.08021791e-02,\n",
       "          2.43167803e-02,  1.43176764e-02, -8.35738052e-03,\n",
       "          3.61049883e-02,  2.62946878e-02,  8.25647637e-03,\n",
       "          3.73182446e-02,  1.14201410e-02, -2.67707426e-02,\n",
       "         -2.34232582e-02, -8.90378188e-03,  4.67483606e-03,\n",
       "          1.03949923e-02, -4.95912414e-03, -2.19027698e-02,\n",
       "          3.88176204e-03, -1.48931593e-02, -3.04628834e-02,\n",
       "         -8.33312515e-03, -1.34680318e-02,  2.15992033e-02,\n",
       "          1.39426067e-03, -4.18200269e-02, -1.64758042e-02,\n",
       "         -3.19863372e-02, -2.30338909e-02, -5.97814051e-03,\n",
       "          2.50286460e-02,  2.35399362e-02, -1.32701462e-02,\n",
       "         -2.56777108e-02,  2.75369808e-02,  3.26043181e-02,\n",
       "          1.97529215e-02,  4.68390919e-02,  4.91205528e-02,\n",
       "         -5.21830376e-03,  3.09227593e-02, -1.27312792e-02,\n",
       "          3.03531699e-02, -2.49188840e-02,  2.36405933e-04,\n",
       "          6.54357579e-03,  5.21769263e-02,  2.22307071e-03,\n",
       "          3.46641578e-02, -1.01759313e-02, -1.98111739e-02,\n",
       "          1.72422919e-02,  2.00045910e-02,  1.36315012e-02,\n",
       "          7.09274973e-05, -4.76159342e-02,  1.98621657e-02,\n",
       "          2.21298113e-02, -1.91907156e-02,  8.29750951e-03,\n",
       "          3.85190849e-03, -2.74277106e-02, -2.56189909e-02,\n",
       "         -1.56435221e-02,  1.06365336e-02, -8.12464580e-03,\n",
       "          3.16089764e-02,  3.44233662e-02,  2.38069845e-03,\n",
       "         -4.67520813e-03, -2.95665730e-02,  5.07846614e-03,\n",
       "          8.96632671e-03,  5.66346245e-03,  4.01440542e-03,\n",
       "          1.30542461e-02,  2.11709328e-02,  2.32164934e-02,\n",
       "          4.92966780e-03,  6.10549876e-04,  1.81541443e-02,\n",
       "          2.67440872e-03,  3.88238952e-02, -1.62589997e-02,\n",
       "         -1.51734380e-02,  1.38302902e-02, -2.36018635e-02,\n",
       "          1.53370397e-02,  1.16730090e-02,  8.39687046e-03,\n",
       "         -1.73037145e-02,  1.08953407e-02,  1.03150727e-02,\n",
       "          1.92659590e-02,  4.03104909e-02,  7.14820926e-04,\n",
       "         -2.12392770e-02, -3.88052016e-02, -2.66815107e-02,\n",
       "         -6.71847956e-03, -2.53753494e-02,  2.28836052e-02,\n",
       "          4.23528254e-02, -1.05980122e-02,  1.93070713e-02,\n",
       "         -1.09156417e-02,  3.91567051e-02, -2.77595571e-03,\n",
       "         -2.07020789e-02,  4.60377801e-03,  2.08667368e-02,\n",
       "         -2.61485483e-03, -2.04012897e-02, -3.79487425e-02,\n",
       "         -1.39454110e-02,  3.31238471e-02,  3.95652931e-03,\n",
       "         -1.39932502e-02,  1.45367151e-02, -1.51421605e-02,\n",
       "         -2.28887368e-02,  2.41590217e-02,  1.56084951e-02,\n",
       "          1.93569139e-02,  2.91809328e-02, -1.05490526e-02,\n",
       "          4.74834256e-03, -1.16173318e-02, -1.99852674e-03,\n",
       "         -5.84220281e-03]], dtype=float32),\n",
       " array([[-0.05461048, -0.04446407,  0.07661122,  0.04363031, -0.07853445,\n",
       "         -0.05793419, -0.01823959, -0.00298223,  0.0200364 ,  0.0091384 ,\n",
       "          0.04445877, -0.07065193, -0.08623819,  0.03805092, -0.03259385,\n",
       "         -0.14456916,  0.02275759, -0.0031406 ,  0.07950436,  0.00087195,\n",
       "         -0.05922708,  0.01980978,  0.04145341, -0.0564549 , -0.00175996,\n",
       "         -0.03502711, -0.01386952, -0.00954039,  0.00752792, -0.0014135 ,\n",
       "         -0.02453976, -0.03364118, -0.05143569,  0.02527116, -0.03938705,\n",
       "         -0.026235  ,  0.02744805,  0.07928476, -0.08122288, -0.00223805,\n",
       "          0.07568909,  0.01295714,  0.01385935, -0.03683195, -0.00210636,\n",
       "         -0.04416073,  0.04249427,  0.07328601,  0.02919856,  0.00767219,\n",
       "         -0.09435584, -0.00610474, -0.00441385, -0.01443556, -0.00406273,\n",
       "          0.09723803,  0.00216592,  0.04270228,  0.02484291, -0.02834571,\n",
       "          0.04055436,  0.03659921,  0.09454739,  0.03358512, -0.08113654,\n",
       "          0.01831714,  0.06675521,  0.02824786, -0.06417656,  0.00984226,\n",
       "         -0.10030632,  0.01830991, -0.03767284, -0.04940347, -0.05686143,\n",
       "         -0.07745288,  0.06260297, -0.0454855 , -0.01760194, -0.02156233,\n",
       "         -0.00764818,  0.05984734,  0.02039973,  0.09471081, -0.03953411,\n",
       "         -0.02256072, -0.03462601,  0.03937708, -0.0360858 , -0.00755305,\n",
       "          0.00259856,  0.0633136 , -0.02731034,  0.06794056,  0.01052903,\n",
       "         -0.0237902 , -0.00979655, -0.00855877, -0.06936809, -0.01642321,\n",
       "         -0.00159611, -0.00431947, -0.04367162, -0.00811656,  0.02335948,\n",
       "         -0.07993606, -0.07007197, -0.06710462, -0.02390938, -0.01899405,\n",
       "         -0.00750826, -0.0118195 , -0.06790025,  0.04563474, -0.00405106,\n",
       "          0.0246599 , -0.08151338, -0.02988157,  0.03891665, -0.06777397,\n",
       "         -0.00179861, -0.04423383, -0.01429201, -0.02146234, -0.04338164,\n",
       "         -0.04671714,  0.00505571, -0.05452809,  0.06330809,  0.04947872,\n",
       "          0.02814267, -0.01638711,  0.07084337,  0.05147154,  0.01673675,\n",
       "          0.0720049 ,  0.02222032, -0.05417713, -0.04813865, -0.01818023,\n",
       "          0.00925377,  0.02120732, -0.00972716, -0.04452372,  0.00777689,\n",
       "         -0.02938038, -0.06036287, -0.01646516, -0.02746608,  0.04481412,\n",
       "          0.00286777, -0.08341907, -0.03305306, -0.06570924, -0.04586488,\n",
       "         -0.01240238,  0.05101676,  0.04845487, -0.02689615, -0.05217582,\n",
       "          0.05616963,  0.06686979,  0.04082655,  0.09644759,  0.10256058,\n",
       "         -0.01006748,  0.06277609, -0.02581559,  0.05946784, -0.04917002,\n",
       "          0.00047192,  0.01340362,  0.10086309,  0.0044288 ,  0.06900154,\n",
       "         -0.02003869, -0.04035785,  0.03457884,  0.03992477,  0.0274409 ,\n",
       "          0.00014716, -0.09709129,  0.03972563,  0.0458293 , -0.03920113,\n",
       "          0.01697035,  0.0074105 , -0.054241  , -0.05027562, -0.03035797,\n",
       "          0.0212228 , -0.01627816,  0.06248505,  0.06684408,  0.00478108,\n",
       "         -0.00947594, -0.05844451,  0.01013127,  0.01767498,  0.01105401,\n",
       "          0.00787576,  0.02566165,  0.04367915,  0.04534354,  0.0098612 ,\n",
       "          0.00121295,  0.03750707,  0.00552922,  0.07770705, -0.03287211,\n",
       "         -0.03125472,  0.02812198, -0.0477232 ,  0.03017347,  0.02302791,\n",
       "          0.0171455 , -0.03461268,  0.02199833,  0.02113258,  0.03832519,\n",
       "          0.08001065,  0.00144335, -0.04261738, -0.07914792, -0.05340608,\n",
       "         -0.01379015, -0.04999135,  0.04621733,  0.08353311, -0.02169967,\n",
       "          0.03978181, -0.02151582,  0.07875413, -0.00552206, -0.04167995,\n",
       "          0.00921275,  0.04065853, -0.00509073, -0.04175422, -0.07417805,\n",
       "         -0.02840358,  0.06700996,  0.00774069, -0.02802096,  0.0298028 ,\n",
       "         -0.03163023, -0.04483188,  0.04646021,  0.03053991,  0.03933141,\n",
       "          0.05840308, -0.02038939,  0.00981353, -0.02359666, -0.0039454 ,\n",
       "         -0.0116572 ]], dtype=float32)]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02687396, -0.02275593,  0.03702515,  0.02249553, -0.03955029,\n",
       "         -0.02878058, -0.00912296, -0.00149236,  0.01037748,  0.00470832,\n",
       "          0.02157548, -0.03427692, -0.04459661,  0.01898765, -0.01669138,\n",
       "         -0.07021729,  0.01134609, -0.00161005,  0.04031789,  0.00040445,\n",
       "         -0.03028595,  0.0098694 ,  0.02034914, -0.02835661, -0.00089992,\n",
       "         -0.0170797 , -0.00701362, -0.00457025,  0.00382192, -0.00073401,\n",
       "         -0.01223237, -0.01659616, -0.02528047,  0.01317117, -0.02030543,\n",
       "         -0.01323039,  0.01414666,  0.03951007, -0.04029192, -0.00112985,\n",
       "          0.03767408,  0.00629731,  0.00709937, -0.01898207, -0.00106029,\n",
       "         -0.02246476,  0.02095627,  0.03811391,  0.01449124,  0.0038495 ,\n",
       "         -0.04585696, -0.00299026, -0.00226428, -0.00746317, -0.00199445,\n",
       "          0.04736852,  0.00110353,  0.02191968,  0.01229315, -0.01369936,\n",
       "          0.02003951,  0.01808918,  0.04661681,  0.01683165, -0.04160158,\n",
       "          0.00909688,  0.03435796,  0.01368621, -0.03150711,  0.00492736,\n",
       "         -0.05070926,  0.00891589, -0.01857023, -0.02536513, -0.02862929,\n",
       "         -0.03773943,  0.03040461, -0.02231506, -0.00860152, -0.01052423,\n",
       "         -0.00380122,  0.03038683,  0.01043289,  0.04658718, -0.02000951,\n",
       "         -0.01080428, -0.01725961,  0.01883981, -0.01825465, -0.00370402,\n",
       "          0.00131448,  0.03281339, -0.01372812,  0.03484885,  0.005223  ,\n",
       "         -0.01154294, -0.00498446, -0.00434499, -0.03490186, -0.0080801 ,\n",
       "         -0.00079891, -0.00221862, -0.02111498, -0.00401843,  0.0113169 ,\n",
       "         -0.03929098, -0.03456094, -0.03234689, -0.01153261, -0.00980747,\n",
       "         -0.0039071 , -0.00582649, -0.03468864,  0.02302921, -0.00209599,\n",
       "          0.01215528, -0.04095028, -0.014503  ,  0.01872497, -0.03314189,\n",
       "         -0.00086457, -0.02219429, -0.00705611, -0.01054886, -0.02218523,\n",
       "         -0.02401721,  0.00257316, -0.02659856,  0.03083073,  0.02433728,\n",
       "          0.01429273, -0.0083556 ,  0.0361089 ,  0.02628806,  0.00826023,\n",
       "          0.03732952,  0.01138272, -0.02680928, -0.02341856, -0.00889587,\n",
       "          0.00464961,  0.01037789, -0.00494749, -0.02191425,  0.00388409,\n",
       "         -0.01487559, -0.03045795, -0.00833582, -0.01342373,  0.02160558,\n",
       "          0.00140664, -0.04181128, -0.01647367, -0.0319685 , -0.023043  ,\n",
       "         -0.0060083 ,  0.02503878,  0.02351465, -0.01329676, -0.02567942,\n",
       "          0.02754194,  0.03262226,  0.01977421,  0.04684212,  0.04911739,\n",
       "         -0.00519625,  0.03090474, -0.01275937,  0.03035004, -0.02493005,\n",
       "          0.00025792,  0.00652609,  0.05217349,  0.00221099,  0.03466572,\n",
       "         -0.01017278, -0.01978645,  0.01725608,  0.01996516,  0.01364151,\n",
       "          0.00010318, -0.04760429,  0.01985343,  0.02212067, -0.01919004,\n",
       "          0.00829845,  0.00386823, -0.02744451, -0.02561434, -0.01563352,\n",
       "          0.01062724, -0.00814283,  0.03161482,  0.03444057,  0.00236663,\n",
       "         -0.00469084, -0.02955228,  0.00509309,  0.00897133,  0.00565542,\n",
       "          0.00402165,  0.01307957,  0.02117961,  0.02323693,  0.00494153,\n",
       "          0.00060978,  0.01813945,  0.00264544,  0.03882469, -0.01623942,\n",
       "         -0.01519177,  0.01383447, -0.02358693,  0.01535005,  0.01162855,\n",
       "          0.00840141, -0.01728347,  0.01089576,  0.01031267,  0.01925221,\n",
       "          0.04029787,  0.00073123, -0.02125932, -0.03878239, -0.02670542,\n",
       "         -0.00672149, -0.02536322,  0.0228876 ,  0.04234993, -0.01058312,\n",
       "          0.01926853, -0.0109453 ,  0.03914424, -0.00277562, -0.0207164 ,\n",
       "          0.00461719,  0.02087536, -0.00261509, -0.02040277, -0.03790966,\n",
       "         -0.01393685,  0.03313826,  0.0039352 , -0.01400054,  0.01452418,\n",
       "         -0.01514606, -0.02288244,  0.02416493,  0.01561905,  0.01937452,\n",
       "          0.02914779, -0.01055185,  0.00474793, -0.01160275, -0.00199793,\n",
       "         -0.00587184]], dtype=float32),\n",
       " array([[-0.054598  , -0.04443548,  0.07655191,  0.04359738, -0.07851458,\n",
       "         -0.0579173 , -0.0182646 , -0.00296443,  0.02001988,  0.00913645,\n",
       "          0.04450841, -0.07069609, -0.08621307,  0.03808944, -0.03261681,\n",
       "         -0.14452134,  0.02274677, -0.00315402,  0.07950354,  0.00080567,\n",
       "         -0.05925901,  0.01978221,  0.04149665, -0.0564752 , -0.00175399,\n",
       "         -0.03500925, -0.01384165, -0.00948886,  0.00752965, -0.00143919,\n",
       "         -0.02454697, -0.03361755, -0.05142837,  0.02538045, -0.03932661,\n",
       "         -0.02628931,  0.02743617,  0.07926376, -0.08122635, -0.0022437 ,\n",
       "          0.0756697 ,  0.01290939,  0.01385269, -0.03683706, -0.00205132,\n",
       "         -0.04418948,  0.04257233,  0.07328193,  0.02924517,  0.00775176,\n",
       "         -0.09430924, -0.00610417, -0.00442987, -0.0144736 , -0.00409254,\n",
       "          0.09727469,  0.00216327,  0.04269054,  0.02484502, -0.02833035,\n",
       "          0.04056039,  0.03652763,  0.09456733,  0.03354926, -0.08114181,\n",
       "          0.01827836,  0.06679836,  0.02826798, -0.06415773,  0.00983768,\n",
       "         -0.10029948,  0.01824801, -0.03766509, -0.04938467, -0.05688973,\n",
       "         -0.07743654,  0.06259219, -0.04552834, -0.01760269, -0.02156872,\n",
       "         -0.00769114,  0.05986783,  0.02040759,  0.09467413, -0.03956279,\n",
       "         -0.02249993, -0.03462716,  0.03938197, -0.03604347, -0.00751358,\n",
       "          0.00260512,  0.06325065, -0.02726341,  0.06798424,  0.01052203,\n",
       "         -0.02377892, -0.00976919, -0.00853599, -0.06933452, -0.01640332,\n",
       "         -0.00156212, -0.00431146, -0.04368594, -0.00815322,  0.02336083,\n",
       "         -0.07993073, -0.07008935, -0.06711943, -0.02386097, -0.01900079,\n",
       "         -0.00754047, -0.0117825 , -0.06789797,  0.04570347, -0.00406938,\n",
       "          0.02471795, -0.08145239, -0.02987029,  0.03887524, -0.06780592,\n",
       "         -0.00178153, -0.04426865, -0.01429374, -0.02144261, -0.04339855,\n",
       "         -0.04670803,  0.00500918, -0.05454681,  0.06336668,  0.04952045,\n",
       "          0.02809369, -0.01638357,  0.07085139,  0.05145886,  0.01674443,\n",
       "          0.07202668,  0.02214754, -0.05425546, -0.04812935, -0.01816385,\n",
       "          0.00920382,  0.0211722 , -0.0097043 , -0.04454714,  0.00778152,\n",
       "         -0.02934567, -0.06035274, -0.0164705 , -0.02737544,  0.0448271 ,\n",
       "          0.00289322, -0.08340192, -0.03304905, -0.065672  , -0.04588281,\n",
       "         -0.01246488,  0.05103777,  0.04840258, -0.02695035, -0.05217878,\n",
       "          0.05617986,  0.0669073 ,  0.04087035,  0.09645386,  0.10255363,\n",
       "         -0.01002497,  0.06273987, -0.0258725 ,  0.05946182, -0.04919226,\n",
       "          0.00051486,  0.013368  ,  0.10085646,  0.00440476,  0.06900366,\n",
       "         -0.02003252, -0.04030764,  0.03460662,  0.03984602,  0.02746123,\n",
       "          0.00021408, -0.09706757,  0.03970834,  0.04581008, -0.03919951,\n",
       "          0.01697234,  0.00744187, -0.05427434, -0.0502663 , -0.03033854,\n",
       "          0.02120432, -0.01631451,  0.06249679,  0.06687808,  0.00475283,\n",
       "         -0.0095076 , -0.05841606,  0.01016043,  0.01768469,  0.01103832,\n",
       "          0.00789001,  0.02571155,  0.04369709,  0.04538344,  0.00988485,\n",
       "          0.00121141,  0.03747649,  0.00546935,  0.07770924, -0.03283262,\n",
       "         -0.03129236,  0.02813057, -0.04769316,  0.03019901,  0.02294027,\n",
       "          0.01715484, -0.0345721 ,  0.02199909,  0.02112755,  0.03829763,\n",
       "          0.07998521,  0.00147648, -0.0426583 , -0.07910149, -0.05345454,\n",
       "         -0.01379636, -0.0499679 ,  0.04622555,  0.08352745, -0.02166904,\n",
       "          0.03970252, -0.0215743 ,  0.07872848, -0.00552139, -0.04170833,\n",
       "          0.00923956,  0.04067498, -0.00509115, -0.04175726, -0.07410147,\n",
       "         -0.02838606,  0.06703826,  0.00769896, -0.02803555,  0.02977696,\n",
       "         -0.03163847, -0.04481919,  0.04647177,  0.03056073,  0.03936733,\n",
       "          0.05833709, -0.02039482,  0.00981261, -0.02356702, -0.00394421,\n",
       "         -0.01171625]], dtype=float32)]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "7ob9YTTgyGRg",
    "outputId": "c6ba0f85-7929-4688-a8c5-3452cd753767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 88, 78) for input Tensor(\"Input_dec:0\", shape=(None, 88, 78), dtype=float32), but it was called on an input with incompatible shape (None, 1, 77).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\n        inputs, training=training, mask=mask)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:716 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer lstm: expected shape=(None, None, 78), found shape=[None, 1, 77]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-af7ddecd461f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m13812\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 입력 문장의 인덱스\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mseq_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdecoded_sent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m35\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"입력 문장:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"src\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-b5a1c17bdbd3>\u001b[0m in \u001b[0;36mdecode_seq\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop_cond\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0moutput_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdec_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# 예측 결과를 문자로 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\n        inputs, training=training, mask=mask)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:716 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    C:\\Users\\5CG7092POZ\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer lstm: expected shape=(None, None, 78), found shape=[None, 1, 77]\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [0, 1, 2]: # 입력 문장의 인덱스\n",
    "    input_seq = enc_input[seq_index:seq_index + 1]\n",
    "    decoded_sent = decode_seq(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print(\"입력 문장:\", data[\"src\"][seq_index])\n",
    "    print(\"정답 문장:\", data[\"tar\"][seq_index][1:len(data[\"tar\"][seq_index])-1]) # \"\\t\"와 \"\\n\"을 빼고 출력\n",
    "    print(\"번역기가 번역한 문장:\", decoded_sent[:len(decoded_sent)-1]) # \"\\n\"을 빼고 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "kbC3si3rrEEN"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-8d5618ddb0e7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-35-8d5618ddb0e7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from nltk.translate.bleu_score import nltk.translate.bleu_score.corpus_bleu, SmoothingFunction\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import nltk.translate.bleu_score.corpus_bleu, SmoothingFunction\n",
    "smooth_fn = SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 994
    },
    "id": "ZbbUbHkjzpuk",
    "outputId": "c9cb2914-7a56-4de1-8190-087220ac40c6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a560306f4da5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 입력 문장의 인덱스\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoder_input' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "actual, predicted = list(), list()\n",
    "\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sent = decode_seq(input_seq)\n",
    "    \n",
    "    actual.append([lines.tar[seq_index][1:len(lines.tar[seq_index])-1].split()])\n",
    "    predicted.append(decoded_sent[:len(decoded_sent)-1].split())\n",
    "                  \n",
    "    print(35 * \"-\")\n",
    "    print(\"입력 문장:\", lines.src[seq_index])\n",
    "    print(lines.src[seq_index].split())\n",
    "    print(\"정답 문장:\", lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # \"\\t\"와 \"\\n\"을 빼고 출력\n",
    "    print(lines.tar[seq_index][1:len(lines.tar[seq_index])-1].split())\n",
    "    print(\"번역기가 번역한 문장:\", decoded_sent[:len(decoded_sent)-1]) # \"\\n\"을 빼고 출력\n",
    "    print(decoded_sent[:len(decoded_sent)-1].split())\n",
    "    \n",
    "    #print(actual)\n",
    "    #print(predicted)\n",
    "    print(\"BLEU-1: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0), smoothing_function = smooth_fn.method1))\n",
    "    print(\"BLEU-2: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0), smoothing_function = smooth_fn.method1))\n",
    "    print(\"BLEU-3: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0), smoothing_function = smooth_fn.method1))\n",
    "    print(\"BLEU-4: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function = smooth_fn.method1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VVugWpwexrfe",
    "outputId": "823bdb72-a0bf-40f0-b4a6-dbdfaf74cc03"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e4cd16961aa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 입력 문장의 인덱스\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoder_input' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "actual, predicted = list(), list()\n",
    "\n",
    "for seq_index in range(0, len(encoder_input)): # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sent = decode_seq(input_seq)\n",
    "    \n",
    "    actual.append([lines.tar[seq_index][1:len(lines.tar[seq_index])-1].split()])\n",
    "    predicted.append(decoded_sent[:len(decoded_sent)-1].split())\n",
    "\n",
    "    if seq_index < 10:\n",
    "      print(35 * \"-\")\n",
    "      print(\"입력 문장:\", lines.src[seq_index])\n",
    "      print(lines.src[seq_index].split())\n",
    "      print(\"정답 문장:\", lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # \"\\t\"와 \"\\n\"을 빼고 출력\n",
    "      print(lines.tar[seq_index][1:len(lines.tar[seq_index])-1].split())\n",
    "      print(\"번역기가 번역한 문장:\", decoded_sent[:len(decoded_sent)-1]) # \"\\n\"을 빼고 출력\n",
    "      print(decoded_sent[:len(decoded_sent)-1].split())\n",
    "    \n",
    "      print(\"BLEU-1: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0), smoothing_function = smooth_fn.method1))\n",
    "      print(\"BLEU-2: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0), smoothing_function = smooth_fn.method1))\n",
    "      print(\"BLEU-3: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0), smoothing_function = smooth_fn.method1))\n",
    "      print(\"BLEU-4: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function = smooth_fn.method1))\n",
    "    \n",
    "print(\"BLEU-1: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0), smoothing_function = smooth_fn.method1))\n",
    "print(\"BLEU-2: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0), smoothing_function = smooth_fn.method1))\n",
    "print(\"BLEU-3: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0), smoothing_function = smooth_fn.method1))\n",
    "print(\"BLEU-4: %f\" % nltk.translate.bleu_score.corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function = smooth_fn.method1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Learning Spoons 6강 (seq2seq).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
