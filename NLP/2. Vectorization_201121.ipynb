{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.0\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\5CG7092POZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\5CG7092POZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\5CG7092POZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from konlpy.tag import *\n",
    "from ckonlpy.tag import Twitter\n",
    "import MeCab\n",
    "import kss\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "from soynlp.normalizer import *\n",
    "import hanspell\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import urllib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import platform\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "okt = Okt()\n",
    "kkm = Kkma()\n",
    "kmr = Komoran()\n",
    "hnn = Hannanum()\n",
    "twt = Twitter()\n",
    "\n",
    "class Mecab:\n",
    "    def pos(self, text):\n",
    "        p = re.compile(\".+\\t[A-Z]+\")\n",
    "        return [tuple(p.match(line).group().split(\"\\t\")) for line in MeCab.Tagger().parse(text).splitlines()[:-1]]\n",
    "    \n",
    "    def morphs(self, text):\n",
    "        p = re.compile(\".+\\t[A-Z]+\")\n",
    "        return [p.match(line).group().split(\"\\t\")[0] for line in MeCab.Tagger().parse(text).splitlines()[:-1]]\n",
    "    \n",
    "    def nouns(self, text):\n",
    "        p = re.compile(\".+\\t[A-Z]+\")\n",
    "        temp = [tuple(p.match(line).group().split(\"\\t\")) for line in MeCab.Tagger().parse(text).splitlines()[:-1]]\n",
    "        nouns=[]\n",
    "        for word in temp:\n",
    "            if word[1] in [\"NNG\", \"NNP\", \"NNB\", \"NNBC\", \"NP\", \"NR\"]:\n",
    "                nouns.append(word[0])\n",
    "        return nouns\n",
    "    \n",
    "mc = Mecab()\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "path = \"C:/Windows/Fonts/malgun.ttf\"\n",
    "if platform.system() == \"Darwin\":\n",
    "    mpl.rc(\"font\", family=\"AppleGothic\")\n",
    "elif platform.system() == \"Windows\":\n",
    "    font_name = mpl.font_manager.FontProperties(fname=path).get_name()\n",
    "    mpl.rc('font', family=font_name)\n",
    "    \n",
    "mpl.rc(\"axes\", unicode_minus=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5D3ayJ7-csa"
   },
   "source": [
    "# 1. Bag of Words\n",
    "- Bag of Words란 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법입니다. Bag of Words를 직역하면 단어들의 가방이라는 의미입니다. 단어들이 들어있는 가방을 상상해봅시다. 갖고있는 어떤 텍스트 문서에 있는 단어들을 가방에다가 전부 넣습니다. 그러고나서 이 가방을 흔들어 단어들을 섞습니다. 만약, 해당 문서 내에서 특정 단어가 N번 등장했다면, 이 가방에는 그 특정 단어가 N개 있게됩니다. 또한 가방을 흔들어서 단어를 섞었기 때문에 더 이상 단어의 순서는 중요하지 않습니다.\n",
    "\n",
    "## 1-1. 직접 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CPCE9Ygl-fDm",
    "outputId": "ab569b17-e46c-4bc9-91b8-a96c81ddc079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
      "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#정규 표현식을 통해 온점을 제거하는 정제 작업입니다.\n",
    "token = re.sub(\"(\\.)\",\"\",\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")  \n",
    "token = okt.morphs(token)  \n",
    "\n",
    "word2idx = {}\n",
    "bow = []\n",
    "for voca in token:\n",
    "    if voca not in word2idx.keys():\n",
    "        # token을 읽으면서, word2idx에 없는 (not in) 단어는 새로 추가하고, 이미 있는 단어는 넘깁니다.\n",
    "        word2idx[voca] = len(word2idx)\n",
    "# BoW 전체에 전부 기본값 1을 넣어줍니다. 단어의 개수는 최소 1개 이상이기 때문입니다.\n",
    "        bow.insert(-1, 1)\n",
    "    else:\n",
    "        #재등장하는 단어의 인덱스를 받아옵니다.\n",
    "        idx = word2idx.get(voca)\n",
    "        #재등장한 단어는 해당하는 인덱스의 위치에 1을 더해줍니다.(단어의 개수를 세는 것입니다.)\n",
    "        bow[idx] = bow[idx] + 1\n",
    "\n",
    "print(word2idx)\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QTivA0U-rw9"
   },
   "source": [
    "## 1-2. CountVectorizer 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lsGR3Cug-s2u",
    "outputId": "b6a396b6-26d6-4ae4-dc38-ad30031b2973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 1 2 1]]\n",
      "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"you know I want your love. because I love you.\"]\n",
    "vect = CountVectorizer()\n",
    "\n",
    "#코퍼스로부터 각 단어의 빈도 수를 기록한다.\n",
    "print(vect.fit_transform(corpus).toarray())\n",
    "#각 단어의 인덱스가 어떻게 부여되었는지를 보여준다.\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5hzdbff-ymS"
   },
   "source": [
    "# 2. TF-IDF\n",
    "\n",
    "## 2-1. 직접 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UjPcwe9-1C8"
   },
   "outputs": [],
   "source": [
    "docs = [\"먹고 싶은 사과\", \"먹고 싶은 바나나\", \"길고 노란 바나나 바나나\", \"저는 과일이 좋아요\"] \n",
    "vocab = list(set(word for doc in docs for word in doc.split(\" \")))\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "op8MoZGy-2RM"
   },
   "outputs": [],
   "source": [
    "#총 문서의 수\n",
    "N = len(docs)\n",
    "\n",
    "def calc_tf(term, doc):\n",
    "    return doc.count(term)\n",
    "\n",
    "def calc_idf(term):\n",
    "    df = 0\n",
    "    for doc in docs:\n",
    "        df += term in doc\n",
    "    return log(N/(df + 1))\n",
    "\n",
    "def calc_tfidf(term, doc):\n",
    "    return calc_tf(term, doc)*calc_idf(term)\n",
    "\n",
    "tf = []\n",
    "for i in range(N):\n",
    "    tf.append([])\n",
    "    doc = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        term = vocab[j]\n",
    "        tf[-1].append(calc_tf(term, doc))\n",
    "\n",
    "tf_df = pd.DataFrame(tf, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
       "0    0   0   0   1    0   1   1   0    0\n",
       "1    0   0   0   1    1   0   1   0    0\n",
       "2    0   1   1   0    2   0   0   0    0\n",
       "3    1   0   0   0    0   0   0   1    1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "zmRYlIcr-4H0",
    "outputId": "843870e2-8695-4ce5-a7db-496ed0fb67b2"
   },
   "outputs": [],
   "source": [
    "idf = []\n",
    "for i in range(len(vocab)):\n",
    "    term = vocab[i]\n",
    "    idf.append(calc_idf(term))\n",
    "idf_ser = pd.Series(idf, index=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "과일이    0.693147\n",
       "길고     0.693147\n",
       "노란     0.693147\n",
       "먹고     0.287682\n",
       "바나나    0.287682\n",
       "사과     0.693147\n",
       "싶은     0.287682\n",
       "저는     0.693147\n",
       "좋아요    0.693147\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "bDxaaHOR-48M",
    "outputId": "d509bfe9-2cae-487c-ff02-b80418152fc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        과일이        길고        노란        먹고       바나나        사과        싶은  \\\n",
       "0  0.000000  0.000000  0.000000  0.287682  0.000000  0.693147  0.287682   \n",
       "1  0.000000  0.000000  0.000000  0.287682  0.287682  0.000000  0.287682   \n",
       "2  0.000000  0.693147  0.693147  0.000000  0.575364  0.000000  0.000000   \n",
       "3  0.693147  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         저는       좋아요  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.693147  0.693147  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = []\n",
    "for i in range(N):\n",
    "    doc = docs[i]\n",
    "    tfidf.append([])\n",
    "    for j in range(len(vocab)):\n",
    "        term = vocab[j]\n",
    "        tfidf[-1].append(calc_tfidf(term, doc))\n",
    "tfidf_df = pd.DataFrame(tfidf, columns=vocab)\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpJC6ZIl-7Fb"
   },
   "source": [
    "- 지금까지 TF-IDF의 가장 기본적인 식에 대해서 학습하고, 이를 실제로 구현하는 실습을 진행해보았습니다. 그런데 사실 실제 TF-IDF 구현을 제공하고 있는 많은 패키지들은 패키지마다 식이 조금씩 다르긴 하지만, 위에서 배운 기본 식에서 조정된 식을 사용합니다. 그 이유는 위의 기본적인 식을 바탕으로 한 구현에도 여전히 문제점이 존재하기 때문입니다. 만약 전체 문서의 수 `N=4`인데, `DF=3`인 경우에는 어떤 일이 벌어질까요? `IDF=0`이 됨을 의미합니다. 식으로 표현하면 `IDF = log(N/(DF + 1)) = 0`입니다. IDF의 값이 0이라면 더 이상 가중치의 역할을 수행하지 못합니다. 그래서 실제 구현체는 IDF = log(N/(DF + 1)) + 1과 같이 log항에 1을 더해줘서 log항의 값이 0이 되더라도 IDF가 최소 1이상의 값을 가지도록 합니다. 사이킷런도 이 방식을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QG_BPc4o-_jc"
   },
   "source": [
    "## 1-2. Tensorflow로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpz6r_1o_GXb"
   },
   "outputs": [],
   "source": [
    "texts = [\"먹고 싶은 사과\", \"먹고 싶은 바나나\", \"길고 노란 바나나 바나나\", \"저는 과일이 좋아요\"]\n",
    "tkn = tf.keras.preprocessing.text.Tokenizer()\n",
    "tkn.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpz6r_1o_GXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'바나나': 1, '먹고': 2, '싶은': 3, '사과': 4, '길고': 5, '노란': 6, '저는': 7, '과일이': 8, '좋아요': 9}\n"
     ]
    }
   ],
   "source": [
    "print(tkn.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Oj1fBxt_J27"
   },
   "source": [
    "- 각 단어에 숫자 1부터 시작하는 정수 인덱스가 부여되었습니다. 이제 텍스트 데이터에 `texts_to_matrix()`를 사용해보겠습니다. `texts_to_matrix()`란 이름에서 알 수 있지만, 이 도구는 입력된 텍스트 데이터로부터 행렬(matrix)를 만드는 도구입니다. 총 4개의 모드를 지원하는데 각 모드는 `\"count\"`, `\"binary\"`, `\"tfidf\"`, `\"freq\"`입니다. 우선 `\"count\"` 모드를 사용해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) `mode=\"binary\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "Ap9iSw0L_NJV",
    "outputId": "d83fb634-88a8-4773-e65c-86b32a2a97f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(tkn.texts_to_matrix(texts, mode=\"binary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tb2_BLrW_P9O"
   },
   "source": [
    "- DTM과 결과가 매우 유사해보입니다. 다만 세번째 행, 두번째 열의 값이 DTM에서는 2였는데 여기서는 1로 바뀌었습니다. 그 이유는 \"binary\" 모드는 해당 단어가 존재하는지만 관심을 가지고 해당 단어가 몇 개였는지는 무시하기 때문입니다. 해당 단어가 존재하면 1, 단어가 존재하지 않으면 0의 값을 가집니다. 즉, 단어의 존재 유무로만 행렬을 표현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) `mode=\"count\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "FpOuYNoo_H5O",
    "outputId": "7ea580eb-4fab-4291-a910-1a985701f9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(tkn.texts_to_matrix(texts, mode=\"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vx1zvYzP_MgS"
   },
   "source": [
    "- \"count\"를 사용하면 우리가 앞서 배운 문서 단어 행렬(Document-Term Matrix, DTM)을 생성합니다. DTM에서의 인덱스는 앞서 확인한 word_index의 결과입니다.\n",
    "- 다만 주의할 점은 각 단어에 부여되는 인덱스는 1부터 시작하는 반면에 완성되는 행렬의 인덱스는 0부터 시작합니다. 실제로 단어의 개수는 9개였지만 완성된 행렬의 열의 개수는 10개인 것과 첫번째 열은 모든 행에서 값이 0인 것을 볼 수 있습니다. 인덱스 0에는 그 어떤 단어도 할당되지 않았기 때문입니다.\n",
    "- 네번째 행을 보겠습니다. 네번째 행은 테스트 데이터에서 네번째 문장을 의미합니다. 네번째 행은 8번째 열, 9번째 열, 10번째 열에서 1의 값을 가집니다. 이는 7번 단어, 8번 단어, 9번 단어가 네번째 문장에서 1개씩 존재함을 의미합니다. 위에서 정수 인코딩 된 결과를 보면 7번 단어는 \"저는\", 8번 단어는 \"과일이\", 9번 단어는 \"좋아요\"입니다. 세번째 행의 첫번째 열의 값은 2인데, 이는 세번째 문장에서 1번 인덱스를 가진 바나나가 두 번 등장했기 때문입니다.\n",
    "- 앞서 배웠듯이 DTM은 bag of words를 기반으로 하므로 단어 순서 정보는 보존되지 않습니다. 사실 더 구체적으로는 4개의 모든 모드에서 단어 순서 정보는 보존되지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) `mode=\"tfidf\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "ydGrk7x3_Qg-",
    "outputId": "21ebd6a4-06c5-4176-e691-b105768e4d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.847 0.847 1.099 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.847 0.847 0.847 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    1.435 0.    0.    0.    1.099 1.099 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    1.099 1.099 1.099]]\n"
     ]
    }
   ],
   "source": [
    "#둘째 자리까지 반올림하여 출력합니다.\n",
    "print(tkn.texts_to_matrix(texts, mode=\"tfidf\").round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZnL6_U6x_S8r"
   },
   "source": [
    "- 말 그대로 TF-IDF 행렬을 만듭니다. 다만, TF-IDF 챕터에서 배운 기본식이나 사이킷런의 TfidfVectorizer에서 사용하는 식이랑 또 조금 다릅니다. TF를 각 문서에서의 각 단어의 빈도에 자연 로그를 씌우고 1을 더한 값으로 정의했습니다. IDF에서는 앞서 배운 기본식에서 로그는 자연 로그를 사용하고, 로그 안의 분수에 1을 추가로 더했습니다. 물론, 이러한 식을 굳이 기억할 필요는 없고 여전히 TF-IDF의 기존 의도를 갖고 있다고 이해하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) `mode=\"freq\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "U-i5QahO_TFk",
    "outputId": "a4e7281d-10b1-4319-c440-675b6fb0ba16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.333 0.333 0.333 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.333 0.333 0.333 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.5   0.    0.    0.    0.25  0.25  0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.333 0.333 0.333]]\n"
     ]
    }
   ],
   "source": [
    "#둘째 자리까지 반올림하여 출력합니다.\n",
    "print(tkn.texts_to_matrix(texts, mode=\"freq\").round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0waK4a3_WFH"
   },
   "source": [
    "- 각 문서에서의 각 단어의 등장 횟수를 분자로, 각 문서의 크기(각 문서에서 등장한 모든 단어의 개수의 총 합)를 분모로 하는 표현 방법입니다. 예를 들어 세번째 행을 보겠습니다. 세번째 문장은 \"길고 노란 바나나 바나나\" 였습니다. 문서의 크기는 4인데, 바나나는 총 2회 등장했습니다. 이에 따라서 세번째 문장에서의 단어 \"바나나\"의 값은 위의 행렬에서 0.5가 됩니다. 반면에 \"길고\", \"노란\"이라는 두 단어는 각 1회 등장했으므로 각자 1/4의 값인 0.25의 값을 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyL3hSOoJDzs"
   },
   "source": [
    "# 3. Tensorflow Basics\n",
    "- 딥러닝 실행 순서\n",
    "    1. 전처리: 학습에 필요한 데이터 전처리를 수행합니다.  \n",
    "    2. 모델링(tf.keras.Model): 모델을 정의합니다.  \n",
    "    3. 컴파일(compile): 모델을 생성합니다.  \n",
    "    4. 학습 (fit): 모델을 학습시킵니다.\n",
    "    - 아래는 실제 전처리 - 모델링 - 컴파일 - 학습으로 이어지는 코드를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1by4O49SJcEd",
    "outputId": "810965ac-a988-47d1-bf73-512a6ce2eb9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.000051]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([5.0, 6.0, 7.0, 8.0, 9.0, 10.0], dtype=float)\n",
    "\n",
    "# 모델의 정의 (tf.keras.Modeling)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_shape=(1,), activation=\"relu\"))\n",
    "\n",
    "# 모델의 생성 (compile)\n",
    "model.compile(optimizer=\"sgd\", loss=\"mse\")\n",
    "\n",
    "# 학습 (fit)\n",
    "model.fit(xs, ys, epochs=1200, verbose=0)\n",
    "\n",
    "# 검증\n",
    "# 16.000046\n",
    "model.predict([10.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vloTgnLOBEvj"
   },
   "source": [
    "## 3-1. Linear Regression 구현하기\n",
    "\n",
    "### (1) Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8bT5wwxBKw_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9 samples\n",
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 132ms/sample - loss: 432.2936 - root_mean_squared_error: 20.7917\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.4084 - root_mean_squared_error: 1.5519\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3983 - root_mean_squared_error: 1.5486\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.3886 - root_mean_squared_error: 1.5455\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.3793 - root_mean_squared_error: 1.5425\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3704 - root_mean_squared_error: 1.5396\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3618 - root_mean_squared_error: 1.5368\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.3536 - root_mean_squared_error: 1.5342\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.3458 - root_mean_squared_error: 1.5316\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3383 - root_mean_squared_error: 1.5291\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3311 - root_mean_squared_error: 1.5268\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3242 - root_mean_squared_error: 1.5245\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.3175 - root_mean_squared_error: 1.5223\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.3112 - root_mean_squared_error: 1.5202\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.3050 - root_mean_squared_error: 1.5182\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2992 - root_mean_squared_error: 1.5163\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2935 - root_mean_squared_error: 1.5144\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 996us/sample - loss: 2.2881 - root_mean_squared_error: 1.5127\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2829 - root_mean_squared_error: 1.5109\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2779 - root_mean_squared_error: 1.5093\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2731 - root_mean_squared_error: 1.5077\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.2685 - root_mean_squared_error: 1.5062\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2641 - root_mean_squared_error: 1.5047\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2599 - root_mean_squared_error: 1.5033\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2558 - root_mean_squared_error: 1.5019\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2518 - root_mean_squared_error: 1.5006\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2480 - root_mean_squared_error: 1.4993\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2444 - root_mean_squared_error: 1.4981\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2409 - root_mean_squared_error: 1.4970\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2375 - root_mean_squared_error: 1.4958\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.2343 - root_mean_squared_error: 1.4947\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2312 - root_mean_squared_error: 1.4937\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.2282 - root_mean_squared_error: 1.4927\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2253 - root_mean_squared_error: 1.4917\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.2225 - root_mean_squared_error: 1.4908\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2198 - root_mean_squared_error: 1.4899\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2172 - root_mean_squared_error: 1.4890\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2147 - root_mean_squared_error: 1.4882\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.2123 - root_mean_squared_error: 1.4874\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2100 - root_mean_squared_error: 1.4866\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2078 - root_mean_squared_error: 1.4859\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2056 - root_mean_squared_error: 1.4851\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2036 - root_mean_squared_error: 1.4844\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.2016 - root_mean_squared_error: 1.4838\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1997 - root_mean_squared_error: 1.4831\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1978 - root_mean_squared_error: 1.4825\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1960 - root_mean_squared_error: 1.4819\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1943 - root_mean_squared_error: 1.4813\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1926 - root_mean_squared_error: 1.4808\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1910 - root_mean_squared_error: 1.4802\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1895 - root_mean_squared_error: 1.4797\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1880 - root_mean_squared_error: 1.4792\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1866 - root_mean_squared_error: 1.4787\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1852 - root_mean_squared_error: 1.4782\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1839 - root_mean_squared_error: 1.4778\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1826 - root_mean_squared_error: 1.4774\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1813 - root_mean_squared_error: 1.4769\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1801 - root_mean_squared_error: 1.4765\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1790 - root_mean_squared_error: 1.4761\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1778 - root_mean_squared_error: 1.4758\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1768 - root_mean_squared_error: 1.4754\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1757 - root_mean_squared_error: 1.4750\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1747 - root_mean_squared_error: 1.4747\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1737 - root_mean_squared_error: 1.4744\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1728 - root_mean_squared_error: 1.4740\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1719 - root_mean_squared_error: 1.4737\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1710 - root_mean_squared_error: 1.4734\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1702 - root_mean_squared_error: 1.4732\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1694 - root_mean_squared_error: 1.4729\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1686 - root_mean_squared_error: 1.4726\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1678 - root_mean_squared_error: 1.4724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1671 - root_mean_squared_error: 1.4721\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1664 - root_mean_squared_error: 1.4719\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1657 - root_mean_squared_error: 1.4716\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1651 - root_mean_squared_error: 1.4714\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 887us/sample - loss: 2.1644 - root_mean_squared_error: 1.4712\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1638 - root_mean_squared_error: 1.4710\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1632 - root_mean_squared_error: 1.4708\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1626 - root_mean_squared_error: 1.4706\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1621 - root_mean_squared_error: 1.4704\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1615 - root_mean_squared_error: 1.4702\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1610 - root_mean_squared_error: 1.4700\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1605 - root_mean_squared_error: 1.4699\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1600 - root_mean_squared_error: 1.4697\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1596 - root_mean_squared_error: 1.4695\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1591 - root_mean_squared_error: 1.4694\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1587 - root_mean_squared_error: 1.4692\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1582 - root_mean_squared_error: 1.4691\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1578 - root_mean_squared_error: 1.4690\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1574 - root_mean_squared_error: 1.4688\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1571 - root_mean_squared_error: 1.4687\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1567 - root_mean_squared_error: 1.4686\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1563 - root_mean_squared_error: 1.4684\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1560 - root_mean_squared_error: 1.4683\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1557 - root_mean_squared_error: 1.4682\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1554 - root_mean_squared_error: 1.4681\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1550 - root_mean_squared_error: 1.4680\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1547 - root_mean_squared_error: 1.4679\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1544 - root_mean_squared_error: 1.4678\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1542 - root_mean_squared_error: 1.4677\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1539 - root_mean_squared_error: 1.4676\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1536 - root_mean_squared_error: 1.4675\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1534 - root_mean_squared_error: 1.4674\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1531 - root_mean_squared_error: 1.4674\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1529 - root_mean_squared_error: 1.4673\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1527 - root_mean_squared_error: 1.4672\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1524 - root_mean_squared_error: 1.4671\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1522 - root_mean_squared_error: 1.4671\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1520 - root_mean_squared_error: 1.4670\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1518 - root_mean_squared_error: 1.4669\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1516 - root_mean_squared_error: 1.4668\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1515 - root_mean_squared_error: 1.4668\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1513 - root_mean_squared_error: 1.4667\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1511 - root_mean_squared_error: 1.4667\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1509 - root_mean_squared_error: 1.4666\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1508 - root_mean_squared_error: 1.4666\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1506 - root_mean_squared_error: 1.4665\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 886us/sample - loss: 2.1505 - root_mean_squared_error: 1.4664\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1503 - root_mean_squared_error: 1.4664\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1502 - root_mean_squared_error: 1.4663\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1500 - root_mean_squared_error: 1.4663\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1499 - root_mean_squared_error: 1.4663\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1498 - root_mean_squared_error: 1.4662\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1496 - root_mean_squared_error: 1.4662\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1495 - root_mean_squared_error: 1.4661\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1494 - root_mean_squared_error: 1.4661\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1493 - root_mean_squared_error: 1.4661\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1492 - root_mean_squared_error: 1.4660\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1491 - root_mean_squared_error: 1.4660\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1490 - root_mean_squared_error: 1.4659\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1489 - root_mean_squared_error: 1.4659\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1488 - root_mean_squared_error: 1.4659\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 887us/sample - loss: 2.1487 - root_mean_squared_error: 1.4658\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 886us/sample - loss: 2.1486 - root_mean_squared_error: 1.4658\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1485 - root_mean_squared_error: 1.4658\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1484 - root_mean_squared_error: 1.4658\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1484 - root_mean_squared_error: 1.4657\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1483 - root_mean_squared_error: 1.4657\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1482 - root_mean_squared_error: 1.4657\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1481 - root_mean_squared_error: 1.4657\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1481 - root_mean_squared_error: 1.4656\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1480 - root_mean_squared_error: 1.4656\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1479 - root_mean_squared_error: 1.4656\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1479 - root_mean_squared_error: 1.4656\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1478 - root_mean_squared_error: 1.4655\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1478 - root_mean_squared_error: 1.4655\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1477 - root_mean_squared_error: 1.4655\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1476 - root_mean_squared_error: 1.4655\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1476 - root_mean_squared_error: 1.4655\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1475 - root_mean_squared_error: 1.4654\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1475 - root_mean_squared_error: 1.4654\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1474 - root_mean_squared_error: 1.4654\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1474 - root_mean_squared_error: 1.4654\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1473 - root_mean_squared_error: 1.4654\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1473 - root_mean_squared_error: 1.4654\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1473 - root_mean_squared_error: 1.4654\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 886us/sample - loss: 2.1472 - root_mean_squared_error: 1.4653\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1472 - root_mean_squared_error: 1.4653\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1471 - root_mean_squared_error: 1.4653\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1471 - root_mean_squared_error: 1.4653\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1471 - root_mean_squared_error: 1.4653\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1470 - root_mean_squared_error: 1.4653\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1470 - root_mean_squared_error: 1.4653\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1470 - root_mean_squared_error: 1.4653\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1469 - root_mean_squared_error: 1.4652\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1469 - root_mean_squared_error: 1.4652\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1469 - root_mean_squared_error: 1.4652\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1469 - root_mean_squared_error: 1.4652\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1468 - root_mean_squared_error: 1.4652\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1468 - root_mean_squared_error: 1.4652\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1468 - root_mean_squared_error: 1.4652\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1467 - root_mean_squared_error: 1.4652\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1467 - root_mean_squared_error: 1.4652\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1467 - root_mean_squared_error: 1.4652\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1467 - root_mean_squared_error: 1.4652\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1467 - root_mean_squared_error: 1.4651\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1466 - root_mean_squared_error: 1.4651\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1466 - root_mean_squared_error: 1.4651\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1466 - root_mean_squared_error: 1.4651\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1466 - root_mean_squared_error: 1.4651\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1466 - root_mean_squared_error: 1.4651\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1465 - root_mean_squared_error: 1.4651\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1465 - root_mean_squared_error: 1.4651\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1465 - root_mean_squared_error: 1.4651\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1465 - root_mean_squared_error: 1.4651\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1465 - root_mean_squared_error: 1.4651\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1465 - root_mean_squared_error: 1.4651\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1464 - root_mean_squared_error: 1.4651\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1464 - root_mean_squared_error: 1.4651\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1464 - root_mean_squared_error: 1.4651\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1464 - root_mean_squared_error: 1.4651\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1464 - root_mean_squared_error: 1.4651\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1464 - root_mean_squared_error: 1.4651\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1464 - root_mean_squared_error: 1.4650\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 998us/sample - loss: 2.1464 - root_mean_squared_error: 1.4650\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1463 - root_mean_squared_error: 1.4650\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 212/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1462 - root_mean_squared_error: 1.4650\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4650\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1461 - root_mean_squared_error: 1.4649\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 998us/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 997us/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 1ms/sample - loss: 2.1460 - root_mean_squared_error: 1.4649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d4bd587f48>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([11, 22, 33, 44, 53, 66, 77, 87, 95])\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_shape=(1,), activation=\"linear\"))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01), loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "model.fit(x, y, batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 459.9264 - mse: 459.9264\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.4705 - mse: 2.4705\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.4577 - mse: 2.4577\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.4454 - mse: 2.4454\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.4337 - mse: 2.4337\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.4225 - mse: 2.4225\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.4117 - mse: 2.4117\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.4014 - mse: 2.4014\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 2.3916 - mse: 2.3916\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3821 - mse: 2.3821\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.3731 - mse: 2.3731\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.3645 - mse: 2.3645\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 2.3562 - mse: 2.3562\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3482 - mse: 2.3482\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3406 - mse: 2.3406\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3333 - mse: 2.3333\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.3263 - mse: 2.3263\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.3196 - mse: 2.3196\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3131 - mse: 2.3131\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.3069 - mse: 2.3069\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3010 - mse: 2.3010\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.2953 - mse: 2.2953\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2898 - mse: 2.2898\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2845 - mse: 2.2845\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2795 - mse: 2.2795\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 2.2746 - mse: 2.2746\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2700 - mse: 2.2700\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.2655 - mse: 2.2655\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2612 - mse: 2.2612\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2570 - mse: 2.2570\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2530 - mse: 2.2530\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2492 - mse: 2.2492\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2455 - mse: 2.2455\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2420 - mse: 2.2420\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2386 - mse: 2.2386\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2353 - mse: 2.2353\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.2321 - mse: 2.2321\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2291 - mse: 2.2291\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2262 - mse: 2.2262\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.2233 - mse: 2.2233\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2206 - mse: 2.2206\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2180 - mse: 2.2180\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2155 - mse: 2.2155\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2131 - mse: 2.2131\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.2107 - mse: 2.2107\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.2085 - mse: 2.2085\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2063 - mse: 2.2063\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2042 - mse: 2.2042\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.2022 - mse: 2.2022\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2002 - mse: 2.2002\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1984 - mse: 2.1984\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1966 - mse: 2.1966\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 2.1948 - mse: 2.1948\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1932 - mse: 2.1932\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1915 - mse: 2.1915\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1900 - mse: 2.1900\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1885 - mse: 2.1885\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1870 - mse: 2.1870\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1856 - mse: 2.1856\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1843 - mse: 2.1843\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1830 - mse: 2.1830\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1817 - mse: 2.1817\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1805 - mse: 2.1805\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1793 - mse: 2.1793\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1782 - mse: 2.1782\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1771 - mse: 2.1771\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1760 - mse: 2.1760\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1750 - mse: 2.1750\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1740 - mse: 2.1740\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1731 - mse: 2.1731\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1722 - mse: 2.1722\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1713 - mse: 2.1713\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1705 - mse: 2.1705\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 2.1696 - mse: 2.1696\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 2.1688 - mse: 2.1688\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1681 - mse: 2.1681\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1673 - mse: 2.1673\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1666 - mse: 2.1666\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1659 - mse: 2.1659\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1653 - mse: 2.1653\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1646 - mse: 2.1646\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1640 - mse: 2.1640\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1634 - mse: 2.1634\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1628 - mse: 2.1628\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1622 - mse: 2.1622\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1617 - mse: 2.1617\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1612 - mse: 2.1612\n",
      "Epoch 88/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1607 - mse: 2.1607\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1602 - mse: 2.1602\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1597 - mse: 2.1597\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1592 - mse: 2.1592\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1588 - mse: 2.1588\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1584 - mse: 2.1584\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1580 - mse: 2.1580\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1576 - mse: 2.1576\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1572 - mse: 2.1572\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1568 - mse: 2.1568\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1565 - mse: 2.1565\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1561 - mse: 2.1561\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1558 - mse: 2.1558\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1555 - mse: 2.1555\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1551 - mse: 2.1551\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1548 - mse: 2.1548\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1545 - mse: 2.1545\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1543 - mse: 2.1543\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 2.1540 - mse: 2.1540\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1537 - mse: 2.1537\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1535 - mse: 2.1535\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1532 - mse: 2.1532\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1530 - mse: 2.1530\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1527 - mse: 2.1527\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1525 - mse: 2.1525\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1523 - mse: 2.1523\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1521 - mse: 2.1521\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1519 - mse: 2.1519\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1517 - mse: 2.1517\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1515 - mse: 2.1515\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1513 - mse: 2.1513\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1512 - mse: 2.1512\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1510 - mse: 2.1510\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1508 - mse: 2.1508\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1507 - mse: 2.1507\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1505 - mse: 2.1505\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1504 - mse: 2.1504\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1502 - mse: 2.1502\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1501 - mse: 2.1501\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1499 - mse: 2.1499\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1498 - mse: 2.1498\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1497 - mse: 2.1497\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1496 - mse: 2.1496\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1494 - mse: 2.1494\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1493 - mse: 2.1493\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1492 - mse: 2.1492\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1491 - mse: 2.1491\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1490 - mse: 2.1490\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1489 - mse: 2.1489\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1488 - mse: 2.1488\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1487 - mse: 2.1487\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 2.1486 - mse: 2.1486\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1486 - mse: 2.1486\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1485 - mse: 2.1485\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1484 - mse: 2.1484\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1483 - mse: 2.1483\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1482 - mse: 2.1482\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1482 - mse: 2.1482\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1481 - mse: 2.1481\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1480 - mse: 2.1480\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1480 - mse: 2.1480\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1479 - mse: 2.1479\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1478 - mse: 2.1478\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1478 - mse: 2.1478\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1477 - mse: 2.1477\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1477 - mse: 2.1477\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1476 - mse: 2.1476\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1476 - mse: 2.1476\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1475 - mse: 2.1475\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1475 - mse: 2.1475\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1474 - mse: 2.1474\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1474 - mse: 2.1474\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1473 - mse: 2.1473\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1473 - mse: 2.1473\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1472 - mse: 2.1472\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1472 - mse: 2.1472\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1472 - mse: 2.1472\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1471 - mse: 2.1471\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1471 - mse: 2.1471\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1470 - mse: 2.1470\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1470 - mse: 2.1470\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1470 - mse: 2.1470\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1470 - mse: 2.1470\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1469 - mse: 2.1469\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1469 - mse: 2.1469\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1469 - mse: 2.1469\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1468 - mse: 2.1468\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1468 - mse: 2.1468\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1468 - mse: 2.1468\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1468 - mse: 2.1468\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1467 - mse: 2.1467\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1467 - mse: 2.1467\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1467 - mse: 2.1467\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1467 - mse: 2.1467\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.5262 - mse: 2.526 - 0s 886us/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd6cd94608>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([11, 22, 33, 44, 53, 66, 77, 87, 95])\n",
    "\n",
    "inputs = tf.keras.Input(shape=(1,))\n",
    "outputs = tf.keras.layers.Dense(units=1, activation=\"linear\")(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "model.fit(x, y, batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98.55645]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([9.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VpSK_S5BSsO"
   },
   "source": [
    "## 3-2. Logistic Regression 구현하기\n",
    "\n",
    "### (1) Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2143 - binary_accuracy: 0.9231\n",
      "Epoch 2/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2073 - binary_accuracy: 0.9231\n",
      "Epoch 3/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2042 - binary_accuracy: 0.9231\n",
      "Epoch 4/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2020 - binary_accuracy: 0.9231\n",
      "Epoch 5/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2002 - binary_accuracy: 0.9231\n",
      "Epoch 6/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1984 - binary_accuracy: 0.9231\n",
      "Epoch 7/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1968 - binary_accuracy: 0.9231\n",
      "Epoch 8/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1952 - binary_accuracy: 0.9231\n",
      "Epoch 9/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1936 - binary_accuracy: 0.9231\n",
      "Epoch 10/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1921 - binary_accuracy: 0.9231\n",
      "Epoch 11/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1906 - binary_accuracy: 0.9231\n",
      "Epoch 12/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1891 - binary_accuracy: 0.9231\n",
      "Epoch 13/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1876 - binary_accuracy: 0.9231\n",
      "Epoch 14/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1862 - binary_accuracy: 0.9231\n",
      "Epoch 15/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1848 - binary_accuracy: 0.9231\n",
      "Epoch 16/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1834 - binary_accuracy: 0.9231\n",
      "Epoch 17/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1820 - binary_accuracy: 0.9231\n",
      "Epoch 18/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1807 - binary_accuracy: 0.9231\n",
      "Epoch 19/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1794 - binary_accuracy: 0.9231\n",
      "Epoch 20/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1781 - binary_accuracy: 0.9231\n",
      "Epoch 21/400\n",
      "13/13 [==============================] - 1s 72ms/step - loss: 0.1768 - binary_accuracy: 0.9231\n",
      "Epoch 22/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1755 - binary_accuracy: 0.9231\n",
      "Epoch 23/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1743 - binary_accuracy: 0.9231\n",
      "Epoch 24/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1731 - binary_accuracy: 0.9231\n",
      "Epoch 25/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1719 - binary_accuracy: 0.9231\n",
      "Epoch 26/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1707 - binary_accuracy: 0.9231\n",
      "Epoch 27/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1695 - binary_accuracy: 0.9231\n",
      "Epoch 28/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1684 - binary_accuracy: 0.9231\n",
      "Epoch 29/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1672 - binary_accuracy: 0.9231\n",
      "Epoch 30/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1661 - binary_accuracy: 0.9231\n",
      "Epoch 31/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1650 - binary_accuracy: 0.9231\n",
      "Epoch 32/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1640 - binary_accuracy: 0.9231\n",
      "Epoch 33/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1629 - binary_accuracy: 0.9231\n",
      "Epoch 34/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1619 - binary_accuracy: 0.9231\n",
      "Epoch 35/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1608 - binary_accuracy: 0.9231\n",
      "Epoch 36/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1598 - binary_accuracy: 0.9231\n",
      "Epoch 37/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1588 - binary_accuracy: 0.9231\n",
      "Epoch 38/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1579 - binary_accuracy: 0.9231\n",
      "Epoch 39/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1569 - binary_accuracy: 0.9231\n",
      "Epoch 40/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1559 - binary_accuracy: 0.9231\n",
      "Epoch 41/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1550 - binary_accuracy: 0.9231\n",
      "Epoch 42/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1541 - binary_accuracy: 0.9231\n",
      "Epoch 43/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.1532 - binary_accuracy: 0.9231\n",
      "Epoch 44/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1523 - binary_accuracy: 0.9231\n",
      "Epoch 45/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1514 - binary_accuracy: 0.9231\n",
      "Epoch 46/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1505 - binary_accuracy: 0.9231\n",
      "Epoch 47/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1497 - binary_accuracy: 0.9231\n",
      "Epoch 48/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1488 - binary_accuracy: 0.9231\n",
      "Epoch 49/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1480 - binary_accuracy: 0.9231\n",
      "Epoch 50/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1472 - binary_accuracy: 0.9231\n",
      "Epoch 51/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1463 - binary_accuracy: 0.9231\n",
      "Epoch 52/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1455 - binary_accuracy: 0.9231\n",
      "Epoch 53/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1448 - binary_accuracy: 0.9231\n",
      "Epoch 54/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1440 - binary_accuracy: 0.9231\n",
      "Epoch 55/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1432 - binary_accuracy: 0.9231\n",
      "Epoch 56/400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.1425 - binary_accuracy: 0.9231\n",
      "Epoch 57/400\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.6277e-06 - binary_accuracy: 1.000 - 0s 920us/step - loss: 0.1417 - binary_accuracy: 0.9231\n",
      "Epoch 58/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1410 - binary_accuracy: 0.9231\n",
      "Epoch 59/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1402 - binary_accuracy: 0.9231\n",
      "Epoch 60/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.1395 - binary_accuracy: 0.9231\n",
      "Epoch 61/400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.1388 - binary_accuracy: 0.9231\n",
      "Epoch 62/400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.1381 - binary_accuracy: 0.9231\n",
      "Epoch 63/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1374 - binary_accuracy: 0.9231\n",
      "Epoch 64/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1368 - binary_accuracy: 0.9231\n",
      "Epoch 65/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1361 - binary_accuracy: 0.9231\n",
      "Epoch 66/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1354 - binary_accuracy: 0.9231\n",
      "Epoch 67/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1348 - binary_accuracy: 0.9231\n",
      "Epoch 68/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1341 - binary_accuracy: 0.9231\n",
      "Epoch 69/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1335 - binary_accuracy: 0.9231\n",
      "Epoch 70/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1329 - binary_accuracy: 0.9231\n",
      "Epoch 71/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1323 - binary_accuracy: 0.9231\n",
      "Epoch 72/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1316 - binary_accuracy: 0.9231\n",
      "Epoch 73/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1310 - binary_accuracy: 0.9231\n",
      "Epoch 74/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1304 - binary_accuracy: 0.9231\n",
      "Epoch 75/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1298 - binary_accuracy: 0.9231\n",
      "Epoch 76/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 997us/step - loss: 0.1293 - binary_accuracy: 0.9231\n",
      "Epoch 77/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1287 - binary_accuracy: 0.9231\n",
      "Epoch 78/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1281 - binary_accuracy: 0.9231\n",
      "Epoch 79/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1276 - binary_accuracy: 0.9231\n",
      "Epoch 80/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1270 - binary_accuracy: 0.9231\n",
      "Epoch 81/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1265 - binary_accuracy: 0.9231\n",
      "Epoch 82/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1259 - binary_accuracy: 0.9231\n",
      "Epoch 83/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1254 - binary_accuracy: 0.9231\n",
      "Epoch 84/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1249 - binary_accuracy: 0.9231\n",
      "Epoch 85/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1243 - binary_accuracy: 0.9231\n",
      "Epoch 86/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1238 - binary_accuracy: 0.9231\n",
      "Epoch 87/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1233 - binary_accuracy: 0.9231\n",
      "Epoch 88/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1228 - binary_accuracy: 0.9231\n",
      "Epoch 89/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1223 - binary_accuracy: 0.9231\n",
      "Epoch 90/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1218 - binary_accuracy: 0.9231\n",
      "Epoch 91/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1213 - binary_accuracy: 0.9231\n",
      "Epoch 92/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1208 - binary_accuracy: 0.9231\n",
      "Epoch 93/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1204 - binary_accuracy: 0.9231\n",
      "Epoch 94/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1199 - binary_accuracy: 0.9231\n",
      "Epoch 95/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1194 - binary_accuracy: 0.9231\n",
      "Epoch 96/400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.1190 - binary_accuracy: 0.9231\n",
      "Epoch 97/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1185 - binary_accuracy: 0.9231\n",
      "Epoch 98/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1180 - binary_accuracy: 0.9231\n",
      "Epoch 99/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1176 - binary_accuracy: 0.9231\n",
      "Epoch 100/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1172 - binary_accuracy: 0.9231\n",
      "Epoch 101/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1167 - binary_accuracy: 0.9231\n",
      "Epoch 102/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1163 - binary_accuracy: 0.9231\n",
      "Epoch 103/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1159 - binary_accuracy: 0.9231\n",
      "Epoch 104/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1154 - binary_accuracy: 0.9231\n",
      "Epoch 105/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1150 - binary_accuracy: 0.9231\n",
      "Epoch 106/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1146 - binary_accuracy: 0.9231\n",
      "Epoch 107/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1142 - binary_accuracy: 0.9231\n",
      "Epoch 108/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1138 - binary_accuracy: 0.9231\n",
      "Epoch 109/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1134 - binary_accuracy: 0.9231\n",
      "Epoch 110/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1130 - binary_accuracy: 0.9231\n",
      "Epoch 111/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1126 - binary_accuracy: 0.9231\n",
      "Epoch 112/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1122 - binary_accuracy: 0.9231\n",
      "Epoch 113/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1118 - binary_accuracy: 0.9231\n",
      "Epoch 114/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1114 - binary_accuracy: 0.9231\n",
      "Epoch 115/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1111 - binary_accuracy: 0.9231\n",
      "Epoch 116/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1107 - binary_accuracy: 0.9231\n",
      "Epoch 117/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1103 - binary_accuracy: 0.9231\n",
      "Epoch 118/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1099 - binary_accuracy: 0.9231\n",
      "Epoch 119/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1096 - binary_accuracy: 0.9231\n",
      "Epoch 120/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1092 - binary_accuracy: 0.9231\n",
      "Epoch 121/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1089 - binary_accuracy: 0.9231\n",
      "Epoch 122/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1085 - binary_accuracy: 0.9231\n",
      "Epoch 123/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1082 - binary_accuracy: 0.9231\n",
      "Epoch 124/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1078 - binary_accuracy: 0.9231\n",
      "Epoch 125/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1075 - binary_accuracy: 0.9231\n",
      "Epoch 126/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1071 - binary_accuracy: 0.9231\n",
      "Epoch 127/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1068 - binary_accuracy: 0.9231\n",
      "Epoch 128/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1065 - binary_accuracy: 0.9231\n",
      "Epoch 129/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1061 - binary_accuracy: 0.9231\n",
      "Epoch 130/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1058 - binary_accuracy: 0.9231\n",
      "Epoch 131/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1055 - binary_accuracy: 0.9231\n",
      "Epoch 132/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1051 - binary_accuracy: 0.9231\n",
      "Epoch 133/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1048 - binary_accuracy: 0.9231\n",
      "Epoch 134/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1045 - binary_accuracy: 0.9231\n",
      "Epoch 135/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1042 - binary_accuracy: 0.9231\n",
      "Epoch 136/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1039 - binary_accuracy: 0.9231\n",
      "Epoch 137/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1036 - binary_accuracy: 0.9231\n",
      "Epoch 138/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1033 - binary_accuracy: 0.9231\n",
      "Epoch 139/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1030 - binary_accuracy: 0.9231\n",
      "Epoch 140/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1027 - binary_accuracy: 0.9231\n",
      "Epoch 141/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1024 - binary_accuracy: 0.9231\n",
      "Epoch 142/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1021 - binary_accuracy: 0.9231\n",
      "Epoch 143/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1018 - binary_accuracy: 0.9231\n",
      "Epoch 144/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1015 - binary_accuracy: 0.9231\n",
      "Epoch 145/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1012 - binary_accuracy: 0.9231\n",
      "Epoch 146/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1009 - binary_accuracy: 0.9231\n",
      "Epoch 147/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1006 - binary_accuracy: 0.9231\n",
      "Epoch 148/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1004 - binary_accuracy: 0.9231\n",
      "Epoch 149/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1001 - binary_accuracy: 0.9231\n",
      "Epoch 150/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0998 - binary_accuracy: 0.9231\n",
      "Epoch 151/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0995 - binary_accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0993 - binary_accuracy: 0.9231\n",
      "Epoch 153/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0990 - binary_accuracy: 0.9231\n",
      "Epoch 154/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0987 - binary_accuracy: 0.9231\n",
      "Epoch 155/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0984 - binary_accuracy: 0.9231\n",
      "Epoch 156/400\n",
      "13/13 [==============================] - 0s 843us/step - loss: 0.0982 - binary_accuracy: 0.9231\n",
      "Epoch 157/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0979 - binary_accuracy: 0.9231\n",
      "Epoch 158/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.0977 - binary_accuracy: 0.9231\n",
      "Epoch 159/400\n",
      "13/13 [==============================] - ETA: 0s - loss: 7.4143e-08 - binary_accuracy: 1.000 - 0s 997us/step - loss: 0.0974 - binary_accuracy: 0.9231\n",
      "Epoch 160/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0972 - binary_accuracy: 0.9231\n",
      "Epoch 161/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0969 - binary_accuracy: 0.9231\n",
      "Epoch 162/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0966 - binary_accuracy: 0.9231\n",
      "Epoch 163/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0964 - binary_accuracy: 0.9231\n",
      "Epoch 164/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0962 - binary_accuracy: 0.9231\n",
      "Epoch 165/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0959 - binary_accuracy: 0.9231\n",
      "Epoch 166/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0957 - binary_accuracy: 0.9231\n",
      "Epoch 167/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0954 - binary_accuracy: 0.9231\n",
      "Epoch 168/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0952 - binary_accuracy: 0.9231\n",
      "Epoch 169/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0949 - binary_accuracy: 0.9231\n",
      "Epoch 170/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0947 - binary_accuracy: 0.9231\n",
      "Epoch 171/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0945 - binary_accuracy: 0.9231\n",
      "Epoch 172/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0942 - binary_accuracy: 0.9231\n",
      "Epoch 173/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0940 - binary_accuracy: 0.9231\n",
      "Epoch 174/400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.0938 - binary_accuracy: 0.9231\n",
      "Epoch 175/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.0936 - binary_accuracy: 0.9231\n",
      "Epoch 176/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0933 - binary_accuracy: 0.9231\n",
      "Epoch 177/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0931 - binary_accuracy: 0.9231\n",
      "Epoch 178/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0929 - binary_accuracy: 0.9231\n",
      "Epoch 179/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0927 - binary_accuracy: 0.9231\n",
      "Epoch 180/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0924 - binary_accuracy: 0.9231\n",
      "Epoch 181/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0922 - binary_accuracy: 0.9231\n",
      "Epoch 182/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0920 - binary_accuracy: 0.9231\n",
      "Epoch 183/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0918 - binary_accuracy: 0.9231\n",
      "Epoch 184/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0916 - binary_accuracy: 0.9231\n",
      "Epoch 185/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0914 - binary_accuracy: 0.9231\n",
      "Epoch 186/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0912 - binary_accuracy: 0.9231\n",
      "Epoch 187/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0909 - binary_accuracy: 0.9231\n",
      "Epoch 188/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0907 - binary_accuracy: 0.9231\n",
      "Epoch 189/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0905 - binary_accuracy: 0.9231\n",
      "Epoch 190/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0903 - binary_accuracy: 0.9231\n",
      "Epoch 191/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0901 - binary_accuracy: 0.9231\n",
      "Epoch 192/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0899 - binary_accuracy: 0.9231\n",
      "Epoch 193/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0897 - binary_accuracy: 1.0000\n",
      "Epoch 194/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0895 - binary_accuracy: 1.0000\n",
      "Epoch 195/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0893 - binary_accuracy: 1.0000\n",
      "Epoch 196/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0891 - binary_accuracy: 1.0000\n",
      "Epoch 197/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0889 - binary_accuracy: 1.0000\n",
      "Epoch 198/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0887 - binary_accuracy: 1.0000\n",
      "Epoch 199/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0885 - binary_accuracy: 1.0000\n",
      "Epoch 200/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0884 - binary_accuracy: 1.0000\n",
      "Epoch 201/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0882 - binary_accuracy: 1.0000\n",
      "Epoch 202/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0880 - binary_accuracy: 1.0000\n",
      "Epoch 203/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0878 - binary_accuracy: 1.0000\n",
      "Epoch 204/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0876 - binary_accuracy: 1.0000\n",
      "Epoch 205/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0874 - binary_accuracy: 1.0000\n",
      "Epoch 206/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0872 - binary_accuracy: 1.0000\n",
      "Epoch 207/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0870 - binary_accuracy: 1.0000\n",
      "Epoch 208/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0869 - binary_accuracy: 1.0000\n",
      "Epoch 209/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0867 - binary_accuracy: 1.0000\n",
      "Epoch 210/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0865 - binary_accuracy: 1.0000\n",
      "Epoch 211/400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.0863 - binary_accuracy: 1.0000\n",
      "Epoch 212/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0861 - binary_accuracy: 1.0000\n",
      "Epoch 213/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0860 - binary_accuracy: 1.0000\n",
      "Epoch 214/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0858 - binary_accuracy: 1.0000\n",
      "Epoch 215/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0856 - binary_accuracy: 1.0000\n",
      "Epoch 216/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0854 - binary_accuracy: 1.0000\n",
      "Epoch 217/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0853 - binary_accuracy: 1.0000\n",
      "Epoch 218/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0851 - binary_accuracy: 1.0000\n",
      "Epoch 219/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0849 - binary_accuracy: 1.0000\n",
      "Epoch 220/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0848 - binary_accuracy: 1.0000\n",
      "Epoch 221/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0846 - binary_accuracy: 1.0000\n",
      "Epoch 222/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0844 - binary_accuracy: 1.0000\n",
      "Epoch 223/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0843 - binary_accuracy: 1.0000\n",
      "Epoch 224/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0841 - binary_accuracy: 1.0000\n",
      "Epoch 225/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0839 - binary_accuracy: 1.0000\n",
      "Epoch 226/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 998us/step - loss: 0.0838 - binary_accuracy: 1.0000\n",
      "Epoch 227/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0836 - binary_accuracy: 1.0000\n",
      "Epoch 228/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0834 - binary_accuracy: 1.0000\n",
      "Epoch 229/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0833 - binary_accuracy: 1.0000\n",
      "Epoch 230/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0831 - binary_accuracy: 1.0000\n",
      "Epoch 231/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0830 - binary_accuracy: 1.0000\n",
      "Epoch 232/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0828 - binary_accuracy: 1.0000\n",
      "Epoch 233/400\n",
      "13/13 [==============================] - 0s 996us/step - loss: 0.0826 - binary_accuracy: 1.0000\n",
      "Epoch 234/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0825 - binary_accuracy: 1.0000\n",
      "Epoch 235/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0823 - binary_accuracy: 1.0000\n",
      "Epoch 236/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0822 - binary_accuracy: 1.0000\n",
      "Epoch 237/400\n",
      "13/13 [==============================] - ETA: 0s - loss: 7.5067e-09 - binary_accuracy: 1.000 - 0s 920us/step - loss: 0.0820 - binary_accuracy: 1.0000\n",
      "Epoch 238/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0819 - binary_accuracy: 1.0000\n",
      "Epoch 239/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0817 - binary_accuracy: 1.0000\n",
      "Epoch 240/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0816 - binary_accuracy: 1.0000\n",
      "Epoch 241/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0814 - binary_accuracy: 1.0000\n",
      "Epoch 242/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0813 - binary_accuracy: 1.0000\n",
      "Epoch 243/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0811 - binary_accuracy: 1.0000\n",
      "Epoch 244/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0810 - binary_accuracy: 1.0000\n",
      "Epoch 245/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0808 - binary_accuracy: 1.0000\n",
      "Epoch 246/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0807 - binary_accuracy: 1.0000\n",
      "Epoch 247/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0805 - binary_accuracy: 1.0000\n",
      "Epoch 248/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0804 - binary_accuracy: 1.0000\n",
      "Epoch 249/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0803 - binary_accuracy: 1.0000\n",
      "Epoch 250/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0801 - binary_accuracy: 1.0000\n",
      "Epoch 251/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0800 - binary_accuracy: 1.0000\n",
      "Epoch 252/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0798 - binary_accuracy: 1.0000\n",
      "Epoch 253/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0797 - binary_accuracy: 1.0000\n",
      "Epoch 254/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.0795 - binary_accuracy: 1.0000\n",
      "Epoch 255/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0794 - binary_accuracy: 1.0000\n",
      "Epoch 256/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0793 - binary_accuracy: 1.0000\n",
      "Epoch 257/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0791 - binary_accuracy: 1.0000\n",
      "Epoch 258/400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.0790 - binary_accuracy: 1.0000\n",
      "Epoch 259/400\n",
      "13/13 [==============================] - 0s 922us/step - loss: 0.0789 - binary_accuracy: 1.0000\n",
      "Epoch 260/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0787 - binary_accuracy: 1.0000\n",
      "Epoch 261/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0786 - binary_accuracy: 1.0000\n",
      "Epoch 262/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0785 - binary_accuracy: 1.0000\n",
      "Epoch 263/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.0783 - binary_accuracy: 1.0000\n",
      "Epoch 264/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0782 - binary_accuracy: 1.0000\n",
      "Epoch 265/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0781 - binary_accuracy: 1.0000\n",
      "Epoch 266/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0779 - binary_accuracy: 1.0000\n",
      "Epoch 267/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0778 - binary_accuracy: 1.0000\n",
      "Epoch 268/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0777 - binary_accuracy: 1.0000\n",
      "Epoch 269/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0775 - binary_accuracy: 1.0000\n",
      "Epoch 270/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0774 - binary_accuracy: 1.0000\n",
      "Epoch 271/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0773 - binary_accuracy: 1.0000\n",
      "Epoch 272/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0771 - binary_accuracy: 1.0000\n",
      "Epoch 273/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0770 - binary_accuracy: 1.0000\n",
      "Epoch 274/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0769 - binary_accuracy: 1.0000\n",
      "Epoch 275/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0768 - binary_accuracy: 1.0000\n",
      "Epoch 276/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0766 - binary_accuracy: 1.0000\n",
      "Epoch 277/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0765 - binary_accuracy: 1.0000\n",
      "Epoch 278/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0764 - binary_accuracy: 1.0000\n",
      "Epoch 279/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0763 - binary_accuracy: 1.0000\n",
      "Epoch 280/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0761 - binary_accuracy: 1.0000\n",
      "Epoch 281/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0760 - binary_accuracy: 1.0000\n",
      "Epoch 282/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0759 - binary_accuracy: 1.0000\n",
      "Epoch 283/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0758 - binary_accuracy: 1.0000\n",
      "Epoch 284/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0757 - binary_accuracy: 1.0000\n",
      "Epoch 285/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0755 - binary_accuracy: 1.0000\n",
      "Epoch 286/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0754 - binary_accuracy: 1.0000\n",
      "Epoch 287/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0753 - binary_accuracy: 1.0000\n",
      "Epoch 288/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0752 - binary_accuracy: 1.0000\n",
      "Epoch 289/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0751 - binary_accuracy: 1.0000\n",
      "Epoch 290/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0749 - binary_accuracy: 1.0000\n",
      "Epoch 291/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0748 - binary_accuracy: 1.0000\n",
      "Epoch 292/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0747 - binary_accuracy: 1.0000\n",
      "Epoch 293/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0746 - binary_accuracy: 1.0000\n",
      "Epoch 294/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0745 - binary_accuracy: 1.0000\n",
      "Epoch 295/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0744 - binary_accuracy: 1.0000\n",
      "Epoch 296/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0743 - binary_accuracy: 1.0000\n",
      "Epoch 297/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0741 - binary_accuracy: 1.0000\n",
      "Epoch 298/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0740 - binary_accuracy: 1.0000\n",
      "Epoch 299/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0739 - binary_accuracy: 1.0000\n",
      "Epoch 300/400\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4916e-09 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.0738 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0737 - binary_accuracy: 1.0000\n",
      "Epoch 302/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0736 - binary_accuracy: 1.0000\n",
      "Epoch 303/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0735 - binary_accuracy: 1.0000\n",
      "Epoch 304/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0734 - binary_accuracy: 1.0000\n",
      "Epoch 305/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0732 - binary_accuracy: 1.0000\n",
      "Epoch 306/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0731 - binary_accuracy: 1.0000\n",
      "Epoch 307/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0730 - binary_accuracy: 1.0000\n",
      "Epoch 308/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0729 - binary_accuracy: 1.0000\n",
      "Epoch 309/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0728 - binary_accuracy: 1.0000\n",
      "Epoch 310/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0727 - binary_accuracy: 1.0000\n",
      "Epoch 311/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0726 - binary_accuracy: 1.0000\n",
      "Epoch 312/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0725 - binary_accuracy: 1.0000\n",
      "Epoch 313/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0724 - binary_accuracy: 1.0000\n",
      "Epoch 314/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0723 - binary_accuracy: 1.0000\n",
      "Epoch 315/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0722 - binary_accuracy: 1.0000\n",
      "Epoch 316/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0721 - binary_accuracy: 1.0000\n",
      "Epoch 317/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0720 - binary_accuracy: 1.0000\n",
      "Epoch 318/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0719 - binary_accuracy: 1.0000\n",
      "Epoch 319/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0718 - binary_accuracy: 1.0000\n",
      "Epoch 320/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0717 - binary_accuracy: 1.0000\n",
      "Epoch 321/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0716 - binary_accuracy: 1.0000\n",
      "Epoch 322/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0715 - binary_accuracy: 1.0000\n",
      "Epoch 323/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0713 - binary_accuracy: 1.0000\n",
      "Epoch 324/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0712 - binary_accuracy: 1.0000\n",
      "Epoch 325/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0711 - binary_accuracy: 1.0000\n",
      "Epoch 326/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0710 - binary_accuracy: 1.0000\n",
      "Epoch 327/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0709 - binary_accuracy: 1.0000\n",
      "Epoch 328/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0708 - binary_accuracy: 1.0000\n",
      "Epoch 329/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0707 - binary_accuracy: 1.0000\n",
      "Epoch 330/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0706 - binary_accuracy: 1.0000\n",
      "Epoch 331/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0706 - binary_accuracy: 1.0000\n",
      "Epoch 332/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0705 - binary_accuracy: 1.0000\n",
      "Epoch 333/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0704 - binary_accuracy: 1.0000\n",
      "Epoch 334/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0703 - binary_accuracy: 1.0000\n",
      "Epoch 335/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0702 - binary_accuracy: 1.0000\n",
      "Epoch 336/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0701 - binary_accuracy: 1.0000\n",
      "Epoch 337/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0700 - binary_accuracy: 1.0000\n",
      "Epoch 338/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0699 - binary_accuracy: 1.0000\n",
      "Epoch 339/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0698 - binary_accuracy: 1.0000\n",
      "Epoch 340/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0697 - binary_accuracy: 1.0000\n",
      "Epoch 341/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0696 - binary_accuracy: 1.0000\n",
      "Epoch 342/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0695 - binary_accuracy: 1.0000\n",
      "Epoch 343/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0694 - binary_accuracy: 1.0000\n",
      "Epoch 344/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0693 - binary_accuracy: 1.0000\n",
      "Epoch 345/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0692 - binary_accuracy: 1.0000\n",
      "Epoch 346/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0691 - binary_accuracy: 1.0000\n",
      "Epoch 347/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0690 - binary_accuracy: 1.0000\n",
      "Epoch 348/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0689 - binary_accuracy: 1.0000\n",
      "Epoch 349/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0688 - binary_accuracy: 1.0000\n",
      "Epoch 350/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0688 - binary_accuracy: 1.0000\n",
      "Epoch 351/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0687 - binary_accuracy: 1.0000\n",
      "Epoch 352/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0686 - binary_accuracy: 1.0000\n",
      "Epoch 353/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0685 - binary_accuracy: 1.0000\n",
      "Epoch 354/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0684 - binary_accuracy: 1.0000\n",
      "Epoch 355/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0683 - binary_accuracy: 1.0000\n",
      "Epoch 356/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0682 - binary_accuracy: 1.0000\n",
      "Epoch 357/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0681 - binary_accuracy: 1.0000\n",
      "Epoch 358/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0680 - binary_accuracy: 1.0000\n",
      "Epoch 359/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0679 - binary_accuracy: 1.0000\n",
      "Epoch 360/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0679 - binary_accuracy: 1.0000\n",
      "Epoch 361/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0678 - binary_accuracy: 1.0000\n",
      "Epoch 362/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0677 - binary_accuracy: 1.0000\n",
      "Epoch 363/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0676 - binary_accuracy: 1.0000\n",
      "Epoch 364/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0675 - binary_accuracy: 1.0000\n",
      "Epoch 365/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0674 - binary_accuracy: 1.0000\n",
      "Epoch 366/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0673 - binary_accuracy: 1.0000\n",
      "Epoch 367/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0673 - binary_accuracy: 1.0000\n",
      "Epoch 368/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0672 - binary_accuracy: 1.0000\n",
      "Epoch 369/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0671 - binary_accuracy: 1.0000\n",
      "Epoch 370/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0670 - binary_accuracy: 1.0000\n",
      "Epoch 371/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0669 - binary_accuracy: 1.0000\n",
      "Epoch 372/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0668 - binary_accuracy: 1.0000\n",
      "Epoch 373/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0667 - binary_accuracy: 1.0000\n",
      "Epoch 374/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0667 - binary_accuracy: 1.0000\n",
      "Epoch 375/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0666 - binary_accuracy: 1.0000\n",
      "Epoch 376/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0665 - binary_accuracy: 1.0000\n",
      "Epoch 377/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0664 - binary_accuracy: 1.0000\n",
      "Epoch 378/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0663 - binary_accuracy: 1.0000\n",
      "Epoch 379/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0662 - binary_accuracy: 1.0000\n",
      "Epoch 380/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0662 - binary_accuracy: 1.0000\n",
      "Epoch 381/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0661 - binary_accuracy: 1.0000\n",
      "Epoch 382/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0660 - binary_accuracy: 1.0000\n",
      "Epoch 383/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0659 - binary_accuracy: 1.0000\n",
      "Epoch 384/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0658 - binary_accuracy: 1.0000\n",
      "Epoch 385/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0658 - binary_accuracy: 1.0000\n",
      "Epoch 386/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0657 - binary_accuracy: 1.0000\n",
      "Epoch 387/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0656 - binary_accuracy: 1.0000\n",
      "Epoch 388/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0655 - binary_accuracy: 1.0000\n",
      "Epoch 389/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0654 - binary_accuracy: 1.0000\n",
      "Epoch 390/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0654 - binary_accuracy: 1.0000\n",
      "Epoch 391/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0653 - binary_accuracy: 1.0000\n",
      "Epoch 392/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0652 - binary_accuracy: 1.0000\n",
      "Epoch 393/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0651 - binary_accuracy: 1.0000\n",
      "Epoch 394/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0650 - binary_accuracy: 1.0000\n",
      "Epoch 395/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0650 - binary_accuracy: 1.0000\n",
      "Epoch 396/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0649 - binary_accuracy: 1.0000\n",
      "Epoch 397/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0648 - binary_accuracy: 1.0000\n",
      "Epoch 398/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0647 - binary_accuracy: 1.0000\n",
      "Epoch 399/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0647 - binary_accuracy: 1.0000\n",
      "Epoch 400/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0646 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd701ca5c8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([-50, -40, -30, -20, -10, -5, 0, 5, 10, 20, 30, 40, 50])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]) #숫자 10부터 1\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_shape=(1,), activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n",
    "\n",
    "model.fit(x, y, batch_size=1, epochs=400, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uooupQZfBdmc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.2075 - binary_accuracy: 0.9231\n",
      "Epoch 2/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.2054 - binary_accuracy: 0.9231\n",
      "Epoch 3/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.2035 - binary_accuracy: 0.9231\n",
      "Epoch 4/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2017 - binary_accuracy: 0.9231\n",
      "Epoch 5/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.2000 - binary_accuracy: 0.9231\n",
      "Epoch 6/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1984 - binary_accuracy: 0.9231\n",
      "Epoch 7/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1968 - binary_accuracy: 0.9231\n",
      "Epoch 8/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1952 - binary_accuracy: 0.9231\n",
      "Epoch 9/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1936 - binary_accuracy: 0.9231\n",
      "Epoch 10/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1921 - binary_accuracy: 0.9231\n",
      "Epoch 11/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1906 - binary_accuracy: 0.9231\n",
      "Epoch 12/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1891 - binary_accuracy: 0.9231\n",
      "Epoch 13/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1877 - binary_accuracy: 0.9231\n",
      "Epoch 14/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1862 - binary_accuracy: 0.9231\n",
      "Epoch 15/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1848 - binary_accuracy: 0.9231\n",
      "Epoch 16/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1834 - binary_accuracy: 0.9231\n",
      "Epoch 17/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1821 - binary_accuracy: 0.9231\n",
      "Epoch 18/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1807 - binary_accuracy: 0.9231\n",
      "Epoch 19/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1794 - binary_accuracy: 0.9231\n",
      "Epoch 20/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1781 - binary_accuracy: 0.9231\n",
      "Epoch 21/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1768 - binary_accuracy: 0.9231\n",
      "Epoch 22/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1756 - binary_accuracy: 0.9231\n",
      "Epoch 23/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1743 - binary_accuracy: 0.9231\n",
      "Epoch 24/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1731 - binary_accuracy: 0.9231\n",
      "Epoch 25/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1719 - binary_accuracy: 0.9231\n",
      "Epoch 26/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1707 - binary_accuracy: 0.9231\n",
      "Epoch 27/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1696 - binary_accuracy: 0.9231\n",
      "Epoch 28/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1684 - binary_accuracy: 0.9231\n",
      "Epoch 29/400\n",
      "13/13 [==============================] - 0s 767us/step - loss: 0.1673 - binary_accuracy: 0.9231\n",
      "Epoch 30/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1662 - binary_accuracy: 0.9231\n",
      "Epoch 31/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1651 - binary_accuracy: 0.9231\n",
      "Epoch 32/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1640 - binary_accuracy: 0.9231\n",
      "Epoch 33/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1629 - binary_accuracy: 0.9231\n",
      "Epoch 34/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1619 - binary_accuracy: 0.9231\n",
      "Epoch 35/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1609 - binary_accuracy: 0.9231\n",
      "Epoch 36/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1599 - binary_accuracy: 0.9231\n",
      "Epoch 37/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1589 - binary_accuracy: 0.9231\n",
      "Epoch 38/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1579 - binary_accuracy: 0.9231\n",
      "Epoch 39/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1569 - binary_accuracy: 0.9231\n",
      "Epoch 40/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1560 - binary_accuracy: 0.9231\n",
      "Epoch 41/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1550 - binary_accuracy: 0.9231\n",
      "Epoch 42/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1541 - binary_accuracy: 0.9231\n",
      "Epoch 43/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1532 - binary_accuracy: 0.9231\n",
      "Epoch 44/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1523 - binary_accuracy: 0.9231\n",
      "Epoch 45/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1514 - binary_accuracy: 0.9231\n",
      "Epoch 46/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1505 - binary_accuracy: 0.9231\n",
      "Epoch 47/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1497 - binary_accuracy: 0.9231\n",
      "Epoch 48/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1488 - binary_accuracy: 0.9231\n",
      "Epoch 49/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1480 - binary_accuracy: 0.9231\n",
      "Epoch 50/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1472 - binary_accuracy: 0.9231\n",
      "Epoch 51/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1464 - binary_accuracy: 0.9231\n",
      "Epoch 52/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1456 - binary_accuracy: 0.9231\n",
      "Epoch 53/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1448 - binary_accuracy: 0.9231\n",
      "Epoch 54/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1440 - binary_accuracy: 0.9231\n",
      "Epoch 55/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1432 - binary_accuracy: 0.9231\n",
      "Epoch 56/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1425 - binary_accuracy: 0.9231\n",
      "Epoch 57/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1417 - binary_accuracy: 0.9231\n",
      "Epoch 58/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1410 - binary_accuracy: 0.9231\n",
      "Epoch 59/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1403 - binary_accuracy: 0.9231\n",
      "Epoch 60/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1396 - binary_accuracy: 0.9231\n",
      "Epoch 61/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1389 - binary_accuracy: 0.9231\n",
      "Epoch 62/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1382 - binary_accuracy: 0.9231\n",
      "Epoch 63/400\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.1077e-06 - binary_accuracy: 1.000 - 0s 1ms/step - loss: 0.1375 - binary_accuracy: 0.9231\n",
      "Epoch 64/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1368 - binary_accuracy: 0.9231\n",
      "Epoch 65/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1361 - binary_accuracy: 0.9231\n",
      "Epoch 66/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1355 - binary_accuracy: 0.9231\n",
      "Epoch 67/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1348 - binary_accuracy: 0.9231\n",
      "Epoch 68/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1342 - binary_accuracy: 0.9231\n",
      "Epoch 69/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.1335 - binary_accuracy: 0.9231\n",
      "Epoch 70/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1329 - binary_accuracy: 0.9231\n",
      "Epoch 71/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1323 - binary_accuracy: 0.9231\n",
      "Epoch 72/400\n",
      "13/13 [==============================] - 0s 767us/step - loss: 0.1317 - binary_accuracy: 0.9231\n",
      "Epoch 73/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1311 - binary_accuracy: 0.9231\n",
      "Epoch 74/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9231\n",
      "Epoch 75/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1299 - binary_accuracy: 0.9231\n",
      "Epoch 76/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 921us/step - loss: 0.1293 - binary_accuracy: 0.9231\n",
      "Epoch 77/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1287 - binary_accuracy: 0.9231\n",
      "Epoch 78/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1281 - binary_accuracy: 0.9231\n",
      "Epoch 79/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1276 - binary_accuracy: 0.9231\n",
      "Epoch 80/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1270 - binary_accuracy: 0.9231\n",
      "Epoch 81/400\n",
      "13/13 [==============================] - 0s 996us/step - loss: 0.1265 - binary_accuracy: 0.9231\n",
      "Epoch 82/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1259 - binary_accuracy: 0.9231\n",
      "Epoch 83/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1254 - binary_accuracy: 0.9231\n",
      "Epoch 84/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1249 - binary_accuracy: 0.9231\n",
      "Epoch 85/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1243 - binary_accuracy: 0.9231\n",
      "Epoch 86/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1238 - binary_accuracy: 0.9231\n",
      "Epoch 87/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1233 - binary_accuracy: 0.9231\n",
      "Epoch 88/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1228 - binary_accuracy: 0.9231\n",
      "Epoch 89/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1223 - binary_accuracy: 0.9231\n",
      "Epoch 90/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1218 - binary_accuracy: 0.9231\n",
      "Epoch 91/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.1213 - binary_accuracy: 0.9231\n",
      "Epoch 92/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1208 - binary_accuracy: 0.9231\n",
      "Epoch 93/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1204 - binary_accuracy: 0.9231\n",
      "Epoch 94/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1199 - binary_accuracy: 0.9231\n",
      "Epoch 95/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1194 - binary_accuracy: 0.9231\n",
      "Epoch 96/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1190 - binary_accuracy: 0.9231\n",
      "Epoch 97/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1185 - binary_accuracy: 0.9231\n",
      "Epoch 98/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1181 - binary_accuracy: 0.9231\n",
      "Epoch 99/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1176 - binary_accuracy: 0.9231\n",
      "Epoch 100/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1172 - binary_accuracy: 0.9231\n",
      "Epoch 101/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1167 - binary_accuracy: 0.9231\n",
      "Epoch 102/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1163 - binary_accuracy: 0.9231\n",
      "Epoch 103/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1159 - binary_accuracy: 0.9231\n",
      "Epoch 104/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1155 - binary_accuracy: 0.9231\n",
      "Epoch 105/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1150 - binary_accuracy: 0.9231\n",
      "Epoch 106/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1146 - binary_accuracy: 0.9231\n",
      "Epoch 107/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1142 - binary_accuracy: 0.9231\n",
      "Epoch 108/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1138 - binary_accuracy: 0.9231\n",
      "Epoch 109/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1134 - binary_accuracy: 0.9231\n",
      "Epoch 110/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1130 - binary_accuracy: 0.9231\n",
      "Epoch 111/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1126 - binary_accuracy: 0.9231\n",
      "Epoch 112/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1122 - binary_accuracy: 0.9231\n",
      "Epoch 113/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1118 - binary_accuracy: 0.9231\n",
      "Epoch 114/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.1114 - binary_accuracy: 0.9231\n",
      "Epoch 115/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1111 - binary_accuracy: 0.9231\n",
      "Epoch 116/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1107 - binary_accuracy: 0.9231\n",
      "Epoch 117/400\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.9953e-07 - binary_accuracy: 1.000 - 0s 1ms/step - loss: 0.1103 - binary_accuracy: 0.9231\n",
      "Epoch 118/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1100 - binary_accuracy: 0.9231\n",
      "Epoch 119/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.1096 - binary_accuracy: 0.9231\n",
      "Epoch 120/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1092 - binary_accuracy: 0.9231\n",
      "Epoch 121/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1089 - binary_accuracy: 0.9231\n",
      "Epoch 122/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1085 - binary_accuracy: 0.9231\n",
      "Epoch 123/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1082 - binary_accuracy: 0.9231\n",
      "Epoch 124/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1078 - binary_accuracy: 0.9231\n",
      "Epoch 125/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1075 - binary_accuracy: 0.9231\n",
      "Epoch 126/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1071 - binary_accuracy: 0.9231\n",
      "Epoch 127/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1068 - binary_accuracy: 0.9231\n",
      "Epoch 128/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1065 - binary_accuracy: 0.9231\n",
      "Epoch 129/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1061 - binary_accuracy: 0.9231\n",
      "Epoch 130/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1058 - binary_accuracy: 0.9231\n",
      "Epoch 131/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1055 - binary_accuracy: 0.9231\n",
      "Epoch 132/400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.1052 - binary_accuracy: 0.9231\n",
      "Epoch 133/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1048 - binary_accuracy: 0.9231\n",
      "Epoch 134/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1045 - binary_accuracy: 0.9231\n",
      "Epoch 135/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1042 - binary_accuracy: 0.9231\n",
      "Epoch 136/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1039 - binary_accuracy: 0.9231\n",
      "Epoch 137/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1036 - binary_accuracy: 0.9231\n",
      "Epoch 138/400\n",
      "13/13 [==============================] - 0s 998us/step - loss: 0.1033 - binary_accuracy: 0.9231\n",
      "Epoch 139/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1030 - binary_accuracy: 0.9231\n",
      "Epoch 140/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1027 - binary_accuracy: 0.9231\n",
      "Epoch 141/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1024 - binary_accuracy: 0.9231\n",
      "Epoch 142/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1021 - binary_accuracy: 0.9231\n",
      "Epoch 143/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1018 - binary_accuracy: 0.9231\n",
      "Epoch 144/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1015 - binary_accuracy: 0.9231\n",
      "Epoch 145/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.1012 - binary_accuracy: 0.9231\n",
      "Epoch 146/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1009 - binary_accuracy: 0.9231\n",
      "Epoch 147/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.1006 - binary_accuracy: 0.9231\n",
      "Epoch 148/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.1004 - binary_accuracy: 0.9231\n",
      "Epoch 149/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.1001 - binary_accuracy: 0.9231\n",
      "Epoch 150/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 998us/step - loss: 0.0998 - binary_accuracy: 0.9231\n",
      "Epoch 151/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0995 - binary_accuracy: 0.9231\n",
      "Epoch 152/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0993 - binary_accuracy: 0.9231\n",
      "Epoch 153/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.0990 - binary_accuracy: 0.9231\n",
      "Epoch 154/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0987 - binary_accuracy: 0.9231\n",
      "Epoch 155/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0985 - binary_accuracy: 0.9231\n",
      "Epoch 156/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0982 - binary_accuracy: 0.9231\n",
      "Epoch 157/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0979 - binary_accuracy: 0.9231\n",
      "Epoch 158/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0977 - binary_accuracy: 0.9231\n",
      "Epoch 159/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0974 - binary_accuracy: 0.9231\n",
      "Epoch 160/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0972 - binary_accuracy: 0.9231\n",
      "Epoch 161/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.0969 - binary_accuracy: 0.9231\n",
      "Epoch 162/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0967 - binary_accuracy: 0.9231\n",
      "Epoch 163/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.0964 - binary_accuracy: 0.9231\n",
      "Epoch 164/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0962 - binary_accuracy: 0.9231\n",
      "Epoch 165/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0959 - binary_accuracy: 0.9231\n",
      "Epoch 166/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0957 - binary_accuracy: 0.9231\n",
      "Epoch 167/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0954 - binary_accuracy: 0.9231\n",
      "Epoch 168/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0952 - binary_accuracy: 0.9231\n",
      "Epoch 169/400\n",
      "13/13 [==============================] - 0s 995us/step - loss: 0.0950 - binary_accuracy: 0.9231\n",
      "Epoch 170/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0947 - binary_accuracy: 0.9231\n",
      "Epoch 171/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0945 - binary_accuracy: 0.9231\n",
      "Epoch 172/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0942 - binary_accuracy: 0.9231\n",
      "Epoch 173/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0940 - binary_accuracy: 0.9231\n",
      "Epoch 174/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0938 - binary_accuracy: 0.9231\n",
      "Epoch 175/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0936 - binary_accuracy: 0.9231\n",
      "Epoch 176/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0933 - binary_accuracy: 0.9231\n",
      "Epoch 177/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.0931 - binary_accuracy: 0.9231\n",
      "Epoch 178/400\n",
      "13/13 [==============================] - 0s 768us/step - loss: 0.0929 - binary_accuracy: 0.9231\n",
      "Epoch 179/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0927 - binary_accuracy: 0.9231\n",
      "Epoch 180/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0924 - binary_accuracy: 0.9231\n",
      "Epoch 181/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0922 - binary_accuracy: 0.9231\n",
      "Epoch 182/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0920 - binary_accuracy: 0.9231\n",
      "Epoch 183/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0918 - binary_accuracy: 0.9231\n",
      "Epoch 184/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0916 - binary_accuracy: 0.9231\n",
      "Epoch 185/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0914 - binary_accuracy: 0.9231\n",
      "Epoch 186/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0912 - binary_accuracy: 0.9231\n",
      "Epoch 187/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0910 - binary_accuracy: 0.9231\n",
      "Epoch 188/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0907 - binary_accuracy: 0.9231\n",
      "Epoch 189/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0905 - binary_accuracy: 0.9231\n",
      "Epoch 190/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0903 - binary_accuracy: 0.9231\n",
      "Epoch 191/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0901 - binary_accuracy: 0.9231\n",
      "Epoch 192/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0899 - binary_accuracy: 0.9231\n",
      "Epoch 193/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0897 - binary_accuracy: 1.0000\n",
      "Epoch 194/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0895 - binary_accuracy: 1.0000\n",
      "Epoch 195/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0893 - binary_accuracy: 1.0000\n",
      "Epoch 196/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0891 - binary_accuracy: 1.0000\n",
      "Epoch 197/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0889 - binary_accuracy: 1.0000\n",
      "Epoch 198/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0887 - binary_accuracy: 1.0000\n",
      "Epoch 199/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0885 - binary_accuracy: 1.0000\n",
      "Epoch 200/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0884 - binary_accuracy: 1.0000\n",
      "Epoch 201/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0882 - binary_accuracy: 1.0000\n",
      "Epoch 202/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0880 - binary_accuracy: 1.0000\n",
      "Epoch 203/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0878 - binary_accuracy: 1.0000\n",
      "Epoch 204/400\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8950e-08 - binary_accuracy: 1.000 - 0s 1ms/step - loss: 0.0876 - binary_accuracy: 1.0000\n",
      "Epoch 205/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0874 - binary_accuracy: 1.0000\n",
      "Epoch 206/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0872 - binary_accuracy: 1.0000\n",
      "Epoch 207/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0870 - binary_accuracy: 1.0000\n",
      "Epoch 208/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0869 - binary_accuracy: 1.0000\n",
      "Epoch 209/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0867 - binary_accuracy: 1.0000\n",
      "Epoch 210/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.0865 - binary_accuracy: 1.0000\n",
      "Epoch 211/400\n",
      "13/13 [==============================] - 0s 996us/step - loss: 0.0863 - binary_accuracy: 1.0000\n",
      "Epoch 212/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0861 - binary_accuracy: 1.0000\n",
      "Epoch 213/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0860 - binary_accuracy: 1.0000\n",
      "Epoch 214/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0858 - binary_accuracy: 1.0000\n",
      "Epoch 215/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0856 - binary_accuracy: 1.0000\n",
      "Epoch 216/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0854 - binary_accuracy: 1.0000\n",
      "Epoch 217/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0853 - binary_accuracy: 1.0000\n",
      "Epoch 218/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0851 - binary_accuracy: 1.0000\n",
      "Epoch 219/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0849 - binary_accuracy: 1.0000\n",
      "Epoch 220/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0848 - binary_accuracy: 1.0000\n",
      "Epoch 221/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0846 - binary_accuracy: 1.0000\n",
      "Epoch 222/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0844 - binary_accuracy: 1.0000\n",
      "Epoch 223/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0843 - binary_accuracy: 1.0000\n",
      "Epoch 224/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0841 - binary_accuracy: 1.0000\n",
      "Epoch 225/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0839 - binary_accuracy: 1.0000\n",
      "Epoch 226/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0838 - binary_accuracy: 1.0000\n",
      "Epoch 227/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0836 - binary_accuracy: 1.0000\n",
      "Epoch 228/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0834 - binary_accuracy: 1.0000\n",
      "Epoch 229/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0833 - binary_accuracy: 1.0000\n",
      "Epoch 230/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0831 - binary_accuracy: 1.0000\n",
      "Epoch 231/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0830 - binary_accuracy: 1.0000\n",
      "Epoch 232/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0828 - binary_accuracy: 1.0000\n",
      "Epoch 233/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0827 - binary_accuracy: 1.0000\n",
      "Epoch 234/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0825 - binary_accuracy: 1.0000\n",
      "Epoch 235/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0823 - binary_accuracy: 1.0000\n",
      "Epoch 236/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0822 - binary_accuracy: 1.0000\n",
      "Epoch 237/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0820 - binary_accuracy: 1.0000\n",
      "Epoch 238/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0819 - binary_accuracy: 1.0000\n",
      "Epoch 239/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0817 - binary_accuracy: 1.0000\n",
      "Epoch 240/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0816 - binary_accuracy: 1.0000\n",
      "Epoch 241/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0814 - binary_accuracy: 1.0000\n",
      "Epoch 242/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0813 - binary_accuracy: 1.0000\n",
      "Epoch 243/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0811 - binary_accuracy: 1.0000\n",
      "Epoch 244/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0810 - binary_accuracy: 1.0000\n",
      "Epoch 245/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0808 - binary_accuracy: 1.0000\n",
      "Epoch 246/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0807 - binary_accuracy: 1.0000\n",
      "Epoch 247/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0805 - binary_accuracy: 1.0000\n",
      "Epoch 248/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0804 - binary_accuracy: 1.0000\n",
      "Epoch 249/400\n",
      "13/13 [==============================] - 0s 844us/step - loss: 0.0803 - binary_accuracy: 1.0000\n",
      "Epoch 250/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0801 - binary_accuracy: 1.0000\n",
      "Epoch 251/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0800 - binary_accuracy: 1.0000\n",
      "Epoch 252/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0798 - binary_accuracy: 1.0000\n",
      "Epoch 253/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0797 - binary_accuracy: 1.0000\n",
      "Epoch 254/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0795 - binary_accuracy: 1.0000\n",
      "Epoch 255/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0794 - binary_accuracy: 1.0000\n",
      "Epoch 256/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0793 - binary_accuracy: 1.0000\n",
      "Epoch 257/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0791 - binary_accuracy: 1.0000\n",
      "Epoch 258/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0790 - binary_accuracy: 1.0000\n",
      "Epoch 259/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0789 - binary_accuracy: 1.0000\n",
      "Epoch 260/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0787 - binary_accuracy: 1.0000\n",
      "Epoch 261/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0786 - binary_accuracy: 1.0000\n",
      "Epoch 262/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0785 - binary_accuracy: 1.0000\n",
      "Epoch 263/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0783 - binary_accuracy: 1.0000\n",
      "Epoch 264/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0782 - binary_accuracy: 1.0000\n",
      "Epoch 265/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0781 - binary_accuracy: 1.0000\n",
      "Epoch 266/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0779 - binary_accuracy: 1.0000\n",
      "Epoch 267/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0778 - binary_accuracy: 1.0000\n",
      "Epoch 268/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0777 - binary_accuracy: 1.0000\n",
      "Epoch 269/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0775 - binary_accuracy: 1.0000\n",
      "Epoch 270/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0774 - binary_accuracy: 1.0000\n",
      "Epoch 271/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0773 - binary_accuracy: 1.0000\n",
      "Epoch 272/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0771 - binary_accuracy: 1.0000\n",
      "Epoch 273/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0770 - binary_accuracy: 1.0000\n",
      "Epoch 274/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0769 - binary_accuracy: 1.0000\n",
      "Epoch 275/400\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0768 - binary_accuracy: 1.0000\n",
      "Epoch 276/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0766 - binary_accuracy: 1.0000\n",
      "Epoch 277/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0765 - binary_accuracy: 1.0000\n",
      "Epoch 278/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0764 - binary_accuracy: 1.0000\n",
      "Epoch 279/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0763 - binary_accuracy: 1.0000\n",
      "Epoch 280/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0761 - binary_accuracy: 1.0000\n",
      "Epoch 281/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0760 - binary_accuracy: 1.0000\n",
      "Epoch 282/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0759 - binary_accuracy: 1.0000\n",
      "Epoch 283/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0758 - binary_accuracy: 1.0000\n",
      "Epoch 284/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0757 - binary_accuracy: 1.0000\n",
      "Epoch 285/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0755 - binary_accuracy: 1.0000\n",
      "Epoch 286/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0754 - binary_accuracy: 1.0000\n",
      "Epoch 287/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0753 - binary_accuracy: 1.0000\n",
      "Epoch 288/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0752 - binary_accuracy: 1.0000\n",
      "Epoch 289/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0751 - binary_accuracy: 1.0000\n",
      "Epoch 290/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0749 - binary_accuracy: 1.0000\n",
      "Epoch 291/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0748 - binary_accuracy: 1.0000\n",
      "Epoch 292/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0747 - binary_accuracy: 1.0000\n",
      "Epoch 293/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0746 - binary_accuracy: 1.0000\n",
      "Epoch 294/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0745 - binary_accuracy: 1.0000\n",
      "Epoch 295/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0744 - binary_accuracy: 1.0000\n",
      "Epoch 296/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0743 - binary_accuracy: 1.0000\n",
      "Epoch 297/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0741 - binary_accuracy: 1.0000\n",
      "Epoch 298/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0740 - binary_accuracy: 1.0000\n",
      "Epoch 299/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0739 - binary_accuracy: 1.0000\n",
      "Epoch 300/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0738 - binary_accuracy: 1.0000\n",
      "Epoch 301/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0737 - binary_accuracy: 1.0000\n",
      "Epoch 302/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0736 - binary_accuracy: 1.0000\n",
      "Epoch 303/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0735 - binary_accuracy: 1.0000\n",
      "Epoch 304/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0734 - binary_accuracy: 1.0000\n",
      "Epoch 305/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0732 - binary_accuracy: 1.0000\n",
      "Epoch 306/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0731 - binary_accuracy: 1.0000\n",
      "Epoch 307/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0730 - binary_accuracy: 1.0000\n",
      "Epoch 308/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0729 - binary_accuracy: 1.0000\n",
      "Epoch 309/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0728 - binary_accuracy: 1.0000\n",
      "Epoch 310/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0727 - binary_accuracy: 1.0000\n",
      "Epoch 311/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0726 - binary_accuracy: 1.0000\n",
      "Epoch 312/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0725 - binary_accuracy: 1.0000\n",
      "Epoch 313/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0724 - binary_accuracy: 1.0000\n",
      "Epoch 314/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0723 - binary_accuracy: 1.0000\n",
      "Epoch 315/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0722 - binary_accuracy: 1.0000\n",
      "Epoch 316/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0721 - binary_accuracy: 1.0000\n",
      "Epoch 317/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0720 - binary_accuracy: 1.0000\n",
      "Epoch 318/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0719 - binary_accuracy: 1.0000\n",
      "Epoch 319/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0718 - binary_accuracy: 1.0000\n",
      "Epoch 320/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0717 - binary_accuracy: 1.0000\n",
      "Epoch 321/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0716 - binary_accuracy: 1.0000\n",
      "Epoch 322/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0715 - binary_accuracy: 1.0000\n",
      "Epoch 323/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0714 - binary_accuracy: 1.0000\n",
      "Epoch 324/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0713 - binary_accuracy: 1.0000\n",
      "Epoch 325/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0711 - binary_accuracy: 1.0000\n",
      "Epoch 326/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0710 - binary_accuracy: 1.0000\n",
      "Epoch 327/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0709 - binary_accuracy: 1.0000\n",
      "Epoch 328/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0708 - binary_accuracy: 1.0000\n",
      "Epoch 329/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0708 - binary_accuracy: 1.0000\n",
      "Epoch 330/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0707 - binary_accuracy: 1.0000\n",
      "Epoch 331/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0706 - binary_accuracy: 1.0000\n",
      "Epoch 332/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0705 - binary_accuracy: 1.0000\n",
      "Epoch 333/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0704 - binary_accuracy: 1.0000\n",
      "Epoch 334/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0703 - binary_accuracy: 1.0000\n",
      "Epoch 335/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0702 - binary_accuracy: 1.0000\n",
      "Epoch 336/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0701 - binary_accuracy: 1.0000\n",
      "Epoch 337/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0700 - binary_accuracy: 1.0000\n",
      "Epoch 338/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0699 - binary_accuracy: 1.0000\n",
      "Epoch 339/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0698 - binary_accuracy: 1.0000\n",
      "Epoch 340/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0697 - binary_accuracy: 1.0000\n",
      "Epoch 341/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0696 - binary_accuracy: 1.0000\n",
      "Epoch 342/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0695 - binary_accuracy: 1.0000\n",
      "Epoch 343/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0694 - binary_accuracy: 1.0000\n",
      "Epoch 344/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0693 - binary_accuracy: 1.0000\n",
      "Epoch 345/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0692 - binary_accuracy: 1.0000\n",
      "Epoch 346/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0691 - binary_accuracy: 1.0000\n",
      "Epoch 347/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0690 - binary_accuracy: 1.0000\n",
      "Epoch 348/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0689 - binary_accuracy: 1.0000\n",
      "Epoch 349/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0688 - binary_accuracy: 1.0000\n",
      "Epoch 350/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0688 - binary_accuracy: 1.0000\n",
      "Epoch 351/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0687 - binary_accuracy: 1.0000\n",
      "Epoch 352/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0686 - binary_accuracy: 1.0000\n",
      "Epoch 353/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0685 - binary_accuracy: 1.0000\n",
      "Epoch 354/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0684 - binary_accuracy: 1.0000\n",
      "Epoch 355/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0683 - binary_accuracy: 1.0000\n",
      "Epoch 356/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0682 - binary_accuracy: 1.0000\n",
      "Epoch 357/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0681 - binary_accuracy: 1.0000\n",
      "Epoch 358/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0680 - binary_accuracy: 1.0000\n",
      "Epoch 359/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0679 - binary_accuracy: 1.0000\n",
      "Epoch 360/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0679 - binary_accuracy: 1.0000\n",
      "Epoch 361/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0678 - binary_accuracy: 1.0000\n",
      "Epoch 362/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0677 - binary_accuracy: 1.0000\n",
      "Epoch 363/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0676 - binary_accuracy: 1.0000\n",
      "Epoch 364/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0675 - binary_accuracy: 1.0000\n",
      "Epoch 365/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0674 - binary_accuracy: 1.0000\n",
      "Epoch 366/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0673 - binary_accuracy: 1.0000\n",
      "Epoch 367/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0673 - binary_accuracy: 1.0000\n",
      "Epoch 368/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0672 - binary_accuracy: 1.0000\n",
      "Epoch 369/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0671 - binary_accuracy: 1.0000\n",
      "Epoch 370/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0670 - binary_accuracy: 1.0000\n",
      "Epoch 371/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0669 - binary_accuracy: 1.0000\n",
      "Epoch 372/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0668 - binary_accuracy: 1.0000\n",
      "Epoch 373/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0667 - binary_accuracy: 1.0000\n",
      "Epoch 374/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0667 - binary_accuracy: 1.0000\n",
      "Epoch 375/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0666 - binary_accuracy: 1.0000\n",
      "Epoch 376/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0665 - binary_accuracy: 1.0000\n",
      "Epoch 377/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0664 - binary_accuracy: 1.0000\n",
      "Epoch 378/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0663 - binary_accuracy: 1.0000\n",
      "Epoch 379/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0662 - binary_accuracy: 1.0000\n",
      "Epoch 380/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0662 - binary_accuracy: 1.0000\n",
      "Epoch 381/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0661 - binary_accuracy: 1.0000\n",
      "Epoch 382/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0660 - binary_accuracy: 1.0000\n",
      "Epoch 383/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0659 - binary_accuracy: 1.0000\n",
      "Epoch 384/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0658 - binary_accuracy: 1.0000\n",
      "Epoch 385/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0658 - binary_accuracy: 1.0000\n",
      "Epoch 386/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0657 - binary_accuracy: 1.0000\n",
      "Epoch 387/400\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0656 - binary_accuracy: 1.0000\n",
      "Epoch 388/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0655 - binary_accuracy: 1.0000\n",
      "Epoch 389/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0654 - binary_accuracy: 1.0000\n",
      "Epoch 390/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0654 - binary_accuracy: 1.0000\n",
      "Epoch 391/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0653 - binary_accuracy: 1.0000\n",
      "Epoch 392/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0652 - binary_accuracy: 1.0000\n",
      "Epoch 393/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0651 - binary_accuracy: 1.0000\n",
      "Epoch 394/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0650 - binary_accuracy: 1.0000\n",
      "Epoch 395/400\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.0650 - binary_accuracy: 1.0000\n",
      "Epoch 396/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0649 - binary_accuracy: 1.0000\n",
      "Epoch 397/400\n",
      "13/13 [==============================] - 0s 920us/step - loss: 0.0648 - binary_accuracy: 1.0000\n",
      "Epoch 398/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0647 - binary_accuracy: 1.0000\n",
      "Epoch 399/400\n",
      "13/13 [==============================] - 0s 921us/step - loss: 0.0647 - binary_accuracy: 1.0000\n",
      "Epoch 400/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0646 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd6cff92c8>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([-50, -40, -30, -20, -10, -5, 0, 5, 10, 20, 30, 40, 50])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]) #숫자 10부터 1\n",
    "\n",
    "inputs = tf.keras.Input(shape=(1,))\n",
    "outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n",
    "\n",
    "model.fit(x, y, batch_size=1, epochs=400, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1cd7142ca88>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, model.predict(x), color=\"b\")\n",
    "plt.scatter(x, y, color=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "BQvKbR9uBiDP",
    "outputId": "8f1fa49e-4bce-40ae-af07-20c62b36cfcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11951354]\n",
      " [0.16893   ]\n",
      " [0.23336375]\n",
      " [0.31311452]\n",
      " [0.35808378]]\n",
      "[[0.88504624]\n",
      " [0.99771535]\n",
      " [0.9999596 ]\n",
      " [0.9999993 ]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([1, 2, 3, 4, 4.5]))\n",
    "print(model.predict([11, 21, 31, 41, 500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IPZ78iD2BpDl"
   },
   "source": [
    "## 3-3. Multivariate Linear Regression 구현하기\n",
    "- 중간 고사, 기말 고사, 그리고 추가 점수를 어떤 공식을 통해 최종 점수를 계산한 데이터가 있고, 그 규칙을 찾고싶다면 이제는 더 이상 독립 변수가 1개가 아닙니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4F5xc7BOBt0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 11530.2520 - mse: 11530.2520\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2798.8584 - mse: 2798.8584\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1272.4995 - mse: 1272.4995\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 877.7783 - mse: 877.7783\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 695.5632 - mse: 695.5632\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 573.0280 - mse: 573.0280\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 478.7897 - mse: 478.7897\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 403.3607 - mse: 403.3607\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 342.2296 - mse: 342.2296\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 292.4771 - mse: 292.4771\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 251.9252 - mse: 251.9252\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 218.8552 - mse: 218.8552\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 191.8816 - mse: 191.8816\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 169.8783 - mse: 169.8783\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 151.9280 - mse: 151.9280\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 137.2821 - mse: 137.2821\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 125.3298 - mse: 125.3298\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 115.5724 - mse: 115.5724\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 107.6031 - mse: 107.6031\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 101.0900 - mse: 101.0900\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 95.7623 - mse: 95.7623\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 91.3993 - mse: 91.3993\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 87.8209 - mse: 87.8209\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 84.8803 - mse: 84.8803\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 82.4580 - mse: 82.4580\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 80.4565 - mse: 80.4565\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 78.7964 - mse: 78.7964\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 77.4132 - mse: 77.4132\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 76.2542 - mse: 76.2542\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 75.2769 - mse: 75.2769\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 74.4463 - mse: 74.4463\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 73.7344 - mse: 73.7344\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 73.1180 - mse: 73.1180\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 72.5786 - mse: 72.5786\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 72.1014 - mse: 72.1014\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 71.6739 - mse: 71.6739\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 71.2863 - mse: 71.2863\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 70.9305 - mse: 70.9305\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 70.6003 - mse: 70.6003\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 70.2904 - mse: 70.2904\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 69.9966 - mse: 69.9966\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 69.7157 - mse: 69.7157\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 69.4449 - mse: 69.4449\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 69.1820 - mse: 69.1820\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 68.9254 - mse: 68.9254\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 68.6736 - mse: 68.6736\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 68.4258 - mse: 68.4258\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 68.1808 - mse: 68.1808\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 67.9383 - mse: 67.9383\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 67.6976 - mse: 67.6976\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 67.4582 - mse: 67.4582\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 67.2200 - mse: 67.2200\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 66.9828 - mse: 66.9828\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 66.7462 - mse: 66.7462\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 66.5102 - mse: 66.5102\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 66.2749 - mse: 66.2749\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 66.0399 - mse: 66.0399\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 65.8053 - mse: 65.8053\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 65.5712 - mse: 65.5712\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 65.3375 - mse: 65.3375\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 65.1042 - mse: 65.1042\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 64.8714 - mse: 64.8714\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 64.6390 - mse: 64.6390\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 64.4069 - mse: 64.4069\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 64.1754 - mse: 64.1754\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 63.9443 - mse: 63.9443\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 63.7139 - mse: 63.7139\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 63.4839 - mse: 63.4839\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 63.2545 - mse: 63.2545\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 63.0257 - mse: 63.0257\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 62.7973 - mse: 62.7973\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 62.5697 - mse: 62.5697\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 62.3427 - mse: 62.3427\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 62.1164 - mse: 62.1164\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 61.8906 - mse: 61.8906\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 61.6656 - mse: 61.6656\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 61.4412 - mse: 61.4412\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 61.2175 - mse: 61.2175\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 60.9945 - mse: 60.9945\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 60.7723 - mse: 60.7723\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 60.5507 - mse: 60.5507\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 60.3298 - mse: 60.3298\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 60.1098 - mse: 60.1098\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 59.8903 - mse: 59.8903\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 59.6717 - mse: 59.6717\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 59.4538 - mse: 59.4538\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 59.2366 - mse: 59.2366\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 59.0202 - mse: 59.0202\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 58.8045 - mse: 58.8045\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 58.5896 - mse: 58.5896\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 58.3754 - mse: 58.3754\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 58.1620 - mse: 58.1620\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 57.9494 - mse: 57.9494\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 57.7374 - mse: 57.7374\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 57.5263 - mse: 57.5263\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 57.3158 - mse: 57.3158\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 57.1061 - mse: 57.1061\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 56.8973 - mse: 56.8973\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 56.6891 - mse: 56.6891\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 56.4817 - mse: 56.4817\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 56.2750 - mse: 56.2750\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 56.0691 - mse: 56.0691\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 55.8639 - mse: 55.8639\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 55.6594 - mse: 55.6594\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 55.4558 - mse: 55.4558\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 55.2527 - mse: 55.2527\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 55.0505 - mse: 55.0505\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 54.8490 - mse: 54.8490\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 54.6482 - mse: 54.6482\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 54.4482 - mse: 54.4482\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 54.2489 - mse: 54.2489\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 54.0503 - mse: 54.0503\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 53.8524 - mse: 53.8524\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 53.6553 - mse: 53.6553\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 53.4589 - mse: 53.4589\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 53.2632 - mse: 53.2632\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 53.0682 - mse: 53.0682\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 52.8739 - mse: 52.8739\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 52.6803 - mse: 52.6803\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 52.4874 - mse: 52.4874\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 52.2953 - mse: 52.2953\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 52.1039 - mse: 52.1039\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 51.9131 - mse: 51.9131\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 51.7230 - mse: 51.7230\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 51.5337 - mse: 51.5337\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 51.3450 - mse: 51.3450\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 51.1570 - mse: 51.1570\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 50.9697 - mse: 50.9697\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 50.7831 - mse: 50.7831\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 50.5972 - mse: 50.5972\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 50.4119 - mse: 50.4119\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.2274 - mse: 50.2274\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.0435 - mse: 50.0435\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 49.8603 - mse: 49.8603\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 49.6777 - mse: 49.6777\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 49.4958 - mse: 49.4958\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 49.3146 - mse: 49.3146\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 49.1341 - mse: 49.1341\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 48.9542 - mse: 48.9542\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.7749 - mse: 48.7749\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 48.5963 - mse: 48.5963\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.4184 - mse: 48.4184\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 111.2388 - mse: 111.238 - 0s 2ms/step - loss: 48.2412 - mse: 48.2412\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.0645 - mse: 48.0645\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 47.8885 - mse: 47.8885\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 47.7132 - mse: 47.7132\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 47.5385 - mse: 47.5385\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 47.3645 - mse: 47.3645\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 47.1910 - mse: 47.1910\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 47.0182 - mse: 47.0182\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 46.8461 - mse: 46.8461\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 46.6746 - mse: 46.6746\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 46.5037 - mse: 46.5037\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 106.8086 - mse: 106.808 - 0s 1ms/step - loss: 46.3334 - mse: 46.3334\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 46.1638 - mse: 46.1638\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 45.9948 - mse: 45.9948\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 45.8264 - mse: 45.8264\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 45.6586 - mse: 45.6586\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 45.4914 - mse: 45.4914\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 45.3249 - mse: 45.3249\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 45.1589 - mse: 45.1589\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 44.9935 - mse: 44.9935\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 44.8289 - mse: 44.8289\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 44.6647 - mse: 44.6647\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 44.5012 - mse: 44.5012\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 44.3382 - mse: 44.3382\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 44.1759 - mse: 44.1759\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 44.0142 - mse: 44.0142\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 43.8530 - mse: 43.8530\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 43.6924 - mse: 43.6924\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 43.5325 - mse: 43.5325\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 43.3731 - mse: 43.3731\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 43.2143 - mse: 43.2143\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 43.0561 - mse: 43.0561\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 42.8984 - mse: 42.8984\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 42.7414 - mse: 42.7414\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 42.5848 - mse: 42.5848\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 42.4289 - mse: 42.4289\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 42.2736 - mse: 42.2736\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 42.1188 - mse: 42.1188\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.9646 - mse: 41.9646\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.8110 - mse: 41.8110\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.6579 - mse: 41.6579\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.5054 - mse: 41.5054\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.3534 - mse: 41.3534\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.2020 - mse: 41.2020\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.0511 - mse: 41.0511\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 40.9008 - mse: 40.9008\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 40.7511 - mse: 40.7511\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 40.6019 - mse: 40.6019\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 40.4532 - mse: 40.4532\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.3052 - mse: 40.3052\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.1575 - mse: 40.1575\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 40.0105 - mse: 40.0105\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 39.8640 - mse: 39.8640\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.7181 - mse: 39.7181\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.5726 - mse: 39.5726\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.4278 - mse: 39.4278\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 39.2835 - mse: 39.2835\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 39.1396 - mse: 39.1396\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.9963 - mse: 38.9963\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 38.8536 - mse: 38.8536\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 38.7112 - mse: 38.7112\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 88.7860 - mse: 88.786 - 0s 1ms/step - loss: 38.5695 - mse: 38.5695\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 38.4283 - mse: 38.4283\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 38.2877 - mse: 38.2877\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 38.1475 - mse: 38.1475\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.0078 - mse: 38.0078\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 37.8686 - mse: 37.8686\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 37.7300 - mse: 37.7300\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 37.5919 - mse: 37.5919\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 997us/step - loss: 37.4542 - mse: 37.4542\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 37.3171 - mse: 37.3171\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 37.1805 - mse: 37.1805\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 37.0443 - mse: 37.0443\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 36.9087 - mse: 36.9087\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 36.7736 - mse: 36.7736\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 36.6389 - mse: 36.6389\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 36.5048 - mse: 36.5048\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 998us/step - loss: 36.3712 - mse: 36.3712\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 36.2380 - mse: 36.2380\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 36.1053 - mse: 36.1053\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 35.9731 - mse: 35.9731\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 35.8414 - mse: 35.8414\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 35.7102 - mse: 35.7102\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 35.5795 - mse: 35.5795\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 35.4492 - mse: 35.4492\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 35.3193 - mse: 35.3193\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 35.1901 - mse: 35.1901\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 35.0612 - mse: 35.0612\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 34.9328 - mse: 34.9328\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 34.8050 - mse: 34.8050\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 34.6775 - mse: 34.6775\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 34.5506 - mse: 34.5506\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 34.4241 - mse: 34.4241\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 34.2980 - mse: 34.2980\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 34.1725 - mse: 34.1725\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 34.0474 - mse: 34.0474\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 33.9227 - mse: 33.9227\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 33.7986 - mse: 33.7986\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 33.6748 - mse: 33.6748\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 33.5515 - mse: 33.5515\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 33.4286 - mse: 33.4286\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 33.3062 - mse: 33.3062\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 33.1844 - mse: 33.1844\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 33.0629 - mse: 33.0629\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 32.9418 - mse: 32.9418\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 32.8212 - mse: 32.8212\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 32.7010 - mse: 32.7010\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 74.8946 - mse: 74.894 - 0s 2ms/step - loss: 32.5813 - mse: 32.5813\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 32.4620 - mse: 32.4620\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 32.3431 - mse: 32.3431\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 32.2247 - mse: 32.2247\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 32.1068 - mse: 32.1068\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 31.9892 - mse: 31.9892\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 31.8721 - mse: 31.8721\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 31.7554 - mse: 31.7554\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 31.6391 - mse: 31.6391\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 31.5233 - mse: 31.5233\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 31.4079 - mse: 31.4079\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 31.2929 - mse: 31.2929\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 31.1783 - mse: 31.1783\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 31.0642 - mse: 31.0642\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 30.9505 - mse: 30.9505\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.8372 - mse: 30.8372\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.7243 - mse: 30.7243\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.6118 - mse: 30.6118\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 30.4997 - mse: 30.4997\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 30.3880 - mse: 30.3880\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.2768 - mse: 30.2768\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 998us/step - loss: 30.1660 - mse: 30.1660\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.0554 - mse: 30.0554\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.9454 - mse: 29.9454\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 29.8358 - mse: 29.8358\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 997us/step - loss: 29.7266 - mse: 29.7266\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.6178 - mse: 29.6178\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.5093 - mse: 29.5093\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 29.4013 - mse: 29.4013\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.2937 - mse: 29.2937\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.1864 - mse: 29.1864\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 29.0796 - mse: 29.0796\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 66.5296 - mse: 66.529 - 0s 2ms/step - loss: 28.9731 - mse: 28.9731\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 28.8670 - mse: 28.8670\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.7613 - mse: 28.7613\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.6560 - mse: 28.6560\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.5511 - mse: 28.5511\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.4466 - mse: 28.4466\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.3424 - mse: 28.3424\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.2387 - mse: 28.2387\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 28.1353 - mse: 28.1353\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 28.0323 - mse: 28.0323\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 27.9296 - mse: 27.9296\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 997us/step - loss: 27.8274 - mse: 27.8274\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 27.7255 - mse: 27.7255\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 998us/step - loss: 27.6240 - mse: 27.6240\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 995us/step - loss: 27.5229 - mse: 27.5229\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 27.4221 - mse: 27.4221\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 27.3217 - mse: 27.3217\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 27.2217 - mse: 27.2217\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 27.1221 - mse: 27.1221\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 27.0228 - mse: 27.0228\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 26.9238 - mse: 26.9238\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 26.8252 - mse: 26.8252\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 26.7270 - mse: 26.7270\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 26.6292 - mse: 26.6292\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 26.5317 - mse: 26.5317\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 26.4346 - mse: 26.4346\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 26.3378 - mse: 26.3378\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 26.2414 - mse: 26.2414\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 26.1453 - mse: 26.1453\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 26.0496 - mse: 26.0496\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 25.9542 - mse: 25.9542\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 25.8592 - mse: 25.8592\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 25.7646 - mse: 25.7646\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 25.6702 - mse: 25.6702\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 25.5762 - mse: 25.5762\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 25.4826 - mse: 25.4826\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 998us/step - loss: 25.3893 - mse: 25.3893\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 25.2964 - mse: 25.2964\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 25.2038 - mse: 25.2038\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 25.1115 - mse: 25.1115\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 25.0196 - mse: 25.0196\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 24.9279 - mse: 24.9279\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 24.8367 - mse: 24.8367\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 24.7458 - mse: 24.7458\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 24.6552 - mse: 24.6552\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 24.5649 - mse: 24.5649\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 24.4750 - mse: 24.4750\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 24.3854 - mse: 24.3854\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 24.2961 - mse: 24.2961\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 24.2071 - mse: 24.2071\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 24.1185 - mse: 24.1185\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 24.0302 - mse: 24.0302\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 23.9422 - mse: 23.9422\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 23.8546 - mse: 23.8546\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 23.7673 - mse: 23.7673\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 23.6803 - mse: 23.6803\n",
      "Epoch 338/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 23.5936 - mse: 23.5936\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 23.5072 - mse: 23.5072\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 23.4212 - mse: 23.4212\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 23.3354 - mse: 23.3354\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 23.2500 - mse: 23.2500\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 23.1649 - mse: 23.1649\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 23.0801 - mse: 23.0801\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.9956 - mse: 22.9956\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.9114 - mse: 22.9114\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 22.8275 - mse: 22.8275\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.7439 - mse: 22.7439\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.6607 - mse: 22.6607\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 22.5777 - mse: 22.5777\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.4950 - mse: 22.4950\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 22.4127 - mse: 22.4127\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 22.3307 - mse: 22.3307\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.2489 - mse: 22.2489\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.1675 - mse: 22.1675\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.0863 - mse: 22.0863\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.0054 - mse: 22.0054\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 21.9249 - mse: 21.9249\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 21.8446 - mse: 21.8446\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 21.7647 - mse: 21.7647\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 21.6850 - mse: 21.6850\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 21.6056 - mse: 21.6056\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 21.5265 - mse: 21.5265\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 21.4477 - mse: 21.4477\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 21.3692 - mse: 21.3692\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 21.2910 - mse: 21.2910\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 21.2131 - mse: 21.2131\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 21.1354 - mse: 21.1354\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 21.0580 - mse: 21.0580\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.9809 - mse: 20.9809\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.9041 - mse: 20.9041\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.8276 - mse: 20.8276\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.7514 - mse: 20.7514\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.6754 - mse: 20.6754\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.5997 - mse: 20.5997\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.5243 - mse: 20.5243\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.4491 - mse: 20.4491\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.3743 - mse: 20.3743\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.2997 - mse: 20.2997\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.2254 - mse: 20.2254\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.1513 - mse: 20.1513\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.0776 - mse: 20.0776\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 20.0041 - mse: 20.0041\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 19.9308 - mse: 19.9308\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 19.8579 - mse: 19.8579\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 19.7852 - mse: 19.7852\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 19.7128 - mse: 19.7128\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 19.6406 - mse: 19.6406\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 19.5687 - mse: 19.5687\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 19.4970 - mse: 19.4970\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 19.4257 - mse: 19.4257\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 19.3546 - mse: 19.3546\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.2838 - mse: 19.2838\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 19.2131 - mse: 19.2131\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 19.1428 - mse: 19.1428\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 19.0728 - mse: 19.0728\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 19.0029 - mse: 19.0029\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 18.9334 - mse: 18.9334\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 18.8640 - mse: 18.8640\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 18.7950 - mse: 18.7950\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 42.8027 - mse: 42.802 - 0s 4ms/step - loss: 18.7262 - mse: 18.7262\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 18.6576 - mse: 18.6576\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 18.5894 - mse: 18.5894\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 18.5213 - mse: 18.5213\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 18.4535 - mse: 18.4535\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 18.3860 - mse: 18.3860\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 18.3186 - mse: 18.3186\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 18.2516 - mse: 18.2516\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 18.1848 - mse: 18.1848\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 18.1182 - mse: 18.1182\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 18.0519 - mse: 18.0519\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.9858 - mse: 17.9858\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.9200 - mse: 17.9200\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17.8544 - mse: 17.8544\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.7890 - mse: 17.7890\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7239 - mse: 17.7239\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.6591 - mse: 17.6591\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 40.1855 - mse: 40.185 - 0s 2ms/step - loss: 17.5944 - mse: 17.5944\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.5300 - mse: 17.5300\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.4658 - mse: 17.4658\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17.4019 - mse: 17.4019\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.3382 - mse: 17.3382\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17.2747 - mse: 17.2747\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.2115 - mse: 17.2115\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17.1485 - mse: 17.1485\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17.0857 - mse: 17.0857\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.0232 - mse: 17.0232\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 16.9609 - mse: 16.9609\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.8988 - mse: 16.8988\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.8369 - mse: 16.8369\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16.7753 - mse: 16.7753\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.7139 - mse: 16.7139\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16.6527 - mse: 16.6527\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.5918 - mse: 16.5918\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.5310 - mse: 16.5310\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.4705 - mse: 16.4705\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.4102 - mse: 16.4102\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - ETA: 0s - loss: 37.3095 - mse: 37.309 - 0s 2ms/step - loss: 16.3501 - mse: 16.3501\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 16.2903 - mse: 16.2903\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.2307 - mse: 16.2307\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.1713 - mse: 16.1713\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 16.1121 - mse: 16.1121\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 16.0531 - mse: 16.0531\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.9943 - mse: 15.9943\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.9358 - mse: 15.9358\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15.8775 - mse: 15.8775\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.8194 - mse: 15.8194\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 15.7614 - mse: 15.7614\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 15.7037 - mse: 15.7037\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.6462 - mse: 15.6462\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.5890 - mse: 15.5890\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.5319 - mse: 15.5319\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.4751 - mse: 15.4751\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.4184 - mse: 15.4184\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.3620 - mse: 15.3620\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3058 - mse: 15.3058\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.2498 - mse: 15.2498\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.1939 - mse: 15.1939\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.1383 - mse: 15.1383\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.0829 - mse: 15.0829\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 15.0277 - mse: 15.0277\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.9727 - mse: 14.9727\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.9179 - mse: 14.9179\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.8633 - mse: 14.8633\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.8089 - mse: 14.8089\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 14.7547 - mse: 14.7547\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.7007 - mse: 14.7007\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.6469 - mse: 14.6469\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.5933 - mse: 14.5933\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.5399 - mse: 14.5399\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 14.4866 - mse: 14.4866\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.4336 - mse: 14.4336\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.3808 - mse: 14.3808\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 14.3282 - mse: 14.3282\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.2757 - mse: 14.2757\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 14.2234 - mse: 14.2234\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 14.1714 - mse: 14.1714\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.1195 - mse: 14.1195\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.0678 - mse: 14.0678\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 14.0164 - mse: 14.0164\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.9651 - mse: 13.9651\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.9140 - mse: 13.9140\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.8630 - mse: 13.8630\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.8123 - mse: 13.8123\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.7617 - mse: 13.7617\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.7113 - mse: 13.7113\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 13.6611 - mse: 13.6611\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.6112 - mse: 13.6112\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.5613 - mse: 13.5613\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 13.5117 - mse: 13.5117\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.4622 - mse: 13.4622\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.4130 - mse: 13.4130\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.3639 - mse: 13.3639\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.3150 - mse: 13.3150\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.2662 - mse: 13.2662\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.2177 - mse: 13.2177\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.1693 - mse: 13.1693\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.1211 - mse: 13.1211\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13.0731 - mse: 13.0731\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0253 - mse: 13.0253\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[70, 85, 11],  [71, 89, 18], [50, 80, 20], [99, 20, 10], [50, 10, 10]])\n",
    "y = np.array([73, 82, 72, 57, 34])\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_shape=(3,), activation=\"linear\"))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.00001) , loss=\"mean_squared_error\", metrics=[\"mse\"])\n",
    "\n",
    "hist = model.fit(x, y, batch_size=1, epochs=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOVfLLqvB_q0"
   },
   "source": [
    "## 3-4. Multivariate Logistic Regression 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXPeQu5vB5tK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6931 - binary_accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4977 - binary_accuracy: 0.7500\n",
      "Epoch 2/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4950 - binary_accuracy: 0.5000\n",
      "Epoch 3/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4924 - binary_accuracy: 0.5000\n",
      "Epoch 4/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4898 - binary_accuracy: 0.5000\n",
      "Epoch 5/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4874 - binary_accuracy: 0.5000\n",
      "Epoch 6/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4849 - binary_accuracy: 0.5000\n",
      "Epoch 7/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4825 - binary_accuracy: 0.5000\n",
      "Epoch 8/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4802 - binary_accuracy: 0.5000\n",
      "Epoch 9/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4779 - binary_accuracy: 0.5000\n",
      "Epoch 10/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4756 - binary_accuracy: 0.5000\n",
      "Epoch 11/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4734 - binary_accuracy: 0.5000\n",
      "Epoch 12/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4713 - binary_accuracy: 0.5000\n",
      "Epoch 13/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4692 - binary_accuracy: 0.7500\n",
      "Epoch 14/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4671 - binary_accuracy: 0.7500\n",
      "Epoch 15/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4651 - binary_accuracy: 0.7500\n",
      "Epoch 16/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4631 - binary_accuracy: 0.7500\n",
      "Epoch 17/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4611 - binary_accuracy: 0.7500\n",
      "Epoch 18/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4592 - binary_accuracy: 0.7500\n",
      "Epoch 19/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4574 - binary_accuracy: 0.7500\n",
      "Epoch 20/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4555 - binary_accuracy: 0.7500\n",
      "Epoch 21/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4537 - binary_accuracy: 0.7500\n",
      "Epoch 22/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4519 - binary_accuracy: 0.7500\n",
      "Epoch 23/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4502 - binary_accuracy: 0.7500\n",
      "Epoch 24/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4485 - binary_accuracy: 0.7500\n",
      "Epoch 25/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4468 - binary_accuracy: 0.7500\n",
      "Epoch 26/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4452 - binary_accuracy: 0.7500\n",
      "Epoch 27/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4436 - binary_accuracy: 0.7500\n",
      "Epoch 28/1200\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4420 - binary_accuracy: 0.7500\n",
      "Epoch 29/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4404 - binary_accuracy: 0.7500\n",
      "Epoch 30/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4389 - binary_accuracy: 0.7500\n",
      "Epoch 31/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4374 - binary_accuracy: 0.7500\n",
      "Epoch 32/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4359 - binary_accuracy: 0.7500\n",
      "Epoch 33/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4344 - binary_accuracy: 0.7500\n",
      "Epoch 34/1200\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4330 - binary_accuracy: 0.7500\n",
      "Epoch 35/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4316 - binary_accuracy: 0.7500\n",
      "Epoch 36/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4302 - binary_accuracy: 0.7500\n",
      "Epoch 37/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4289 - binary_accuracy: 0.7500\n",
      "Epoch 38/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4275 - binary_accuracy: 0.7500\n",
      "Epoch 39/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4262 - binary_accuracy: 0.7500\n",
      "Epoch 40/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4249 - binary_accuracy: 0.7500\n",
      "Epoch 41/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4236 - binary_accuracy: 0.7500\n",
      "Epoch 42/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4224 - binary_accuracy: 0.7500\n",
      "Epoch 43/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4211 - binary_accuracy: 0.7500\n",
      "Epoch 44/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4199 - binary_accuracy: 0.7500\n",
      "Epoch 45/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4187 - binary_accuracy: 0.7500\n",
      "Epoch 46/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4175 - binary_accuracy: 0.7500\n",
      "Epoch 47/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4163 - binary_accuracy: 0.7500\n",
      "Epoch 48/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4152 - binary_accuracy: 0.7500\n",
      "Epoch 49/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4141 - binary_accuracy: 0.7500\n",
      "Epoch 50/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4129 - binary_accuracy: 0.7500\n",
      "Epoch 51/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4118 - binary_accuracy: 0.7500\n",
      "Epoch 52/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4108 - binary_accuracy: 0.7500\n",
      "Epoch 53/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4097 - binary_accuracy: 0.7500\n",
      "Epoch 54/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4086 - binary_accuracy: 0.7500\n",
      "Epoch 55/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4076 - binary_accuracy: 0.7500\n",
      "Epoch 56/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4066 - binary_accuracy: 0.7500\n",
      "Epoch 57/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4056 - binary_accuracy: 0.7500\n",
      "Epoch 58/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4046 - binary_accuracy: 0.7500\n",
      "Epoch 59/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4036 - binary_accuracy: 0.7500\n",
      "Epoch 60/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4026 - binary_accuracy: 0.7500\n",
      "Epoch 61/1200\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4016 - binary_accuracy: 0.7500\n",
      "Epoch 62/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4007 - binary_accuracy: 0.7500\n",
      "Epoch 63/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3997 - binary_accuracy: 0.7500\n",
      "Epoch 64/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3988 - binary_accuracy: 0.7500\n",
      "Epoch 65/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3979 - binary_accuracy: 0.7500\n",
      "Epoch 66/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3970 - binary_accuracy: 0.7500\n",
      "Epoch 67/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3961 - binary_accuracy: 0.7500\n",
      "Epoch 68/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3952 - binary_accuracy: 0.7500\n",
      "Epoch 69/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3943 - binary_accuracy: 0.7500\n",
      "Epoch 70/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3935 - binary_accuracy: 0.7500\n",
      "Epoch 71/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3926 - binary_accuracy: 0.7500\n",
      "Epoch 72/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3918 - binary_accuracy: 0.7500\n",
      "Epoch 73/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3910 - binary_accuracy: 0.7500\n",
      "Epoch 74/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3901 - binary_accuracy: 0.7500\n",
      "Epoch 75/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3893 - binary_accuracy: 0.7500\n",
      "Epoch 76/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3885 - binary_accuracy: 0.7500\n",
      "Epoch 77/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3877 - binary_accuracy: 0.7500\n",
      "Epoch 78/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3869 - binary_accuracy: 0.7500\n",
      "Epoch 79/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3861 - binary_accuracy: 0.7500\n",
      "Epoch 80/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3854 - binary_accuracy: 0.7500\n",
      "Epoch 81/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3846 - binary_accuracy: 0.7500\n",
      "Epoch 82/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3838 - binary_accuracy: 0.7500\n",
      "Epoch 83/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3831 - binary_accuracy: 0.7500\n",
      "Epoch 84/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3824 - binary_accuracy: 0.7500\n",
      "Epoch 85/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3816 - binary_accuracy: 0.7500\n",
      "Epoch 86/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3809 - binary_accuracy: 0.7500\n",
      "Epoch 87/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3802 - binary_accuracy: 0.7500\n",
      "Epoch 88/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3795 - binary_accuracy: 0.7500\n",
      "Epoch 89/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3788 - binary_accuracy: 0.7500\n",
      "Epoch 90/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3781 - binary_accuracy: 0.7500\n",
      "Epoch 91/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3774 - binary_accuracy: 0.7500\n",
      "Epoch 92/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3767 - binary_accuracy: 0.7500\n",
      "Epoch 93/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3760 - binary_accuracy: 0.7500\n",
      "Epoch 94/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3753 - binary_accuracy: 0.7500\n",
      "Epoch 95/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3746 - binary_accuracy: 0.7500\n",
      "Epoch 96/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3740 - binary_accuracy: 0.7500\n",
      "Epoch 97/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3733 - binary_accuracy: 0.7500\n",
      "Epoch 98/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3727 - binary_accuracy: 0.7500\n",
      "Epoch 99/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3720 - binary_accuracy: 0.7500\n",
      "Epoch 100/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3714 - binary_accuracy: 0.7500\n",
      "Epoch 101/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3707 - binary_accuracy: 0.7500\n",
      "Epoch 102/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3701 - binary_accuracy: 0.7500\n",
      "Epoch 103/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3695 - binary_accuracy: 0.7500\n",
      "Epoch 104/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3689 - binary_accuracy: 0.7500\n",
      "Epoch 105/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3683 - binary_accuracy: 0.7500\n",
      "Epoch 106/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3676 - binary_accuracy: 0.7500\n",
      "Epoch 107/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3670 - binary_accuracy: 0.7500\n",
      "Epoch 108/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3664 - binary_accuracy: 0.7500\n",
      "Epoch 109/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3658 - binary_accuracy: 0.7500\n",
      "Epoch 110/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3653 - binary_accuracy: 0.7500\n",
      "Epoch 111/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3647 - binary_accuracy: 0.7500\n",
      "Epoch 112/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3641 - binary_accuracy: 0.7500\n",
      "Epoch 113/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3635 - binary_accuracy: 0.7500\n",
      "Epoch 114/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3629 - binary_accuracy: 0.7500\n",
      "Epoch 115/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3624 - binary_accuracy: 0.7500\n",
      "Epoch 116/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3618 - binary_accuracy: 0.7500\n",
      "Epoch 117/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3612 - binary_accuracy: 0.7500\n",
      "Epoch 118/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3607 - binary_accuracy: 0.7500\n",
      "Epoch 119/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3601 - binary_accuracy: 0.7500\n",
      "Epoch 120/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3596 - binary_accuracy: 0.7500\n",
      "Epoch 121/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3590 - binary_accuracy: 0.7500\n",
      "Epoch 122/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3585 - binary_accuracy: 0.7500\n",
      "Epoch 123/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3579 - binary_accuracy: 0.7500\n",
      "Epoch 124/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3574 - binary_accuracy: 0.7500\n",
      "Epoch 125/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3569 - binary_accuracy: 0.7500\n",
      "Epoch 126/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3563 - binary_accuracy: 0.7500\n",
      "Epoch 127/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3558 - binary_accuracy: 0.7500\n",
      "Epoch 128/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3553 - binary_accuracy: 0.7500\n",
      "Epoch 129/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3548 - binary_accuracy: 0.7500\n",
      "Epoch 130/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3542 - binary_accuracy: 0.7500\n",
      "Epoch 131/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3537 - binary_accuracy: 0.7500\n",
      "Epoch 132/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3532 - binary_accuracy: 0.7500\n",
      "Epoch 133/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3527 - binary_accuracy: 0.7500\n",
      "Epoch 134/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3522 - binary_accuracy: 0.7500\n",
      "Epoch 135/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3517 - binary_accuracy: 0.7500\n",
      "Epoch 136/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3512 - binary_accuracy: 0.7500\n",
      "Epoch 137/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3507 - binary_accuracy: 0.7500\n",
      "Epoch 138/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.7500\n",
      "Epoch 139/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3497 - binary_accuracy: 0.7500\n",
      "Epoch 140/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3492 - binary_accuracy: 0.7500\n",
      "Epoch 141/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3488 - binary_accuracy: 0.7500\n",
      "Epoch 142/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3483 - binary_accuracy: 0.7500\n",
      "Epoch 143/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3478 - binary_accuracy: 0.7500\n",
      "Epoch 144/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3473 - binary_accuracy: 0.7500\n",
      "Epoch 145/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3468 - binary_accuracy: 0.7500\n",
      "Epoch 146/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3464 - binary_accuracy: 0.7500\n",
      "Epoch 147/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3459 - binary_accuracy: 0.7500\n",
      "Epoch 148/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3454 - binary_accuracy: 0.7500\n",
      "Epoch 149/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3450 - binary_accuracy: 0.7500\n",
      "Epoch 150/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3445 - binary_accuracy: 0.7500\n",
      "Epoch 151/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3440 - binary_accuracy: 0.7500\n",
      "Epoch 152/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3436 - binary_accuracy: 0.7500\n",
      "Epoch 153/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3431 - binary_accuracy: 0.7500\n",
      "Epoch 154/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3427 - binary_accuracy: 0.7500\n",
      "Epoch 155/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3422 - binary_accuracy: 0.7500\n",
      "Epoch 156/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3418 - binary_accuracy: 0.7500\n",
      "Epoch 157/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3413 - binary_accuracy: 0.7500\n",
      "Epoch 158/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3409 - binary_accuracy: 0.7500\n",
      "Epoch 159/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3404 - binary_accuracy: 0.7500\n",
      "Epoch 160/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3400 - binary_accuracy: 0.7500\n",
      "Epoch 161/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3396 - binary_accuracy: 0.7500\n",
      "Epoch 162/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3391 - binary_accuracy: 0.7500\n",
      "Epoch 163/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3387 - binary_accuracy: 0.7500\n",
      "Epoch 164/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3382 - binary_accuracy: 0.7500\n",
      "Epoch 165/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3378 - binary_accuracy: 0.7500\n",
      "Epoch 166/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3374 - binary_accuracy: 0.7500\n",
      "Epoch 167/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3370 - binary_accuracy: 0.7500\n",
      "Epoch 168/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3365 - binary_accuracy: 0.7500\n",
      "Epoch 169/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3361 - binary_accuracy: 0.7500\n",
      "Epoch 170/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3357 - binary_accuracy: 0.7500\n",
      "Epoch 171/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3353 - binary_accuracy: 0.7500\n",
      "Epoch 172/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3348 - binary_accuracy: 0.7500\n",
      "Epoch 173/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3344 - binary_accuracy: 0.7500\n",
      "Epoch 174/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3340 - binary_accuracy: 0.7500\n",
      "Epoch 175/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3336 - binary_accuracy: 0.7500\n",
      "Epoch 176/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3332 - binary_accuracy: 0.7500\n",
      "Epoch 177/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3328 - binary_accuracy: 0.7500\n",
      "Epoch 178/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3324 - binary_accuracy: 0.7500\n",
      "Epoch 179/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3320 - binary_accuracy: 0.7500\n",
      "Epoch 180/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3315 - binary_accuracy: 0.7500\n",
      "Epoch 181/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3311 - binary_accuracy: 0.7500\n",
      "Epoch 182/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3307 - binary_accuracy: 0.7500\n",
      "Epoch 183/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3303 - binary_accuracy: 0.7500\n",
      "Epoch 184/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3299 - binary_accuracy: 0.7500\n",
      "Epoch 185/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3295 - binary_accuracy: 0.7500\n",
      "Epoch 186/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3291 - binary_accuracy: 0.7500\n",
      "Epoch 187/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3287 - binary_accuracy: 0.7500\n",
      "Epoch 188/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3283 - binary_accuracy: 0.7500\n",
      "Epoch 189/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3280 - binary_accuracy: 0.7500\n",
      "Epoch 190/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3276 - binary_accuracy: 0.7500\n",
      "Epoch 191/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3272 - binary_accuracy: 0.7500\n",
      "Epoch 192/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3268 - binary_accuracy: 0.7500\n",
      "Epoch 193/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3264 - binary_accuracy: 0.7500\n",
      "Epoch 194/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3260 - binary_accuracy: 0.7500\n",
      "Epoch 195/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3256 - binary_accuracy: 0.7500\n",
      "Epoch 196/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3252 - binary_accuracy: 0.7500\n",
      "Epoch 197/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3249 - binary_accuracy: 0.7500\n",
      "Epoch 198/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3245 - binary_accuracy: 0.7500\n",
      "Epoch 199/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3241 - binary_accuracy: 0.7500\n",
      "Epoch 200/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7833 - binary_accuracy: 0.0000e+0 - 0s 2ms/step - loss: 0.3237 - binary_accuracy: 0.7500\n",
      "Epoch 201/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3233 - binary_accuracy: 0.7500\n",
      "Epoch 202/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3230 - binary_accuracy: 0.7500\n",
      "Epoch 203/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3226 - binary_accuracy: 0.7500\n",
      "Epoch 204/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3222 - binary_accuracy: 0.7500\n",
      "Epoch 205/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3218 - binary_accuracy: 0.7500\n",
      "Epoch 206/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3215 - binary_accuracy: 0.7500\n",
      "Epoch 207/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3211 - binary_accuracy: 0.7500\n",
      "Epoch 208/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3207 - binary_accuracy: 0.7500\n",
      "Epoch 209/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3204 - binary_accuracy: 0.7500\n",
      "Epoch 210/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3200 - binary_accuracy: 0.7500\n",
      "Epoch 211/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3196 - binary_accuracy: 0.7500\n",
      "Epoch 212/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3193 - binary_accuracy: 0.7500\n",
      "Epoch 213/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3189 - binary_accuracy: 0.7500\n",
      "Epoch 214/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3185 - binary_accuracy: 0.7500\n",
      "Epoch 215/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3182 - binary_accuracy: 0.7500\n",
      "Epoch 216/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3178 - binary_accuracy: 0.7500\n",
      "Epoch 217/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3175 - binary_accuracy: 0.7500\n",
      "Epoch 218/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3171 - binary_accuracy: 0.7500\n",
      "Epoch 219/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3168 - binary_accuracy: 0.7500\n",
      "Epoch 220/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3164 - binary_accuracy: 0.7500\n",
      "Epoch 221/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3160 - binary_accuracy: 0.7500\n",
      "Epoch 222/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3157 - binary_accuracy: 0.7500\n",
      "Epoch 223/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3153 - binary_accuracy: 0.7500\n",
      "Epoch 224/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3150 - binary_accuracy: 0.7500\n",
      "Epoch 225/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3146 - binary_accuracy: 0.7500\n",
      "Epoch 226/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3143 - binary_accuracy: 0.7500\n",
      "Epoch 227/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3139 - binary_accuracy: 0.7500\n",
      "Epoch 228/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3136 - binary_accuracy: 0.7500\n",
      "Epoch 229/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3132 - binary_accuracy: 0.7500\n",
      "Epoch 230/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3129 - binary_accuracy: 0.7500\n",
      "Epoch 231/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3126 - binary_accuracy: 0.7500\n",
      "Epoch 232/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3122 - binary_accuracy: 0.7500\n",
      "Epoch 233/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3119 - binary_accuracy: 0.7500\n",
      "Epoch 234/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3115 - binary_accuracy: 0.7500\n",
      "Epoch 235/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3112 - binary_accuracy: 0.7500\n",
      "Epoch 236/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3108 - binary_accuracy: 0.7500\n",
      "Epoch 237/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3105 - binary_accuracy: 0.7500\n",
      "Epoch 238/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3102 - binary_accuracy: 0.7500\n",
      "Epoch 239/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3098 - binary_accuracy: 0.7500\n",
      "Epoch 240/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3095 - binary_accuracy: 0.7500\n",
      "Epoch 241/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3092 - binary_accuracy: 0.7500\n",
      "Epoch 242/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3088 - binary_accuracy: 0.7500\n",
      "Epoch 243/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3085 - binary_accuracy: 0.7500\n",
      "Epoch 244/1200\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3082 - binary_accuracy: 0.7500\n",
      "Epoch 245/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3078 - binary_accuracy: 0.7500\n",
      "Epoch 246/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3075 - binary_accuracy: 0.7500\n",
      "Epoch 247/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3072 - binary_accuracy: 0.7500\n",
      "Epoch 248/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3068 - binary_accuracy: 0.7500\n",
      "Epoch 249/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3065 - binary_accuracy: 0.7500\n",
      "Epoch 250/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3062 - binary_accuracy: 0.7500\n",
      "Epoch 251/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3058 - binary_accuracy: 0.7500\n",
      "Epoch 252/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3055 - binary_accuracy: 0.7500\n",
      "Epoch 253/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3052 - binary_accuracy: 0.7500\n",
      "Epoch 254/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3049 - binary_accuracy: 0.7500\n",
      "Epoch 255/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3045 - binary_accuracy: 0.7500\n",
      "Epoch 256/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3042 - binary_accuracy: 0.7500\n",
      "Epoch 257/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3039 - binary_accuracy: 0.7500\n",
      "Epoch 258/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3036 - binary_accuracy: 0.7500\n",
      "Epoch 259/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3032 - binary_accuracy: 0.7500\n",
      "Epoch 260/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3029 - binary_accuracy: 0.7500\n",
      "Epoch 261/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3026 - binary_accuracy: 0.7500\n",
      "Epoch 262/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3023 - binary_accuracy: 0.7500\n",
      "Epoch 263/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3020 - binary_accuracy: 0.7500\n",
      "Epoch 264/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3017 - binary_accuracy: 0.7500\n",
      "Epoch 265/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3013 - binary_accuracy: 0.7500\n",
      "Epoch 266/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3010 - binary_accuracy: 0.7500\n",
      "Epoch 267/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3007 - binary_accuracy: 0.7500\n",
      "Epoch 268/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3004 - binary_accuracy: 0.7500\n",
      "Epoch 269/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3001 - binary_accuracy: 0.7500\n",
      "Epoch 270/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2998 - binary_accuracy: 0.7500\n",
      "Epoch 271/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2995 - binary_accuracy: 0.7500\n",
      "Epoch 272/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2991 - binary_accuracy: 0.7500\n",
      "Epoch 273/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2988 - binary_accuracy: 0.7500\n",
      "Epoch 274/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2985 - binary_accuracy: 0.7500\n",
      "Epoch 275/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2982 - binary_accuracy: 0.7500\n",
      "Epoch 276/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2979 - binary_accuracy: 0.7500\n",
      "Epoch 277/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2976 - binary_accuracy: 0.7500\n",
      "Epoch 278/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2973 - binary_accuracy: 0.7500\n",
      "Epoch 279/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2970 - binary_accuracy: 0.7500\n",
      "Epoch 280/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2967 - binary_accuracy: 0.7500\n",
      "Epoch 281/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2964 - binary_accuracy: 0.7500\n",
      "Epoch 282/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2961 - binary_accuracy: 0.7500\n",
      "Epoch 283/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.2958 - binary_accuracy: 0.7500\n",
      "Epoch 284/1200\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.2955 - binary_accuracy: 0.7500\n",
      "Epoch 285/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2952 - binary_accuracy: 0.7500\n",
      "Epoch 286/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2949 - binary_accuracy: 0.7500\n",
      "Epoch 287/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2945 - binary_accuracy: 0.7500\n",
      "Epoch 288/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2942 - binary_accuracy: 0.7500\n",
      "Epoch 289/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2939 - binary_accuracy: 0.7500\n",
      "Epoch 290/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2936 - binary_accuracy: 0.7500\n",
      "Epoch 291/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2934 - binary_accuracy: 0.7500\n",
      "Epoch 292/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2931 - binary_accuracy: 0.7500\n",
      "Epoch 293/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2928 - binary_accuracy: 0.7500\n",
      "Epoch 294/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2925 - binary_accuracy: 0.7500\n",
      "Epoch 295/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2922 - binary_accuracy: 0.7500\n",
      "Epoch 296/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2919 - binary_accuracy: 0.7500\n",
      "Epoch 297/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2916 - binary_accuracy: 0.7500\n",
      "Epoch 298/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2913 - binary_accuracy: 0.7500\n",
      "Epoch 299/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.2910 - binary_accuracy: 0.7500\n",
      "Epoch 300/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2907 - binary_accuracy: 0.7500\n",
      "Epoch 301/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2904 - binary_accuracy: 0.7500\n",
      "Epoch 302/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2901 - binary_accuracy: 0.7500\n",
      "Epoch 303/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2898 - binary_accuracy: 0.7500\n",
      "Epoch 304/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2895 - binary_accuracy: 0.7500\n",
      "Epoch 305/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7230 - binary_accuracy: 0.0000e+0 - 0s 2ms/step - loss: 0.2892 - binary_accuracy: 0.7500\n",
      "Epoch 306/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2889 - binary_accuracy: 0.7500\n",
      "Epoch 307/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2887 - binary_accuracy: 0.7500\n",
      "Epoch 308/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2884 - binary_accuracy: 0.7500\n",
      "Epoch 309/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2881 - binary_accuracy: 0.7500\n",
      "Epoch 310/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2878 - binary_accuracy: 0.7500\n",
      "Epoch 311/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2875 - binary_accuracy: 0.7500\n",
      "Epoch 312/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2872 - binary_accuracy: 0.7500\n",
      "Epoch 313/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2869 - binary_accuracy: 0.7500\n",
      "Epoch 314/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2866 - binary_accuracy: 0.7500\n",
      "Epoch 315/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2864 - binary_accuracy: 0.7500\n",
      "Epoch 316/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2861 - binary_accuracy: 0.7500\n",
      "Epoch 317/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2858 - binary_accuracy: 0.7500\n",
      "Epoch 318/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2855 - binary_accuracy: 0.7500\n",
      "Epoch 319/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2852 - binary_accuracy: 0.7500\n",
      "Epoch 320/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2850 - binary_accuracy: 0.7500\n",
      "Epoch 321/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2847 - binary_accuracy: 0.7500\n",
      "Epoch 322/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2844 - binary_accuracy: 0.7500\n",
      "Epoch 323/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2841 - binary_accuracy: 0.7500\n",
      "Epoch 324/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2838 - binary_accuracy: 0.7500\n",
      "Epoch 325/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2836 - binary_accuracy: 0.7500\n",
      "Epoch 326/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2833 - binary_accuracy: 0.7500\n",
      "Epoch 327/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2830 - binary_accuracy: 0.7500\n",
      "Epoch 328/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2827 - binary_accuracy: 0.7500\n",
      "Epoch 329/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2824 - binary_accuracy: 0.7500\n",
      "Epoch 330/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2822 - binary_accuracy: 0.7500\n",
      "Epoch 331/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2819 - binary_accuracy: 0.7500\n",
      "Epoch 332/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2816 - binary_accuracy: 0.7500\n",
      "Epoch 333/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2813 - binary_accuracy: 0.7500\n",
      "Epoch 334/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2811 - binary_accuracy: 0.7500\n",
      "Epoch 335/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2808 - binary_accuracy: 0.7500\n",
      "Epoch 336/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2805 - binary_accuracy: 0.7500\n",
      "Epoch 337/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2802 - binary_accuracy: 0.7500\n",
      "Epoch 338/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2800 - binary_accuracy: 0.7500\n",
      "Epoch 339/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2797 - binary_accuracy: 0.7500\n",
      "Epoch 340/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2794 - binary_accuracy: 0.7500\n",
      "Epoch 341/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2792 - binary_accuracy: 0.7500\n",
      "Epoch 342/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2789 - binary_accuracy: 0.7500\n",
      "Epoch 343/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2786 - binary_accuracy: 0.7500\n",
      "Epoch 344/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2784 - binary_accuracy: 0.7500\n",
      "Epoch 345/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2781 - binary_accuracy: 0.7500\n",
      "Epoch 346/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2778 - binary_accuracy: 0.7500\n",
      "Epoch 347/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2776 - binary_accuracy: 0.7500\n",
      "Epoch 348/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2773 - binary_accuracy: 0.7500\n",
      "Epoch 349/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2770 - binary_accuracy: 0.7500\n",
      "Epoch 350/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2768 - binary_accuracy: 0.7500\n",
      "Epoch 351/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2765 - binary_accuracy: 0.7500\n",
      "Epoch 352/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2762 - binary_accuracy: 0.7500\n",
      "Epoch 353/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2760 - binary_accuracy: 1.0000\n",
      "Epoch 354/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2757 - binary_accuracy: 1.0000\n",
      "Epoch 355/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2754 - binary_accuracy: 1.0000\n",
      "Epoch 356/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2752 - binary_accuracy: 1.0000\n",
      "Epoch 357/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2749 - binary_accuracy: 1.0000\n",
      "Epoch 358/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2746 - binary_accuracy: 1.0000\n",
      "Epoch 359/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2744 - binary_accuracy: 1.0000\n",
      "Epoch 360/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2741 - binary_accuracy: 1.0000\n",
      "Epoch 361/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2739 - binary_accuracy: 1.0000\n",
      "Epoch 362/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2736 - binary_accuracy: 1.0000\n",
      "Epoch 363/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2733 - binary_accuracy: 1.0000\n",
      "Epoch 364/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2731 - binary_accuracy: 1.0000\n",
      "Epoch 365/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2728 - binary_accuracy: 1.0000\n",
      "Epoch 366/1200\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2726 - binary_accuracy: 1.0000\n",
      "Epoch 367/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2723 - binary_accuracy: 1.0000\n",
      "Epoch 368/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2721 - binary_accuracy: 1.0000\n",
      "Epoch 369/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2718 - binary_accuracy: 1.0000\n",
      "Epoch 370/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2715 - binary_accuracy: 1.0000\n",
      "Epoch 371/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2713 - binary_accuracy: 1.0000\n",
      "Epoch 372/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2710 - binary_accuracy: 1.0000\n",
      "Epoch 373/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2708 - binary_accuracy: 1.0000\n",
      "Epoch 374/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2705 - binary_accuracy: 1.0000\n",
      "Epoch 375/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2703 - binary_accuracy: 1.0000\n",
      "Epoch 376/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2700 - binary_accuracy: 1.0000\n",
      "Epoch 377/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2698 - binary_accuracy: 1.0000\n",
      "Epoch 378/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2695 - binary_accuracy: 1.0000\n",
      "Epoch 379/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2693 - binary_accuracy: 1.0000\n",
      "Epoch 380/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2690 - binary_accuracy: 1.0000\n",
      "Epoch 381/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2688 - binary_accuracy: 1.0000\n",
      "Epoch 382/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2685 - binary_accuracy: 1.0000\n",
      "Epoch 383/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2683 - binary_accuracy: 1.0000\n",
      "Epoch 384/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2680 - binary_accuracy: 1.0000\n",
      "Epoch 385/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2678 - binary_accuracy: 1.0000\n",
      "Epoch 386/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2675 - binary_accuracy: 1.0000\n",
      "Epoch 387/1200\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2673 - binary_accuracy: 1.0000\n",
      "Epoch 388/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2670 - binary_accuracy: 1.0000\n",
      "Epoch 389/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2668 - binary_accuracy: 1.0000\n",
      "Epoch 390/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2665 - binary_accuracy: 1.0000\n",
      "Epoch 391/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2663 - binary_accuracy: 1.0000\n",
      "Epoch 392/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2660 - binary_accuracy: 1.0000\n",
      "Epoch 393/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2658 - binary_accuracy: 1.0000\n",
      "Epoch 394/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2655 - binary_accuracy: 1.0000\n",
      "Epoch 395/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2653 - binary_accuracy: 1.0000\n",
      "Epoch 396/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2650 - binary_accuracy: 1.0000\n",
      "Epoch 397/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2648 - binary_accuracy: 1.0000\n",
      "Epoch 398/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2646 - binary_accuracy: 1.0000\n",
      "Epoch 399/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2643 - binary_accuracy: 1.0000\n",
      "Epoch 400/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2641 - binary_accuracy: 1.0000\n",
      "Epoch 401/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2638 - binary_accuracy: 1.0000\n",
      "Epoch 402/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2636 - binary_accuracy: 1.0000\n",
      "Epoch 403/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2633 - binary_accuracy: 1.0000\n",
      "Epoch 404/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2631 - binary_accuracy: 1.0000\n",
      "Epoch 405/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2629 - binary_accuracy: 1.0000\n",
      "Epoch 406/1200\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2626 - binary_accuracy: 1.0000\n",
      "Epoch 407/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2624 - binary_accuracy: 1.0000\n",
      "Epoch 408/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2621 - binary_accuracy: 1.0000\n",
      "Epoch 409/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2619 - binary_accuracy: 1.0000\n",
      "Epoch 410/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2617 - binary_accuracy: 1.0000\n",
      "Epoch 411/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2614 - binary_accuracy: 1.0000\n",
      "Epoch 412/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2612 - binary_accuracy: 1.0000\n",
      "Epoch 413/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2610 - binary_accuracy: 1.0000\n",
      "Epoch 414/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2607 - binary_accuracy: 1.0000\n",
      "Epoch 415/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2605 - binary_accuracy: 1.0000\n",
      "Epoch 416/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2602 - binary_accuracy: 1.0000\n",
      "Epoch 417/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2600 - binary_accuracy: 1.0000\n",
      "Epoch 418/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2598 - binary_accuracy: 1.0000\n",
      "Epoch 419/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2595 - binary_accuracy: 1.0000\n",
      "Epoch 420/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2593 - binary_accuracy: 1.0000\n",
      "Epoch 421/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2591 - binary_accuracy: 1.0000\n",
      "Epoch 422/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2588 - binary_accuracy: 1.0000\n",
      "Epoch 423/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2586 - binary_accuracy: 1.0000\n",
      "Epoch 424/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2584 - binary_accuracy: 1.0000\n",
      "Epoch 425/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2581 - binary_accuracy: 1.0000\n",
      "Epoch 426/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2579 - binary_accuracy: 1.0000\n",
      "Epoch 427/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2577 - binary_accuracy: 1.0000\n",
      "Epoch 428/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2574 - binary_accuracy: 1.0000\n",
      "Epoch 429/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2572 - binary_accuracy: 1.0000\n",
      "Epoch 430/1200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2570 - binary_accuracy: 1.0000\n",
      "Epoch 431/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2568 - binary_accuracy: 1.0000\n",
      "Epoch 432/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2565 - binary_accuracy: 1.0000\n",
      "Epoch 433/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2563 - binary_accuracy: 1.0000\n",
      "Epoch 434/1200\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2561 - binary_accuracy: 1.0000\n",
      "Epoch 435/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2558 - binary_accuracy: 1.0000\n",
      "Epoch 436/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2556 - binary_accuracy: 1.0000\n",
      "Epoch 437/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2554 - binary_accuracy: 1.0000\n",
      "Epoch 438/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2552 - binary_accuracy: 1.0000\n",
      "Epoch 439/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2549 - binary_accuracy: 1.0000\n",
      "Epoch 440/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2547 - binary_accuracy: 1.0000\n",
      "Epoch 441/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2545 - binary_accuracy: 1.0000\n",
      "Epoch 442/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2542 - binary_accuracy: 1.0000\n",
      "Epoch 443/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2540 - binary_accuracy: 1.0000\n",
      "Epoch 444/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2538 - binary_accuracy: 1.0000\n",
      "Epoch 445/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2536 - binary_accuracy: 1.0000\n",
      "Epoch 446/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2533 - binary_accuracy: 1.0000\n",
      "Epoch 447/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2531 - binary_accuracy: 1.0000\n",
      "Epoch 448/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2529 - binary_accuracy: 1.0000\n",
      "Epoch 449/1200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2527 - binary_accuracy: 1.0000\n",
      "Epoch 450/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2525 - binary_accuracy: 1.0000\n",
      "Epoch 451/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2522 - binary_accuracy: 1.0000\n",
      "Epoch 452/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2520 - binary_accuracy: 1.0000\n",
      "Epoch 453/1200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2518 - binary_accuracy: 1.0000\n",
      "Epoch 454/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2516 - binary_accuracy: 1.0000\n",
      "Epoch 455/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2513 - binary_accuracy: 1.0000\n",
      "Epoch 456/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2511 - binary_accuracy: 1.0000\n",
      "Epoch 457/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2509 - binary_accuracy: 1.0000\n",
      "Epoch 458/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6290 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.2507 - binary_accuracy: 1.0000\n",
      "Epoch 459/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2505 - binary_accuracy: 1.0000\n",
      "Epoch 460/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2502 - binary_accuracy: 1.0000\n",
      "Epoch 461/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2500 - binary_accuracy: 1.0000\n",
      "Epoch 462/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2498 - binary_accuracy: 1.0000\n",
      "Epoch 463/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2496 - binary_accuracy: 1.0000\n",
      "Epoch 464/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2494 - binary_accuracy: 1.0000\n",
      "Epoch 465/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2492 - binary_accuracy: 1.0000\n",
      "Epoch 466/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2489 - binary_accuracy: 1.0000\n",
      "Epoch 467/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2487 - binary_accuracy: 1.0000\n",
      "Epoch 468/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2485 - binary_accuracy: 1.0000\n",
      "Epoch 469/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2483 - binary_accuracy: 1.0000\n",
      "Epoch 470/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2481 - binary_accuracy: 1.0000\n",
      "Epoch 471/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2479 - binary_accuracy: 1.0000\n",
      "Epoch 472/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2476 - binary_accuracy: 1.0000\n",
      "Epoch 473/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2474 - binary_accuracy: 1.0000\n",
      "Epoch 474/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2472 - binary_accuracy: 1.0000\n",
      "Epoch 475/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2470 - binary_accuracy: 1.0000\n",
      "Epoch 476/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2468 - binary_accuracy: 1.0000\n",
      "Epoch 477/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2466 - binary_accuracy: 1.0000\n",
      "Epoch 478/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2464 - binary_accuracy: 1.0000\n",
      "Epoch 479/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2461 - binary_accuracy: 1.0000\n",
      "Epoch 480/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2459 - binary_accuracy: 1.0000\n",
      "Epoch 481/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2457 - binary_accuracy: 1.0000\n",
      "Epoch 482/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2455 - binary_accuracy: 1.0000\n",
      "Epoch 483/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2453 - binary_accuracy: 1.0000\n",
      "Epoch 484/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2451 - binary_accuracy: 1.0000\n",
      "Epoch 485/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2449 - binary_accuracy: 1.0000\n",
      "Epoch 486/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2447 - binary_accuracy: 1.0000\n",
      "Epoch 487/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2445 - binary_accuracy: 1.0000\n",
      "Epoch 488/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2443 - binary_accuracy: 1.0000\n",
      "Epoch 489/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2440 - binary_accuracy: 1.0000\n",
      "Epoch 490/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2438 - binary_accuracy: 1.0000\n",
      "Epoch 491/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2436 - binary_accuracy: 1.0000\n",
      "Epoch 492/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2434 - binary_accuracy: 1.0000\n",
      "Epoch 493/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2432 - binary_accuracy: 1.0000\n",
      "Epoch 494/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2430 - binary_accuracy: 1.0000\n",
      "Epoch 495/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2428 - binary_accuracy: 1.0000\n",
      "Epoch 496/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2426 - binary_accuracy: 1.0000\n",
      "Epoch 497/1200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2424 - binary_accuracy: 1.0000\n",
      "Epoch 498/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2422 - binary_accuracy: 1.0000\n",
      "Epoch 499/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2420 - binary_accuracy: 1.0000\n",
      "Epoch 500/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2418 - binary_accuracy: 1.0000\n",
      "Epoch 501/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2416 - binary_accuracy: 1.0000\n",
      "Epoch 502/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2414 - binary_accuracy: 1.0000\n",
      "Epoch 503/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2412 - binary_accuracy: 1.0000\n",
      "Epoch 504/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2409 - binary_accuracy: 1.0000\n",
      "Epoch 505/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2407 - binary_accuracy: 1.0000\n",
      "Epoch 506/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2405 - binary_accuracy: 1.0000\n",
      "Epoch 507/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2403 - binary_accuracy: 1.0000\n",
      "Epoch 508/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6008 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.2401 - binary_accuracy: 1.0000\n",
      "Epoch 509/1200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2399 - binary_accuracy: 1.0000\n",
      "Epoch 510/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2397 - binary_accuracy: 1.0000\n",
      "Epoch 511/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2395 - binary_accuracy: 1.0000\n",
      "Epoch 512/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2393 - binary_accuracy: 1.0000\n",
      "Epoch 513/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2391 - binary_accuracy: 1.0000\n",
      "Epoch 514/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2389 - binary_accuracy: 1.0000\n",
      "Epoch 515/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2387 - binary_accuracy: 1.0000\n",
      "Epoch 516/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2385 - binary_accuracy: 1.0000\n",
      "Epoch 517/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2383 - binary_accuracy: 1.0000\n",
      "Epoch 518/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2381 - binary_accuracy: 1.0000\n",
      "Epoch 519/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2379 - binary_accuracy: 1.0000\n",
      "Epoch 520/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2377 - binary_accuracy: 1.0000\n",
      "Epoch 521/1200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2375 - binary_accuracy: 1.0000\n",
      "Epoch 522/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2373 - binary_accuracy: 1.0000\n",
      "Epoch 523/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2371 - binary_accuracy: 1.0000\n",
      "Epoch 524/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2369 - binary_accuracy: 1.0000\n",
      "Epoch 525/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2367 - binary_accuracy: 1.0000\n",
      "Epoch 526/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2365 - binary_accuracy: 1.0000\n",
      "Epoch 527/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2363 - binary_accuracy: 1.0000\n",
      "Epoch 528/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2361 - binary_accuracy: 1.0000\n",
      "Epoch 529/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2359 - binary_accuracy: 1.0000\n",
      "Epoch 530/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2358 - binary_accuracy: 1.0000\n",
      "Epoch 531/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2356 - binary_accuracy: 1.0000\n",
      "Epoch 532/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2354 - binary_accuracy: 1.0000\n",
      "Epoch 533/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2352 - binary_accuracy: 1.0000\n",
      "Epoch 534/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2350 - binary_accuracy: 1.0000\n",
      "Epoch 535/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2348 - binary_accuracy: 1.0000\n",
      "Epoch 536/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2346 - binary_accuracy: 1.0000\n",
      "Epoch 537/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2344 - binary_accuracy: 1.0000\n",
      "Epoch 538/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2342 - binary_accuracy: 1.0000\n",
      "Epoch 539/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2340 - binary_accuracy: 1.0000\n",
      "Epoch 540/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2338 - binary_accuracy: 1.0000\n",
      "Epoch 541/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2336 - binary_accuracy: 1.0000\n",
      "Epoch 542/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2334 - binary_accuracy: 1.0000\n",
      "Epoch 543/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2332 - binary_accuracy: 1.0000\n",
      "Epoch 544/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2330 - binary_accuracy: 1.0000\n",
      "Epoch 545/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2329 - binary_accuracy: 1.0000\n",
      "Epoch 546/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2327 - binary_accuracy: 1.0000\n",
      "Epoch 547/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2325 - binary_accuracy: 1.0000\n",
      "Epoch 548/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2323 - binary_accuracy: 1.0000\n",
      "Epoch 549/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2321 - binary_accuracy: 1.0000\n",
      "Epoch 550/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2319 - binary_accuracy: 1.0000\n",
      "Epoch 551/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2317 - binary_accuracy: 1.0000\n",
      "Epoch 552/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2315 - binary_accuracy: 1.0000\n",
      "Epoch 553/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2313 - binary_accuracy: 1.0000\n",
      "Epoch 554/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2311 - binary_accuracy: 1.0000\n",
      "Epoch 555/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2310 - binary_accuracy: 1.0000\n",
      "Epoch 556/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2308 - binary_accuracy: 1.0000\n",
      "Epoch 557/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2306 - binary_accuracy: 1.0000\n",
      "Epoch 558/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2304 - binary_accuracy: 1.0000\n",
      "Epoch 559/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2302 - binary_accuracy: 1.0000\n",
      "Epoch 560/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2300 - binary_accuracy: 1.0000\n",
      "Epoch 561/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2298 - binary_accuracy: 1.0000\n",
      "Epoch 562/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2296 - binary_accuracy: 1.0000\n",
      "Epoch 563/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5719 - binary_accuracy: 1.000 - 0s 3ms/step - loss: 0.2295 - binary_accuracy: 1.0000\n",
      "Epoch 564/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2293 - binary_accuracy: 1.0000\n",
      "Epoch 565/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2291 - binary_accuracy: 1.0000\n",
      "Epoch 566/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2289 - binary_accuracy: 1.0000\n",
      "Epoch 567/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2287 - binary_accuracy: 1.0000\n",
      "Epoch 568/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2285 - binary_accuracy: 1.0000\n",
      "Epoch 569/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2283 - binary_accuracy: 1.0000\n",
      "Epoch 570/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2282 - binary_accuracy: 1.0000\n",
      "Epoch 571/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2280 - binary_accuracy: 1.0000\n",
      "Epoch 572/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2278 - binary_accuracy: 1.0000\n",
      "Epoch 573/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2276 - binary_accuracy: 1.0000\n",
      "Epoch 574/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2274 - binary_accuracy: 1.0000\n",
      "Epoch 575/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2272 - binary_accuracy: 1.0000\n",
      "Epoch 576/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2271 - binary_accuracy: 1.0000\n",
      "Epoch 577/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2269 - binary_accuracy: 1.0000\n",
      "Epoch 578/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2267 - binary_accuracy: 1.0000\n",
      "Epoch 579/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2265 - binary_accuracy: 1.0000\n",
      "Epoch 580/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2263 - binary_accuracy: 1.0000\n",
      "Epoch 581/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2262 - binary_accuracy: 1.0000\n",
      "Epoch 582/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2260 - binary_accuracy: 1.0000\n",
      "Epoch 583/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2258 - binary_accuracy: 1.0000\n",
      "Epoch 584/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2256 - binary_accuracy: 1.0000\n",
      "Epoch 585/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2254 - binary_accuracy: 1.0000\n",
      "Epoch 586/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2253 - binary_accuracy: 1.0000\n",
      "Epoch 587/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2251 - binary_accuracy: 1.0000\n",
      "Epoch 588/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2249 - binary_accuracy: 1.0000\n",
      "Epoch 589/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2247 - binary_accuracy: 1.0000\n",
      "Epoch 590/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2245 - binary_accuracy: 1.0000\n",
      "Epoch 591/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2244 - binary_accuracy: 1.0000\n",
      "Epoch 592/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5575 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.2242 - binary_accuracy: 1.0000\n",
      "Epoch 593/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2240 - binary_accuracy: 1.0000\n",
      "Epoch 594/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5565 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.2238 - binary_accuracy: 1.0000\n",
      "Epoch 595/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2236 - binary_accuracy: 1.0000\n",
      "Epoch 596/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2235 - binary_accuracy: 1.0000\n",
      "Epoch 597/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2233 - binary_accuracy: 1.0000\n",
      "Epoch 598/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2231 - binary_accuracy: 1.0000\n",
      "Epoch 599/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2229 - binary_accuracy: 1.0000\n",
      "Epoch 600/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2228 - binary_accuracy: 1.0000\n",
      "Epoch 601/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2226 - binary_accuracy: 1.0000\n",
      "Epoch 602/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2224 - binary_accuracy: 1.0000\n",
      "Epoch 603/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2222 - binary_accuracy: 1.0000\n",
      "Epoch 604/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2221 - binary_accuracy: 1.0000\n",
      "Epoch 605/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2219 - binary_accuracy: 1.0000\n",
      "Epoch 606/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2217 - binary_accuracy: 1.0000\n",
      "Epoch 607/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2215 - binary_accuracy: 1.0000\n",
      "Epoch 608/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2214 - binary_accuracy: 1.0000\n",
      "Epoch 609/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2212 - binary_accuracy: 1.0000\n",
      "Epoch 610/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2210 - binary_accuracy: 1.0000\n",
      "Epoch 611/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2208 - binary_accuracy: 1.0000\n",
      "Epoch 612/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2207 - binary_accuracy: 1.0000\n",
      "Epoch 613/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2205 - binary_accuracy: 1.0000\n",
      "Epoch 614/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2203 - binary_accuracy: 1.0000\n",
      "Epoch 615/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2202 - binary_accuracy: 1.0000\n",
      "Epoch 616/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2200 - binary_accuracy: 1.0000\n",
      "Epoch 617/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2198 - binary_accuracy: 1.0000\n",
      "Epoch 618/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2196 - binary_accuracy: 1.0000\n",
      "Epoch 619/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2195 - binary_accuracy: 1.0000\n",
      "Epoch 620/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2193 - binary_accuracy: 1.0000\n",
      "Epoch 621/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2191 - binary_accuracy: 1.0000\n",
      "Epoch 622/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5432 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.2190 - binary_accuracy: 1.0000\n",
      "Epoch 623/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2188 - binary_accuracy: 1.0000\n",
      "Epoch 624/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2186 - binary_accuracy: 1.0000\n",
      "Epoch 625/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2184 - binary_accuracy: 1.0000\n",
      "Epoch 626/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2183 - binary_accuracy: 1.0000\n",
      "Epoch 627/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2181 - binary_accuracy: 1.0000\n",
      "Epoch 628/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2179 - binary_accuracy: 1.0000\n",
      "Epoch 629/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2178 - binary_accuracy: 1.0000\n",
      "Epoch 630/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2176 - binary_accuracy: 1.0000\n",
      "Epoch 631/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2174 - binary_accuracy: 1.0000\n",
      "Epoch 632/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2173 - binary_accuracy: 1.0000\n",
      "Epoch 633/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2171 - binary_accuracy: 1.0000\n",
      "Epoch 634/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2169 - binary_accuracy: 1.0000\n",
      "Epoch 635/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2168 - binary_accuracy: 1.0000\n",
      "Epoch 636/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2166 - binary_accuracy: 1.0000\n",
      "Epoch 637/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2164 - binary_accuracy: 1.0000\n",
      "Epoch 638/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2163 - binary_accuracy: 1.0000\n",
      "Epoch 639/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2161 - binary_accuracy: 1.0000\n",
      "Epoch 640/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2159 - binary_accuracy: 1.0000\n",
      "Epoch 641/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2158 - binary_accuracy: 1.0000\n",
      "Epoch 642/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2156 - binary_accuracy: 1.0000\n",
      "Epoch 643/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2154 - binary_accuracy: 1.0000\n",
      "Epoch 644/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2153 - binary_accuracy: 1.0000\n",
      "Epoch 645/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2151 - binary_accuracy: 1.0000\n",
      "Epoch 646/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2149 - binary_accuracy: 1.0000\n",
      "Epoch 647/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2148 - binary_accuracy: 1.0000\n",
      "Epoch 648/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2146 - binary_accuracy: 1.0000\n",
      "Epoch 649/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2144 - binary_accuracy: 1.0000\n",
      "Epoch 650/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2143 - binary_accuracy: 1.0000\n",
      "Epoch 651/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2141 - binary_accuracy: 1.0000\n",
      "Epoch 652/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2140 - binary_accuracy: 1.0000\n",
      "Epoch 653/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2138 - binary_accuracy: 1.0000\n",
      "Epoch 654/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2136 - binary_accuracy: 1.0000\n",
      "Epoch 655/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2135 - binary_accuracy: 1.0000\n",
      "Epoch 656/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2133 - binary_accuracy: 1.0000\n",
      "Epoch 657/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2131 - binary_accuracy: 1.0000\n",
      "Epoch 658/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2130 - binary_accuracy: 1.0000\n",
      "Epoch 659/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2128 - binary_accuracy: 1.0000\n",
      "Epoch 660/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2127 - binary_accuracy: 1.0000\n",
      "Epoch 661/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2125 - binary_accuracy: 1.0000\n",
      "Epoch 662/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2123 - binary_accuracy: 1.0000\n",
      "Epoch 663/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2122 - binary_accuracy: 1.0000\n",
      "Epoch 664/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2120 - binary_accuracy: 1.0000\n",
      "Epoch 665/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2119 - binary_accuracy: 1.0000\n",
      "Epoch 666/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2117 - binary_accuracy: 1.0000\n",
      "Epoch 667/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2115 - binary_accuracy: 1.0000\n",
      "Epoch 668/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2114 - binary_accuracy: 1.0000\n",
      "Epoch 669/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2112 - binary_accuracy: 1.0000\n",
      "Epoch 670/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2111 - binary_accuracy: 1.0000\n",
      "Epoch 671/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2109 - binary_accuracy: 1.0000\n",
      "Epoch 672/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2107 - binary_accuracy: 1.0000\n",
      "Epoch 673/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2106 - binary_accuracy: 1.0000\n",
      "Epoch 674/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2104 - binary_accuracy: 1.0000\n",
      "Epoch 675/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2103 - binary_accuracy: 1.0000\n",
      "Epoch 676/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2101 - binary_accuracy: 1.0000\n",
      "Epoch 677/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2100 - binary_accuracy: 1.0000\n",
      "Epoch 678/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2098 - binary_accuracy: 1.0000\n",
      "Epoch 679/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2096 - binary_accuracy: 1.0000\n",
      "Epoch 680/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2095 - binary_accuracy: 1.0000\n",
      "Epoch 681/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2093 - binary_accuracy: 1.0000\n",
      "Epoch 682/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2092 - binary_accuracy: 1.0000\n",
      "Epoch 683/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2090 - binary_accuracy: 1.0000\n",
      "Epoch 684/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2089 - binary_accuracy: 1.0000\n",
      "Epoch 685/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2087 - binary_accuracy: 1.0000\n",
      "Epoch 686/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2085 - binary_accuracy: 1.0000\n",
      "Epoch 687/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2084 - binary_accuracy: 1.0000\n",
      "Epoch 688/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2082 - binary_accuracy: 1.0000\n",
      "Epoch 689/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2081 - binary_accuracy: 1.0000\n",
      "Epoch 690/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2079 - binary_accuracy: 1.0000\n",
      "Epoch 691/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2078 - binary_accuracy: 1.0000\n",
      "Epoch 692/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2076 - binary_accuracy: 1.0000\n",
      "Epoch 693/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2075 - binary_accuracy: 1.0000\n",
      "Epoch 694/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2073 - binary_accuracy: 1.0000\n",
      "Epoch 695/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2072 - binary_accuracy: 1.0000\n",
      "Epoch 696/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2070 - binary_accuracy: 1.0000\n",
      "Epoch 697/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2069 - binary_accuracy: 1.0000\n",
      "Epoch 698/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2067 - binary_accuracy: 1.0000\n",
      "Epoch 699/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2065 - binary_accuracy: 1.0000\n",
      "Epoch 700/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2064 - binary_accuracy: 1.0000\n",
      "Epoch 701/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2062 - binary_accuracy: 1.0000\n",
      "Epoch 702/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2061 - binary_accuracy: 1.0000\n",
      "Epoch 703/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2059 - binary_accuracy: 1.0000\n",
      "Epoch 704/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2058 - binary_accuracy: 1.0000\n",
      "Epoch 705/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2056 - binary_accuracy: 1.0000\n",
      "Epoch 706/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2055 - binary_accuracy: 1.0000\n",
      "Epoch 707/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2053 - binary_accuracy: 1.0000\n",
      "Epoch 708/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2052 - binary_accuracy: 1.0000\n",
      "Epoch 709/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2050 - binary_accuracy: 1.0000\n",
      "Epoch 710/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2049 - binary_accuracy: 1.0000\n",
      "Epoch 711/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2047 - binary_accuracy: 1.0000\n",
      "Epoch 712/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2046 - binary_accuracy: 1.0000\n",
      "Epoch 713/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2044 - binary_accuracy: 1.0000\n",
      "Epoch 714/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2043 - binary_accuracy: 1.0000\n",
      "Epoch 715/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2041 - binary_accuracy: 1.0000\n",
      "Epoch 716/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2040 - binary_accuracy: 1.0000\n",
      "Epoch 717/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2038 - binary_accuracy: 1.0000\n",
      "Epoch 718/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2037 - binary_accuracy: 1.0000\n",
      "Epoch 719/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2035 - binary_accuracy: 1.0000\n",
      "Epoch 720/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2034 - binary_accuracy: 1.0000\n",
      "Epoch 721/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5001 - binary_accuracy: 1.000 - 0s 1ms/step - loss: 0.2032 - binary_accuracy: 1.0000\n",
      "Epoch 722/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2031 - binary_accuracy: 1.0000\n",
      "Epoch 723/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2029 - binary_accuracy: 1.0000\n",
      "Epoch 724/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2028 - binary_accuracy: 1.0000\n",
      "Epoch 725/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2027 - binary_accuracy: 1.0000\n",
      "Epoch 726/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2025 - binary_accuracy: 1.0000\n",
      "Epoch 727/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2024 - binary_accuracy: 1.0000\n",
      "Epoch 728/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2022 - binary_accuracy: 1.0000\n",
      "Epoch 729/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2021 - binary_accuracy: 1.0000\n",
      "Epoch 730/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2019 - binary_accuracy: 1.0000\n",
      "Epoch 731/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2018 - binary_accuracy: 1.0000\n",
      "Epoch 732/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2016 - binary_accuracy: 1.0000\n",
      "Epoch 733/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2015 - binary_accuracy: 1.0000\n",
      "Epoch 734/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2013 - binary_accuracy: 1.0000\n",
      "Epoch 735/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2012 - binary_accuracy: 1.0000\n",
      "Epoch 736/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2010 - binary_accuracy: 1.0000\n",
      "Epoch 737/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2009 - binary_accuracy: 1.0000\n",
      "Epoch 738/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2008 - binary_accuracy: 1.0000\n",
      "Epoch 739/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2006 - binary_accuracy: 1.0000\n",
      "Epoch 740/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2005 - binary_accuracy: 1.0000\n",
      "Epoch 741/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2003 - binary_accuracy: 1.0000\n",
      "Epoch 742/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2002 - binary_accuracy: 1.0000\n",
      "Epoch 743/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2000 - binary_accuracy: 1.0000\n",
      "Epoch 744/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1999 - binary_accuracy: 1.0000\n",
      "Epoch 745/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1997 - binary_accuracy: 1.0000\n",
      "Epoch 746/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1996 - binary_accuracy: 1.0000\n",
      "Epoch 747/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1995 - binary_accuracy: 1.0000\n",
      "Epoch 748/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1993 - binary_accuracy: 1.0000\n",
      "Epoch 749/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1992 - binary_accuracy: 1.0000\n",
      "Epoch 750/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1990 - binary_accuracy: 1.0000\n",
      "Epoch 751/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1989 - binary_accuracy: 1.0000\n",
      "Epoch 752/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1988 - binary_accuracy: 1.0000\n",
      "Epoch 753/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1986 - binary_accuracy: 1.0000\n",
      "Epoch 754/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1985 - binary_accuracy: 1.0000\n",
      "Epoch 755/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1983 - binary_accuracy: 1.0000\n",
      "Epoch 756/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1982 - binary_accuracy: 1.0000\n",
      "Epoch 757/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1980 - binary_accuracy: 1.0000\n",
      "Epoch 758/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1979 - binary_accuracy: 1.0000\n",
      "Epoch 759/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1978 - binary_accuracy: 1.0000\n",
      "Epoch 760/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1976 - binary_accuracy: 1.0000\n",
      "Epoch 761/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1975 - binary_accuracy: 1.0000\n",
      "Epoch 762/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1973 - binary_accuracy: 1.0000\n",
      "Epoch 763/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1972 - binary_accuracy: 1.0000\n",
      "Epoch 764/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1971 - binary_accuracy: 1.0000\n",
      "Epoch 765/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1969 - binary_accuracy: 1.0000\n",
      "Epoch 766/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1968 - binary_accuracy: 1.0000\n",
      "Epoch 767/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1966 - binary_accuracy: 1.0000\n",
      "Epoch 768/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1965 - binary_accuracy: 1.0000\n",
      "Epoch 769/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1964 - binary_accuracy: 1.0000\n",
      "Epoch 770/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1962 - binary_accuracy: 1.0000\n",
      "Epoch 771/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1961 - binary_accuracy: 1.0000\n",
      "Epoch 772/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1960 - binary_accuracy: 1.0000\n",
      "Epoch 773/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1958 - binary_accuracy: 1.0000\n",
      "Epoch 774/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1957 - binary_accuracy: 1.0000\n",
      "Epoch 775/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1955 - binary_accuracy: 1.0000\n",
      "Epoch 776/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1954 - binary_accuracy: 1.0000\n",
      "Epoch 777/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1953 - binary_accuracy: 1.0000\n",
      "Epoch 778/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1951 - binary_accuracy: 1.0000\n",
      "Epoch 779/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1950 - binary_accuracy: 1.0000\n",
      "Epoch 780/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1949 - binary_accuracy: 1.0000\n",
      "Epoch 781/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1947 - binary_accuracy: 1.0000\n",
      "Epoch 782/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1946 - binary_accuracy: 1.0000\n",
      "Epoch 783/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1944 - binary_accuracy: 1.0000\n",
      "Epoch 784/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1943 - binary_accuracy: 1.0000\n",
      "Epoch 785/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1942 - binary_accuracy: 1.0000\n",
      "Epoch 786/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1940 - binary_accuracy: 1.0000\n",
      "Epoch 787/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1939 - binary_accuracy: 1.0000\n",
      "Epoch 788/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1938 - binary_accuracy: 1.0000\n",
      "Epoch 789/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1936 - binary_accuracy: 1.0000\n",
      "Epoch 790/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1935 - binary_accuracy: 1.0000\n",
      "Epoch 791/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1934 - binary_accuracy: 1.0000\n",
      "Epoch 792/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1932 - binary_accuracy: 1.0000\n",
      "Epoch 793/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1931 - binary_accuracy: 1.0000\n",
      "Epoch 794/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1930 - binary_accuracy: 1.0000\n",
      "Epoch 795/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1928 - binary_accuracy: 1.0000\n",
      "Epoch 796/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1927 - binary_accuracy: 1.0000\n",
      "Epoch 797/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1926 - binary_accuracy: 1.0000\n",
      "Epoch 798/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1924 - binary_accuracy: 1.0000\n",
      "Epoch 799/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1923 - binary_accuracy: 1.0000\n",
      "Epoch 800/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1922 - binary_accuracy: 1.0000\n",
      "Epoch 801/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1920 - binary_accuracy: 1.0000\n",
      "Epoch 802/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1919 - binary_accuracy: 1.0000\n",
      "Epoch 803/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1918 - binary_accuracy: 1.0000\n",
      "Epoch 804/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1916 - binary_accuracy: 1.0000\n",
      "Epoch 805/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1915 - binary_accuracy: 1.0000\n",
      "Epoch 806/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1914 - binary_accuracy: 1.0000\n",
      "Epoch 807/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1912 - binary_accuracy: 1.0000\n",
      "Epoch 808/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1911 - binary_accuracy: 1.0000\n",
      "Epoch 809/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1910 - binary_accuracy: 1.0000\n",
      "Epoch 810/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1908 - binary_accuracy: 1.0000\n",
      "Epoch 811/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1907 - binary_accuracy: 1.0000\n",
      "Epoch 812/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1906 - binary_accuracy: 1.0000\n",
      "Epoch 813/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1904 - binary_accuracy: 1.0000\n",
      "Epoch 814/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1903 - binary_accuracy: 1.0000\n",
      "Epoch 815/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1902 - binary_accuracy: 1.0000\n",
      "Epoch 816/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1901 - binary_accuracy: 1.0000\n",
      "Epoch 817/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 1.0000\n",
      "Epoch 818/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 1.0000\n",
      "Epoch 819/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1897 - binary_accuracy: 1.0000\n",
      "Epoch 820/1200\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.1895 - binary_accuracy: 1.0000\n",
      "Epoch 821/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1894 - binary_accuracy: 1.0000\n",
      "Epoch 822/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1893 - binary_accuracy: 1.0000\n",
      "Epoch 823/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1891 - binary_accuracy: 1.0000\n",
      "Epoch 824/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1890 - binary_accuracy: 1.0000\n",
      "Epoch 825/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1889 - binary_accuracy: 1.0000\n",
      "Epoch 826/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1888 - binary_accuracy: 1.0000\n",
      "Epoch 827/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1886 - binary_accuracy: 1.0000\n",
      "Epoch 828/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1885 - binary_accuracy: 1.0000\n",
      "Epoch 829/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1884 - binary_accuracy: 1.0000\n",
      "Epoch 830/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1882 - binary_accuracy: 1.0000\n",
      "Epoch 831/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1881 - binary_accuracy: 1.0000\n",
      "Epoch 832/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1880 - binary_accuracy: 1.0000\n",
      "Epoch 833/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1879 - binary_accuracy: 1.0000\n",
      "Epoch 834/1200\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1877 - binary_accuracy: 1.0000\n",
      "Epoch 835/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1876 - binary_accuracy: 1.0000\n",
      "Epoch 836/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1875 - binary_accuracy: 1.0000\n",
      "Epoch 837/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1874 - binary_accuracy: 1.0000\n",
      "Epoch 838/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1872 - binary_accuracy: 1.0000\n",
      "Epoch 839/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1871 - binary_accuracy: 1.0000\n",
      "Epoch 840/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1870 - binary_accuracy: 1.0000\n",
      "Epoch 841/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1868 - binary_accuracy: 1.0000\n",
      "Epoch 842/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1867 - binary_accuracy: 1.0000\n",
      "Epoch 843/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1866 - binary_accuracy: 1.0000\n",
      "Epoch 844/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1865 - binary_accuracy: 1.0000\n",
      "Epoch 845/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1863 - binary_accuracy: 1.0000\n",
      "Epoch 846/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1862 - binary_accuracy: 1.0000\n",
      "Epoch 847/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1861 - binary_accuracy: 1.0000\n",
      "Epoch 848/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1860 - binary_accuracy: 1.0000\n",
      "Epoch 849/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1858 - binary_accuracy: 1.0000\n",
      "Epoch 850/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1857 - binary_accuracy: 1.0000\n",
      "Epoch 851/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1856 - binary_accuracy: 1.0000\n",
      "Epoch 852/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1855 - binary_accuracy: 1.0000\n",
      "Epoch 853/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1853 - binary_accuracy: 1.0000\n",
      "Epoch 854/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1852 - binary_accuracy: 1.0000\n",
      "Epoch 855/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1851 - binary_accuracy: 1.0000\n",
      "Epoch 856/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1850 - binary_accuracy: 1.0000\n",
      "Epoch 857/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1848 - binary_accuracy: 1.0000\n",
      "Epoch 858/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1847 - binary_accuracy: 1.0000\n",
      "Epoch 859/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1846 - binary_accuracy: 1.0000\n",
      "Epoch 860/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1845 - binary_accuracy: 1.0000\n",
      "Epoch 861/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1844 - binary_accuracy: 1.0000\n",
      "Epoch 862/1200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1842 - binary_accuracy: 1.0000\n",
      "Epoch 863/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1841 - binary_accuracy: 1.0000\n",
      "Epoch 864/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1840 - binary_accuracy: 1.0000\n",
      "Epoch 865/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1839 - binary_accuracy: 1.0000\n",
      "Epoch 866/1200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1837 - binary_accuracy: 1.0000\n",
      "Epoch 867/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1836 - binary_accuracy: 1.0000\n",
      "Epoch 868/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1835 - binary_accuracy: 1.0000\n",
      "Epoch 869/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1834 - binary_accuracy: 1.0000\n",
      "Epoch 870/1200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1833 - binary_accuracy: 1.0000\n",
      "Epoch 871/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1831 - binary_accuracy: 1.0000\n",
      "Epoch 872/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1830 - binary_accuracy: 1.0000\n",
      "Epoch 873/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1829 - binary_accuracy: 1.0000\n",
      "Epoch 874/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1828 - binary_accuracy: 1.0000\n",
      "Epoch 875/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1826 - binary_accuracy: 1.0000\n",
      "Epoch 876/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1825 - binary_accuracy: 1.0000\n",
      "Epoch 877/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1824 - binary_accuracy: 1.0000\n",
      "Epoch 878/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1823 - binary_accuracy: 1.0000\n",
      "Epoch 879/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1822 - binary_accuracy: 1.0000\n",
      "Epoch 880/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1820 - binary_accuracy: 1.0000\n",
      "Epoch 881/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1819 - binary_accuracy: 1.0000\n",
      "Epoch 882/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1818 - binary_accuracy: 1.0000\n",
      "Epoch 883/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1817 - binary_accuracy: 1.0000\n",
      "Epoch 884/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1816 - binary_accuracy: 1.0000\n",
      "Epoch 885/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1814 - binary_accuracy: 1.0000\n",
      "Epoch 886/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4406 - binary_accuracy: 1.000 - 0s 3ms/step - loss: 0.1813 - binary_accuracy: 1.0000\n",
      "Epoch 887/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1812 - binary_accuracy: 1.0000\n",
      "Epoch 888/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1811 - binary_accuracy: 1.0000\n",
      "Epoch 889/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1810 - binary_accuracy: 1.0000\n",
      "Epoch 890/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1809 - binary_accuracy: 1.0000\n",
      "Epoch 891/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1807 - binary_accuracy: 1.0000\n",
      "Epoch 892/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1806 - binary_accuracy: 1.0000\n",
      "Epoch 893/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1805 - binary_accuracy: 1.0000\n",
      "Epoch 894/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1804 - binary_accuracy: 1.0000\n",
      "Epoch 895/1200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1803 - binary_accuracy: 1.0000\n",
      "Epoch 896/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1801 - binary_accuracy: 1.0000\n",
      "Epoch 897/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1800 - binary_accuracy: 1.0000\n",
      "Epoch 898/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1799 - binary_accuracy: 1.0000\n",
      "Epoch 899/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1798 - binary_accuracy: 1.0000\n",
      "Epoch 900/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1797 - binary_accuracy: 1.0000\n",
      "Epoch 901/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1796 - binary_accuracy: 1.0000\n",
      "Epoch 902/1200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1794 - binary_accuracy: 1.0000\n",
      "Epoch 903/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1793 - binary_accuracy: 1.0000\n",
      "Epoch 904/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1792 - binary_accuracy: 1.0000\n",
      "Epoch 905/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4345 - binary_accuracy: 1.000 - 0s 5ms/step - loss: 0.1791 - binary_accuracy: 1.0000\n",
      "Epoch 906/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1790 - binary_accuracy: 1.0000\n",
      "Epoch 907/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1789 - binary_accuracy: 1.0000\n",
      "Epoch 908/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1787 - binary_accuracy: 1.0000\n",
      "Epoch 909/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4333 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.1786 - binary_accuracy: 1.0000\n",
      "Epoch 910/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1785 - binary_accuracy: 1.0000\n",
      "Epoch 911/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1784 - binary_accuracy: 1.0000\n",
      "Epoch 912/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1783 - binary_accuracy: 1.0000\n",
      "Epoch 913/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1782 - binary_accuracy: 1.0000\n",
      "Epoch 914/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1780 - binary_accuracy: 1.0000\n",
      "Epoch 915/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1779 - binary_accuracy: 1.0000\n",
      "Epoch 916/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1778 - binary_accuracy: 1.0000\n",
      "Epoch 917/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1777 - binary_accuracy: 1.0000\n",
      "Epoch 918/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1776 - binary_accuracy: 1.0000\n",
      "Epoch 919/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1775 - binary_accuracy: 1.0000\n",
      "Epoch 920/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1774 - binary_accuracy: 1.0000\n",
      "Epoch 921/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1772 - binary_accuracy: 1.0000\n",
      "Epoch 922/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1771 - binary_accuracy: 1.0000\n",
      "Epoch 923/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1770 - binary_accuracy: 1.0000\n",
      "Epoch 924/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1769 - binary_accuracy: 1.0000\n",
      "Epoch 925/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1768 - binary_accuracy: 1.0000\n",
      "Epoch 926/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1767 - binary_accuracy: 1.0000\n",
      "Epoch 927/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1766 - binary_accuracy: 1.0000\n",
      "Epoch 928/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1764 - binary_accuracy: 1.0000\n",
      "Epoch 929/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1763 - binary_accuracy: 1.0000\n",
      "Epoch 930/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1762 - binary_accuracy: 1.0000\n",
      "Epoch 931/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1761 - binary_accuracy: 1.0000\n",
      "Epoch 932/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1760 - binary_accuracy: 1.0000\n",
      "Epoch 933/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1759 - binary_accuracy: 1.0000\n",
      "Epoch 934/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1758 - binary_accuracy: 1.0000\n",
      "Epoch 935/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1757 - binary_accuracy: 1.0000\n",
      "Epoch 936/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1755 - binary_accuracy: 1.0000\n",
      "Epoch 937/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1754 - binary_accuracy: 1.0000\n",
      "Epoch 938/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1753 - binary_accuracy: 1.0000\n",
      "Epoch 939/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1752 - binary_accuracy: 1.0000\n",
      "Epoch 940/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1751 - binary_accuracy: 1.0000\n",
      "Epoch 941/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1750 - binary_accuracy: 1.0000\n",
      "Epoch 942/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1749 - binary_accuracy: 1.0000\n",
      "Epoch 943/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1748 - binary_accuracy: 1.0000\n",
      "Epoch 944/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1747 - binary_accuracy: 1.0000\n",
      "Epoch 945/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1745 - binary_accuracy: 1.0000\n",
      "Epoch 946/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1744 - binary_accuracy: 1.0000\n",
      "Epoch 947/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1743 - binary_accuracy: 1.0000\n",
      "Epoch 948/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1742 - binary_accuracy: 1.0000\n",
      "Epoch 949/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1741 - binary_accuracy: 1.0000\n",
      "Epoch 950/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1740 - binary_accuracy: 1.0000\n",
      "Epoch 951/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1739 - binary_accuracy: 1.0000\n",
      "Epoch 952/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1738 - binary_accuracy: 1.0000\n",
      "Epoch 953/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1737 - binary_accuracy: 1.0000\n",
      "Epoch 954/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1736 - binary_accuracy: 1.0000\n",
      "Epoch 955/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1734 - binary_accuracy: 1.0000\n",
      "Epoch 956/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1733 - binary_accuracy: 1.0000\n",
      "Epoch 957/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1732 - binary_accuracy: 1.0000\n",
      "Epoch 958/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1731 - binary_accuracy: 1.0000\n",
      "Epoch 959/1200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1730 - binary_accuracy: 1.0000\n",
      "Epoch 960/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1729 - binary_accuracy: 1.0000\n",
      "Epoch 961/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1728 - binary_accuracy: 1.0000\n",
      "Epoch 962/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1727 - binary_accuracy: 1.0000\n",
      "Epoch 963/1200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1726 - binary_accuracy: 1.0000\n",
      "Epoch 964/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1725 - binary_accuracy: 1.0000\n",
      "Epoch 965/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1724 - binary_accuracy: 1.0000\n",
      "Epoch 966/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1722 - binary_accuracy: 1.0000\n",
      "Epoch 967/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1721 - binary_accuracy: 1.0000\n",
      "Epoch 968/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1720 - binary_accuracy: 1.0000\n",
      "Epoch 969/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1719 - binary_accuracy: 1.0000\n",
      "Epoch 970/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1718 - binary_accuracy: 1.0000\n",
      "Epoch 971/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1717 - binary_accuracy: 1.0000\n",
      "Epoch 972/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1716 - binary_accuracy: 1.0000\n",
      "Epoch 973/1200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1715 - binary_accuracy: 1.0000\n",
      "Epoch 974/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1714 - binary_accuracy: 1.0000\n",
      "Epoch 975/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1713 - binary_accuracy: 1.0000\n",
      "Epoch 976/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1712 - binary_accuracy: 1.0000\n",
      "Epoch 977/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1711 - binary_accuracy: 1.0000\n",
      "Epoch 978/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1710 - binary_accuracy: 1.0000\n",
      "Epoch 979/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4125 - binary_accuracy: 1.000 - 0s 3ms/step - loss: 0.1709 - binary_accuracy: 1.0000\n",
      "Epoch 980/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1707 - binary_accuracy: 1.0000\n",
      "Epoch 981/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1706 - binary_accuracy: 1.0000\n",
      "Epoch 982/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1705 - binary_accuracy: 1.0000\n",
      "Epoch 983/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1704 - binary_accuracy: 1.0000\n",
      "Epoch 984/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1703 - binary_accuracy: 1.0000\n",
      "Epoch 985/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1702 - binary_accuracy: 1.0000\n",
      "Epoch 986/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1701 - binary_accuracy: 1.0000\n",
      "Epoch 987/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1700 - binary_accuracy: 1.0000\n",
      "Epoch 988/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1699 - binary_accuracy: 1.0000\n",
      "Epoch 989/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1698 - binary_accuracy: 1.0000\n",
      "Epoch 990/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1697 - binary_accuracy: 1.0000\n",
      "Epoch 991/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1696 - binary_accuracy: 1.0000\n",
      "Epoch 992/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1695 - binary_accuracy: 1.0000\n",
      "Epoch 993/1200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1694 - binary_accuracy: 1.0000\n",
      "Epoch 994/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1693 - binary_accuracy: 1.0000\n",
      "Epoch 995/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1692 - binary_accuracy: 1.0000\n",
      "Epoch 996/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1691 - binary_accuracy: 1.0000\n",
      "Epoch 997/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1690 - binary_accuracy: 1.0000\n",
      "Epoch 998/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1688 - binary_accuracy: 1.0000\n",
      "Epoch 999/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1687 - binary_accuracy: 1.0000\n",
      "Epoch 1000/1200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1686 - binary_accuracy: 1.0000\n",
      "Epoch 1001/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1685 - binary_accuracy: 1.0000\n",
      "Epoch 1002/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1684 - binary_accuracy: 1.0000\n",
      "Epoch 1003/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1683 - binary_accuracy: 1.0000\n",
      "Epoch 1004/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1682 - binary_accuracy: 1.0000\n",
      "Epoch 1005/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1681 - binary_accuracy: 1.0000\n",
      "Epoch 1006/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1680 - binary_accuracy: 1.0000\n",
      "Epoch 1007/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1679 - binary_accuracy: 1.0000\n",
      "Epoch 1008/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1678 - binary_accuracy: 1.0000\n",
      "Epoch 1009/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4041 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.1677 - binary_accuracy: 1.0000\n",
      "Epoch 1010/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1676 - binary_accuracy: 1.0000\n",
      "Epoch 1011/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1675 - binary_accuracy: 1.0000\n",
      "Epoch 1012/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1674 - binary_accuracy: 1.0000\n",
      "Epoch 1013/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4030 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.1673 - binary_accuracy: 1.0000\n",
      "Epoch 1014/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1672 - binary_accuracy: 1.0000\n",
      "Epoch 1015/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1671 - binary_accuracy: 1.0000\n",
      "Epoch 1016/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1670 - binary_accuracy: 1.0000\n",
      "Epoch 1017/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1669 - binary_accuracy: 1.0000\n",
      "Epoch 1018/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1668 - binary_accuracy: 1.0000\n",
      "Epoch 1019/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1667 - binary_accuracy: 1.0000\n",
      "Epoch 1020/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1666 - binary_accuracy: 1.0000\n",
      "Epoch 1021/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1665 - binary_accuracy: 1.0000\n",
      "Epoch 1022/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1664 - binary_accuracy: 1.0000\n",
      "Epoch 1023/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1663 - binary_accuracy: 1.0000\n",
      "Epoch 1024/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1662 - binary_accuracy: 1.0000\n",
      "Epoch 1025/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1661 - binary_accuracy: 1.0000\n",
      "Epoch 1026/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1660 - binary_accuracy: 1.0000\n",
      "Epoch 1027/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1659 - binary_accuracy: 1.0000\n",
      "Epoch 1028/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1658 - binary_accuracy: 1.0000\n",
      "Epoch 1029/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1657 - binary_accuracy: 1.0000\n",
      "Epoch 1030/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1656 - binary_accuracy: 1.0000\n",
      "Epoch 1031/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1655 - binary_accuracy: 1.0000\n",
      "Epoch 1032/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1654 - binary_accuracy: 1.0000\n",
      "Epoch 1033/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1653 - binary_accuracy: 1.0000\n",
      "Epoch 1034/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1652 - binary_accuracy: 1.0000\n",
      "Epoch 1035/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1651 - binary_accuracy: 1.0000\n",
      "Epoch 1036/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1650 - binary_accuracy: 1.0000\n",
      "Epoch 1037/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1649 - binary_accuracy: 1.0000\n",
      "Epoch 1038/1200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1648 - binary_accuracy: 1.0000\n",
      "Epoch 1039/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1647 - binary_accuracy: 1.0000\n",
      "Epoch 1040/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1646 - binary_accuracy: 1.0000\n",
      "Epoch 1041/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1645 - binary_accuracy: 1.0000\n",
      "Epoch 1042/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1644 - binary_accuracy: 1.0000\n",
      "Epoch 1043/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1643 - binary_accuracy: 1.0000\n",
      "Epoch 1044/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1642 - binary_accuracy: 1.0000\n",
      "Epoch 1045/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1641 - binary_accuracy: 1.0000\n",
      "Epoch 1046/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1640 - binary_accuracy: 1.0000\n",
      "Epoch 1047/1200\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3940 - binary_accuracy: 1.000 - 0s 2ms/step - loss: 0.1639 - binary_accuracy: 1.0000\n",
      "Epoch 1048/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1638 - binary_accuracy: 1.0000\n",
      "Epoch 1049/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1637 - binary_accuracy: 1.0000\n",
      "Epoch 1050/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1636 - binary_accuracy: 1.0000\n",
      "Epoch 1051/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1635 - binary_accuracy: 1.0000\n",
      "Epoch 1052/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1634 - binary_accuracy: 1.0000\n",
      "Epoch 1053/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1633 - binary_accuracy: 1.0000\n",
      "Epoch 1054/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1632 - binary_accuracy: 1.0000\n",
      "Epoch 1055/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1631 - binary_accuracy: 1.0000\n",
      "Epoch 1056/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1630 - binary_accuracy: 1.0000\n",
      "Epoch 1057/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1629 - binary_accuracy: 1.0000\n",
      "Epoch 1058/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1628 - binary_accuracy: 1.0000\n",
      "Epoch 1059/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1627 - binary_accuracy: 1.0000\n",
      "Epoch 1060/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1626 - binary_accuracy: 1.0000\n",
      "Epoch 1061/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1625 - binary_accuracy: 1.0000\n",
      "Epoch 1062/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1624 - binary_accuracy: 1.0000\n",
      "Epoch 1063/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1623 - binary_accuracy: 1.0000\n",
      "Epoch 1064/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1622 - binary_accuracy: 1.0000\n",
      "Epoch 1065/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1621 - binary_accuracy: 1.0000\n",
      "Epoch 1066/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1620 - binary_accuracy: 1.0000\n",
      "Epoch 1067/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1619 - binary_accuracy: 1.0000\n",
      "Epoch 1068/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1618 - binary_accuracy: 1.0000\n",
      "Epoch 1069/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1617 - binary_accuracy: 1.0000\n",
      "Epoch 1070/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1617 - binary_accuracy: 1.0000\n",
      "Epoch 1071/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1616 - binary_accuracy: 1.0000\n",
      "Epoch 1072/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1615 - binary_accuracy: 1.0000\n",
      "Epoch 1073/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1614 - binary_accuracy: 1.0000\n",
      "Epoch 1074/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1613 - binary_accuracy: 1.0000\n",
      "Epoch 1075/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1612 - binary_accuracy: 1.0000\n",
      "Epoch 1076/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1611 - binary_accuracy: 1.0000\n",
      "Epoch 1077/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1610 - binary_accuracy: 1.0000\n",
      "Epoch 1078/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1609 - binary_accuracy: 1.0000\n",
      "Epoch 1079/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1608 - binary_accuracy: 1.0000\n",
      "Epoch 1080/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1607 - binary_accuracy: 1.0000\n",
      "Epoch 1081/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1606 - binary_accuracy: 1.0000\n",
      "Epoch 1082/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1605 - binary_accuracy: 1.0000\n",
      "Epoch 1083/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1604 - binary_accuracy: 1.0000\n",
      "Epoch 1084/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1603 - binary_accuracy: 1.0000\n",
      "Epoch 1085/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1602 - binary_accuracy: 1.0000\n",
      "Epoch 1086/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1601 - binary_accuracy: 1.0000\n",
      "Epoch 1087/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1600 - binary_accuracy: 1.0000\n",
      "Epoch 1088/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1599 - binary_accuracy: 1.0000\n",
      "Epoch 1089/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1599 - binary_accuracy: 1.0000\n",
      "Epoch 1090/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1598 - binary_accuracy: 1.0000\n",
      "Epoch 1091/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1597 - binary_accuracy: 1.0000\n",
      "Epoch 1092/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1596 - binary_accuracy: 1.0000\n",
      "Epoch 1093/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1595 - binary_accuracy: 1.0000\n",
      "Epoch 1094/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1594 - binary_accuracy: 1.0000\n",
      "Epoch 1095/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1593 - binary_accuracy: 1.0000\n",
      "Epoch 1096/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1592 - binary_accuracy: 1.0000\n",
      "Epoch 1097/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1591 - binary_accuracy: 1.0000\n",
      "Epoch 1098/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1590 - binary_accuracy: 1.0000\n",
      "Epoch 1099/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1589 - binary_accuracy: 1.0000\n",
      "Epoch 1100/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1588 - binary_accuracy: 1.0000\n",
      "Epoch 1101/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1587 - binary_accuracy: 1.0000\n",
      "Epoch 1102/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1586 - binary_accuracy: 1.0000\n",
      "Epoch 1103/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1585 - binary_accuracy: 1.0000\n",
      "Epoch 1104/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1585 - binary_accuracy: 1.0000\n",
      "Epoch 1105/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1584 - binary_accuracy: 1.0000\n",
      "Epoch 1106/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1583 - binary_accuracy: 1.0000\n",
      "Epoch 1107/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1582 - binary_accuracy: 1.0000\n",
      "Epoch 1108/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1581 - binary_accuracy: 1.0000\n",
      "Epoch 1109/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1580 - binary_accuracy: 1.0000\n",
      "Epoch 1110/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1579 - binary_accuracy: 1.0000\n",
      "Epoch 1111/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1578 - binary_accuracy: 1.0000\n",
      "Epoch 1112/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1577 - binary_accuracy: 1.0000\n",
      "Epoch 1113/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1576 - binary_accuracy: 1.0000\n",
      "Epoch 1114/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1575 - binary_accuracy: 1.0000\n",
      "Epoch 1115/1200\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.1574 - binary_accuracy: 1.0000\n",
      "Epoch 1116/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1574 - binary_accuracy: 1.0000\n",
      "Epoch 1117/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1573 - binary_accuracy: 1.0000\n",
      "Epoch 1118/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1572 - binary_accuracy: 1.0000\n",
      "Epoch 1119/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1571 - binary_accuracy: 1.0000\n",
      "Epoch 1120/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1570 - binary_accuracy: 1.0000\n",
      "Epoch 1121/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1569 - binary_accuracy: 1.0000\n",
      "Epoch 1122/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1568 - binary_accuracy: 1.0000\n",
      "Epoch 1123/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1567 - binary_accuracy: 1.0000\n",
      "Epoch 1124/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1566 - binary_accuracy: 1.0000\n",
      "Epoch 1125/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1565 - binary_accuracy: 1.0000\n",
      "Epoch 1126/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1564 - binary_accuracy: 1.0000\n",
      "Epoch 1127/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1564 - binary_accuracy: 1.0000\n",
      "Epoch 1128/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1563 - binary_accuracy: 1.0000\n",
      "Epoch 1129/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1562 - binary_accuracy: 1.0000\n",
      "Epoch 1130/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1561 - binary_accuracy: 1.0000\n",
      "Epoch 1131/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1560 - binary_accuracy: 1.0000\n",
      "Epoch 1132/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1559 - binary_accuracy: 1.0000\n",
      "Epoch 1133/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1558 - binary_accuracy: 1.0000\n",
      "Epoch 1134/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1557 - binary_accuracy: 1.0000\n",
      "Epoch 1135/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1556 - binary_accuracy: 1.0000\n",
      "Epoch 1136/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1556 - binary_accuracy: 1.0000\n",
      "Epoch 1137/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1555 - binary_accuracy: 1.0000\n",
      "Epoch 1138/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1554 - binary_accuracy: 1.0000\n",
      "Epoch 1139/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1553 - binary_accuracy: 1.0000\n",
      "Epoch 1140/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1552 - binary_accuracy: 1.0000\n",
      "Epoch 1141/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1551 - binary_accuracy: 1.0000\n",
      "Epoch 1142/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1550 - binary_accuracy: 1.0000\n",
      "Epoch 1143/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1549 - binary_accuracy: 1.0000\n",
      "Epoch 1144/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1548 - binary_accuracy: 1.0000\n",
      "Epoch 1145/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1548 - binary_accuracy: 1.0000\n",
      "Epoch 1146/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1547 - binary_accuracy: 1.0000\n",
      "Epoch 1147/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1546 - binary_accuracy: 1.0000\n",
      "Epoch 1148/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1545 - binary_accuracy: 1.0000\n",
      "Epoch 1149/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1544 - binary_accuracy: 1.0000\n",
      "Epoch 1150/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1543 - binary_accuracy: 1.0000\n",
      "Epoch 1151/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1542 - binary_accuracy: 1.0000\n",
      "Epoch 1152/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1541 - binary_accuracy: 1.0000\n",
      "Epoch 1153/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1540 - binary_accuracy: 1.0000\n",
      "Epoch 1154/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1540 - binary_accuracy: 1.0000\n",
      "Epoch 1155/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1539 - binary_accuracy: 1.0000\n",
      "Epoch 1156/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1538 - binary_accuracy: 1.0000\n",
      "Epoch 1157/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1537 - binary_accuracy: 1.0000\n",
      "Epoch 1158/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1536 - binary_accuracy: 1.0000\n",
      "Epoch 1159/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1535 - binary_accuracy: 1.0000\n",
      "Epoch 1160/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1534 - binary_accuracy: 1.0000\n",
      "Epoch 1161/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1534 - binary_accuracy: 1.0000\n",
      "Epoch 1162/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1533 - binary_accuracy: 1.0000\n",
      "Epoch 1163/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1532 - binary_accuracy: 1.0000\n",
      "Epoch 1164/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1531 - binary_accuracy: 1.0000\n",
      "Epoch 1165/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1530 - binary_accuracy: 1.0000\n",
      "Epoch 1166/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1529 - binary_accuracy: 1.0000\n",
      "Epoch 1167/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1528 - binary_accuracy: 1.0000\n",
      "Epoch 1168/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1527 - binary_accuracy: 1.0000\n",
      "Epoch 1169/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1527 - binary_accuracy: 1.0000\n",
      "Epoch 1170/1200\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.1526 - binary_accuracy: 1.0000\n",
      "Epoch 1171/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1525 - binary_accuracy: 1.0000\n",
      "Epoch 1172/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1524 - binary_accuracy: 1.0000\n",
      "Epoch 1173/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1523 - binary_accuracy: 1.0000\n",
      "Epoch 1174/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1522 - binary_accuracy: 1.0000\n",
      "Epoch 1175/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1521 - binary_accuracy: 1.0000\n",
      "Epoch 1176/1200\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.1521 - binary_accuracy: 1.0000\n",
      "Epoch 1177/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1520 - binary_accuracy: 1.0000\n",
      "Epoch 1178/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1519 - binary_accuracy: 1.0000\n",
      "Epoch 1179/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1518 - binary_accuracy: 1.0000\n",
      "Epoch 1180/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1517 - binary_accuracy: 1.0000\n",
      "Epoch 1181/1200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1516 - binary_accuracy: 1.0000\n",
      "Epoch 1182/1200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1515 - binary_accuracy: 1.0000\n",
      "Epoch 1183/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1515 - binary_accuracy: 1.0000\n",
      "Epoch 1184/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1514 - binary_accuracy: 1.0000\n",
      "Epoch 1185/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1513 - binary_accuracy: 1.0000\n",
      "Epoch 1186/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1512 - binary_accuracy: 1.0000\n",
      "Epoch 1187/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1511 - binary_accuracy: 1.0000\n",
      "Epoch 1188/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1510 - binary_accuracy: 1.0000\n",
      "Epoch 1189/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1510 - binary_accuracy: 1.0000\n",
      "Epoch 1190/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1509 - binary_accuracy: 1.0000\n",
      "Epoch 1191/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1508 - binary_accuracy: 1.0000\n",
      "Epoch 1192/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1507 - binary_accuracy: 1.0000\n",
      "Epoch 1193/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1506 - binary_accuracy: 1.0000\n",
      "Epoch 1194/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1505 - binary_accuracy: 1.0000\n",
      "Epoch 1195/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1505 - binary_accuracy: 1.0000\n",
      "Epoch 1196/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1504 - binary_accuracy: 1.0000\n",
      "Epoch 1197/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1503 - binary_accuracy: 1.0000\n",
      "Epoch 1198/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1502 - binary_accuracy: 1.0000\n",
      "Epoch 1199/1200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1501 - binary_accuracy: 1.0000\n",
      "Epoch 1200/1200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1500 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 1])\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=1, input_shape=(2,), activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n",
    "\n",
    "hist = model.fit(x, y, batch_size=1, epochs=1200, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewfoQrKdCIQa"
   },
   "source": [
    "## 3-5. Softmax Regression 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "CqyGHAE3Cd2G",
    "outputId": "034af493-100a-4ed8-87df-0d96975352c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2993 - sparse_categorical_accuracy: 0.9124\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9573\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1079 - sparse_categorical_accuracy: 0.9671\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0880 - sparse_categorical_accuracy: 0.9730\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9765\n",
      "313/313 - 0s - loss: 0.0701 - sparse_categorical_accuracy: 0.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07009219378232956, 0.9776999950408936]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SbQah4u_bKx"
   },
   "source": [
    "# 4. NLP using Tensorflow\n",
    "\n",
    "## 4-1. 다층 퍼셉트론으로 20개의 뉴스 분류하기\n",
    "- 사이킷런에서는 20개의 다른 주제를 가진 18,846개의 뉴스 그룹 이메일 데이터를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lP9xAhZP_iAV",
    "outputId": "e6f219f9-7970-48da-d4e5-894765870320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 385 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "news = fetch_20newsgroups(subset=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sju7AlXU_j_x"
   },
   "source": [
    "- `subset=\"all\"`을 통해 전체 데이터인 18,846개의 샘플을 다운로드할 수 있으며, `subset=\"train\"`을 통해 훈련 데이터를, `subset=\"test\"`를 통해 테스트 데이터를 다운로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ysyh4pCg_k48",
    "outputId": "d6f90984-9696-4a63-db3b-deacc2a6fb30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "#해당 데이터의 속성을 확인할 수 있습니다.\n",
    "print(news.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8Mr61SS_r4h"
   },
   "source": [
    "- 해당 데이터는 `data`, `filenames`, `target_names`, `target`, `DESCR`, `description`이라는 6개 속성을 갖고 있습니다. 이 중 실제로 훈련에 사용할 속성은 이메일 본문인 `data`와 메일이 어떤 주제인지 기재된 숫자 레이블인 `target`입니다. 우선 훈련용 샘플의 개수를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "svpaeHsT_sTl",
    "outputId": "97872e71-9f61-4400-8d97-776a25930dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 샘플의 개수 : 11314\n"
     ]
    }
   ],
   "source": [
    "print(f\"훈련용 샘플의 개수 : {len(news['data'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j2WB8hrG_u6s"
   },
   "source": [
    "- `target_names`에는 20개의 주제의 이름을 담고있습니다. 어떤 주제가 있는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "odY-n84K_tBd",
    "outputId": "cdb906bf-6d6d-4b00-99da-c297af92b239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(news[\"target_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hs4dWwb__w1j"
   },
   "source": [
    "- 이번 챕터 실습의 목적은 테스트 데이터에서 이메일 본문을 보고 20개의 주제 중 어떤 주제인지를 맞추는 것입니다. 레이블인 target에는 총 0부터 19까지의 숫자가 들어가있는데 첫번째 샘플의 경우에는 몇 번 주제인지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VnxPyBY5_wat",
    "outputId": "b3bff38b-3b15-48fc-acc2-e13b6641591d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 샘플의 레이블 : 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫번째 샘플의 레이블 : {news['target'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "br6HhWT5_yQl",
    "outputId": "ada9a5f4-9480-470d-f00f-f5e51d135973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 레이블이 의미하는 주제 : rec.autos\n"
     ]
    }
   ],
   "source": [
    "print(f\"7번 레이블이 의미하는 주제 : {news['target_names'][7]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news[\"data\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "orMWgpuM_2M1",
    "outputId": "98ae9a2a-4366-40a8-a23c-3597511857b6"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(news[\"data\"], columns=[\"content\"])\n",
    "data[\"label\"] = news[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...      7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...      4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...      4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...      1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...     14"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "FWIB0kuE_3IN",
    "outputId": "a3b787ba-e89a-48a8-8983-6a1b855646df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11314 entries, 0 to 11313\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   11314 non-null  object\n",
      " 1   target  11314 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 176.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "0WTpdu7e_5ec",
    "outputId": "22fd5213-9ded-4381-c31f-f3ba17fdb63b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"label\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JvNMFSTw_7I0"
   },
   "outputs": [],
   "source": [
    "news_train = fetch_20newsgroups(subset=\"train\", shuffle=True)\n",
    "news_test = fetch_20newsgroups(subset=\"test\", shuffle=True)\n",
    "\n",
    "train_content = news_train[\"data\"]\n",
    "train_label = news_train[\"target\"]\n",
    "test_content = news_train[\"data\"]\n",
    "test_label = news_train[\"target\"]\n",
    "\n",
    "vocab_size = 10000\n",
    "n_clss = 20\n",
    "\n",
    "def prepare_data(ratings_train, ratings_test, mode):\n",
    "    tkn = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size+1)\n",
    "    tkn.fit_on_texts(ratings_train)\n",
    "    x_train = tkn.texts_to_matrix(ratings_train, mode=mode)\n",
    "    x_test = tkn.texts_to_matrix(ratings_test, mode=mode)\n",
    "    return x_train, x_test, tkn.index_word\n",
    "\n",
    "x_train, x_test, idx2word = prepare_data(train_content, test_content, \"binary\")\n",
    "y_train = tf.keras.utils.to_categorical(train_label, n_clss)\n",
    "y_test = tf.keras.utils.to_categorical(test_label, n_clss)\n",
    "\n",
    "def fit_and_evaluate(x_train, y_train, x_test, y_test):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units=256, input_shape=(vocab_size+1,), activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(n_clss, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\"])\n",
    "    \n",
    "    hist = model.fit(x=x_train, y=y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.1)\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JvNMFSTw_7I0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 2.3123 - categorical_accuracy: 0.3311 - val_loss: 1.0163 - val_categorical_accuracy: 0.8260\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 3s 34ms/step - loss: 0.8940 - categorical_accuracy: 0.7568 - val_loss: 0.4652 - val_categorical_accuracy: 0.8860\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.4382 - categorical_accuracy: 0.8824 - val_loss: 0.3433 - val_categorical_accuracy: 0.9099\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.2647 - categorical_accuracy: 0.9311 - val_loss: 0.3137 - val_categorical_accuracy: 0.9099\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.1654 - categorical_accuracy: 0.9607 - val_loss: 0.3006 - val_categorical_accuracy: 0.9134\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.0560 - categorical_accuracy: 0.9882\n",
      "binary 모드의 테스트 정확도 : 98.8%\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 2.8333 - categorical_accuracy: 0.2379 - val_loss: 1.7273 - val_categorical_accuracy: 0.7094\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 1.4825 - categorical_accuracy: 0.6143 - val_loss: 0.7371 - val_categorical_accuracy: 0.8445\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.8309 - categorical_accuracy: 0.7928 - val_loss: 0.5122 - val_categorical_accuracy: 0.8869\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.5455 - categorical_accuracy: 0.8671 - val_loss: 0.4016 - val_categorical_accuracy: 0.8975\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.3911 - categorical_accuracy: 0.9071 - val_loss: 0.4189 - val_categorical_accuracy: 0.8949\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1380 - categorical_accuracy: 0.9779\n",
      "count 모드의 테스트 정확도 : 97.8%\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 2.2331 - categorical_accuracy: 0.3592 - val_loss: 0.7859 - val_categorical_accuracy: 0.8445\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 0.8658 - categorical_accuracy: 0.7652 - val_loss: 0.4108 - val_categorical_accuracy: 0.8913\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.4448 - categorical_accuracy: 0.8828 - val_loss: 0.3482 - val_categorical_accuracy: 0.9081\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.2742 - categorical_accuracy: 0.9301 - val_loss: 0.5323 - val_categorical_accuracy: 0.9170\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 0.2902 - categorical_accuracy: 0.9468 - val_loss: 0.3020 - val_categorical_accuracy: 0.9161\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.0651 - categorical_accuracy: 0.9887\n",
      "tfidf 모드의 테스트 정확도 : 98.9%\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 2.9765 - categorical_accuracy: 0.0917 - val_loss: 2.9171 - val_categorical_accuracy: 0.2800\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 2.6972 - categorical_accuracy: 0.2176 - val_loss: 2.3612 - val_categorical_accuracy: 0.4161\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 3s 36ms/step - loss: 2.1461 - categorical_accuracy: 0.3501 - val_loss: 1.8306 - val_categorical_accuracy: 0.5618\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 1.7041 - categorical_accuracy: 0.4816 - val_loss: 1.4316 - val_categorical_accuracy: 0.6599\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 1.3633 - categorical_accuracy: 0.5871 - val_loss: 1.1483 - val_categorical_accuracy: 0.7323\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 1.0170 - categorical_accuracy: 0.8057\n",
      "freq 모드의 테스트 정확도 : 80.6%\n"
     ]
    }
   ],
   "source": [
    "modes = [\"binary\", \"count\", \"tfidf\", \"freq\"]\n",
    "\n",
    "for mode in modes:\n",
    "    x_train, x_test, _ = prepare_data(train_content, test_content, mode)\n",
    "    score = fit_and_evaluate(x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    print(f\"{mode} 모드의 테스트 정확도 : {score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Lz4ZCD_EdwH"
   },
   "source": [
    "## 4-2. MLP로 네이버 영화 리뷰 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vs2toG0zEfLK",
    "outputId": "1d13584f-4571-4e40-d539-bf262aad64d7"
   },
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "ratings_train = pd.read_table(\"ratings_train.txt\", usecols=[\"document\", \"label\"]).dropna()\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
    "ratings_test = pd.read_table(\"ratings_test.txt\", usecols=[\"document\", \"label\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "p4jbvYoeIFhh",
    "outputId": "d3bdecf0-2c8d-4d09-f746-f432df27db08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  label\n",
       "0                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-SUi72snITHM",
    "outputId": "fdccbe97-ead7-4d76-87f1-a4ad30047142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['아/Exclamation',\n",
      "  '더빙/Noun',\n",
      "  '../Punctuation',\n",
      "  '진짜/Noun',\n",
      "  '짜증나다/Adjective',\n",
      "  '목소리/Noun'],\n",
      " 0)\n",
      "Wall time: 18min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def okt_pos(doc):\n",
    "    return [\"/\".join(t) for t in okt.pos(doc, stem=True, norm=True)]\n",
    "\n",
    "if os.path.exists(\"train_docs.json\"):\n",
    "    with open(\"train_docs.json\") as f:\n",
    "        train_docs = json.load(f)\n",
    "    with open(\"test_docs.json\") as f:\n",
    "        test_docs = json.load(f)\n",
    "else:\n",
    "    train_docs = [(okt_pos(row[\"document\"]), row[\"label\"]) for _, row in ratings_train.iterrows()]\n",
    "    test_docs = [(okt_pos(row[\"document\"]), row[\"label\"]) for _, row in ratings_test.iterrows()]\n",
    "    with open(\"train_docs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(train_docs, f, ensure_ascii=False, indent=\"\\t\")\n",
    "    with open(\"test_docs.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(test_docs, f, ensure_ascii=False, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def okt_pos(doc):\n",
    "    return [\"/\".join(t) for t in okt.pos(doc, stem=True, norm=True)]\n",
    "\n",
    "if os.path.exists(\"train_data.json\"):\n",
    "    with open(\"train_data.json\") as f:\n",
    "        train_data = json.load(f)\n",
    "    with open(\"test_data.json\") as f:\n",
    "        test_data = json.load(f)\n",
    "else:\n",
    "    train_data = [(okt_pos(row[\"document\"]), row[\"label\"]) for _, row in ratings_train.iterrows()]\n",
    "    test_data = [(okt_pos(row[\"document\"]), row[\"label\"]) for _, row in ratings_test.iterrows()]\n",
    "    with open(\"train_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(train_data, f, ensure_ascii=False, indent=\"\\t\")\n",
    "    with open(\"test_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(test_data, f, ensure_ascii=False, indent=\"\\t\")\n",
    "\n",
    "pprint(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TLym1RsCIV68",
    "outputId": "fe887ed0-902c-40f0-8893-640ba26211a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2159921\n",
      "49894\n",
      "[('./Punctuation', 67778),\n",
      " ('영화/Noun', 50818),\n",
      " ('하다/Verb', 41209),\n",
      " ('이/Josa', 38540),\n",
      " ('보다/Verb', 38538),\n",
      " ('의/Josa', 30188),\n",
      " ('../Punctuation', 29055),\n",
      " ('가/Josa', 26627),\n",
      " ('에/Josa', 26468),\n",
      " ('을/Josa', 23118)]\n"
     ]
    }
   ],
   "source": [
    "tokens = [doc for sample in train_data for doc in sample[0]]\n",
    "text = nltk.Text(tokens, name=\"NMSC\")\n",
    "\n",
    "# 전체 토큰의 개수\n",
    "print(len(text.tokens))\n",
    "# 중복을 제외한 토큰의 개수\n",
    "print(len(set(text.tokens)))            \n",
    "# 출현 빈도가 높은 상위 토큰 10개\n",
    "pprint(text.vocab().most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Cwmeu2FMIasz",
    "outputId": "85e7d664-37f3-4871-a75e-60ab05253763"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "text.plot(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "sznQMdKEIepG",
    "outputId": "54728373-f4c4-4a43-d647-72805a42500d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 시간이 꽤 걸립니다! 시간을 절약하고 싶으면 most_common의 매개변수를 줄여보세요.\\nselected_words = [f[0] for f in text.vocab().most_common(10000)]\\n\\ndef term_frequency(doc):\\n    return [doc.count(word) for word in selected_words]\\n\\ntrain_x = [term_frequency(d) for d, _ in train_docs]\\ntest_x = [term_frequency(d) for d, _ in test_docs]\\ntrain_y = [c for _, c in train_docs]\\ntest_y = [c for _, c in test_docs]\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 시간이 꽤 걸립니다! 시간을 절약하고 싶으면 most_common의 매개변수를 줄여보세요.\n",
    "selected_words = [f[0] for f in text.vocab().most_common(10000)]\n",
    "\n",
    "def term_frequency(doc):\n",
    "    return [doc.count(word) for word in selected_words]\n",
    "\n",
    "train_x = [term_frequency(d) for d, _ in train_docs]\n",
    "test_x = [term_frequency(d) for d, _ in test_docs]\n",
    "train_y = [c for _, c in train_docs]\n",
    "test_y = [c for _, c in test_docs]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "b9S4O-gsIf2E",
    "outputId": "8221db11-0af5-40d7-c686-f23693d2aff2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport numpy as np\\n\\nx_train = np.asarray(train_x).astype('float32')\\nx_test = np.asarray(test_x).astype('float32')\\n\\ny_train = np.asarray(train_y).astype('float32')\\ny_test = np.asarray(test_y).astype('float32')\\n\""
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.asarray(train_x).astype(\"float32\")\n",
    "x_test = np.asarray(test_x).astype(\"float32\")\n",
    "\n",
    "y_train = np.asarray(train_y).astype(\"float32\")\n",
    "y_test = np.asarray(test_y).astype(\"float32\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "p2J3LVROIiu6",
    "outputId": "34089f33-84c6-49fd-b8b0-efae5072eb7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras import optimizers\\nfrom tensorflow.keras import losses\\nfrom tensorflow.keras import metrics\\n\\nmodel = models.Sequential()\\nmodel.add(Dense(64, activation='relu', input_shape=(10000,)))\\nmodel.add(Dense(64, activation='relu'))\\nmodel.add(Dense(1, activation='sigmoid'))\\n\\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\\n             loss=losses.binary_crossentropy,\\n             metrics=[metrics.binary_accuracy])\\n\\nmodel.fit(x_train, y_train, epochs=10, batch_size=512)\\nresults = model.evaluate(x_test, y_test)\\n\""
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=64, input_shape=(10000,), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=512)\n",
    "\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsHM192jK1vU"
   },
   "source": [
    "## 4-3. tf.keras.Sequential API vs. Functional API\n",
    "\n",
    "### (1) tf.keras.Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmPQHJ3XK5kZ"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=3, input_shape=(4,), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞에서 Keras를 사용하여 모델을 설계하는 방식을 tf.keras.Sequential API를 사용하였다고 합니다. 그런데 tf.keras.Sequential API는 여러층을 공유하거나 다양한 종류의 입력과 출력을 사용하는 등의 복잡한 모델을 만드는 일을 하기에는 한계가 있습니다. 이번에는 복잡한 모델을 생성할 수 있는 방식인 Functional API에 대해서 알아봅니다.\n",
    "- Functional API는 각 층을 일종의 함수(function)로서 정의합니다. 그리고 각 함수를 조합하기 위한 연산자들을 제공하는데, 이를 이용하여 신경망을 설계합니다. Functional API로 FFNN, RNN 등 다양한 모델을 만들면서 기존의 tf.keras.Sequential API와의 차이를 이해해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkTnwPehK93s"
   },
   "source": [
    "### (2) Functional API로 만든 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFTLoLMTLCeH"
   },
   "source": [
    "### 피드 포워드 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIeK_HXwK_jA"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(10,))\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "hidden2 = tf.keras.layers.Dense(64, activation=\"relu\")(hidden1)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(hidden2)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5S6Q1aZmLfL3"
   },
   "source": [
    "### 다중 입력을 받는 모델(tf.keras.Model that accepts multiple inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CurzrkxLLhqD"
   },
   "outputs": [],
   "source": [
    "# 두 개의 입력층을 정의\n",
    "inputA = tf.keras.Input(shape=(64,))\n",
    "inputB = tf.keras.Input(shape=(128,))\n",
    "\n",
    "# 첫번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\")(inputA)\n",
    "x = tf.keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "x = tf.keras.Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# 두번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
    "y = tf.keras.layers.Dense(64, activation=\"relu\")(inputB)\n",
    "y = tf.keras.layers.Dense(32, activation=\"relu\")(y)\n",
    "y = tf.keras.layers.Dense(8, activation=\"relu\")(y)\n",
    "y = tf.keras.Model(inputs=inputB, outputs=y)\n",
    "\n",
    "# 두개의 인공 신경망의 출력을 연결(concatenate)\n",
    "result = tf.concat([x.output, y.output])\n",
    "\n",
    "# 연결된 값을 입력으로 받는 밀집층을 추가(tf.keras.layers.Dense layer)\n",
    "z = tf.keras.layers.Dense(2, activation=\"relu\")(result)\n",
    "# 선형 회귀를 위해 activation=linear를 설정\n",
    "z = tf.keras.layers.Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "# 결과적으로 이 모델은 두 개의 입력층으로부터 분기되어 진행된 후 마지막에는 하나의 출력을 예측하는 모델이 됨.\n",
    "model = tf.keras.Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYZPxP-TFqLq"
   },
   "source": [
    "# 5. soynlp\n",
    "\n",
    "## 5-1. OOV 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_C6VPJUrFTAW",
    "outputId": "18f54ba9-80b2-4f9a-807b-879e79986752"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'okt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f22dea16c49e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mokt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"에이비식스 이대휘 1월 최애돌 기부 요정\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'okt' is not defined"
     ]
    }
   ],
   "source": [
    "print(okt.morphs(\"에이비식스 이대휘 1월 최애돌 기부 요정\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFzimbZBFwgo"
   },
   "source": [
    "- 에이비식스는 아이돌의 이름이고, 이대휘는 에이비식스의 멤버이며, 최애돌은 최고로 애정하는 아이돌이라는 뜻이지만 위의 형태소 분석 결과에서는 전부 분리된 결과를 보여줍니다.\n",
    "- 그렇다면 텍스트 데이터에서 특정 문자 시퀀스가 함께 자주 등장하는 빈도가 높고, 앞 뒤로 조사 또는 완전히 다른 단어가 등장하는 것을 고려해서 해당 문자 시퀀스를 형태소라고 판단하는 형태소 분석기라면 어떨까요?\n",
    "- 예를 들어 에이비식스라는 문자열이 자주 연결되어 등장한다면 형태소라고 판단하고, 또한 에이비식스라는 단어 앞, 뒤에 \"최고\", \"가수\", \"실력\"과 같은 독립된 다른 단어들이 계속해서 등장한다면 에이비식스를 형태소로 파악하는 식이지요. 그리고 이런 아이디어를 가진 형태소 분석기가 soynlp입니다.\n",
    "- soynlp는 품사 태깅, 형태소 분석 등을 지원하는 한국어 형태소 분석기입니다. 비지도 학습으로 형태소 분석을 한다는 특징을 갖고 있으며, 데이터에 자주 등장하는 단어들을 형태소로 분석합니다. soynlp 형태소 분석기는 내부적으로 단어 점수 표로 동작합니다. 이 점수는 응집 확률(cohesion probability)과 브랜칭 엔트로피(branching entropy)를 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PR5hjIsmF1-o",
    "outputId": "b2e731d2-7233-4071-bfc2-33bd2784ce87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2016-10-20.txt', <http.client.HTTPMessage at 0x131981bfd08>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVULVPMdF6eE"
   },
   "source": [
    "다운로드 한 말뭉치를 문서 단위로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "f0835RTkF45f",
    "outputId": "d4f363b2-2890-4e0c-d170-589e96a30ce8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30091"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp import DoublespaceLineCorpus\n",
    "\n",
    "# 말뭉치에 대해서 다수의 문서로 분리\n",
    "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\")\n",
    "\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibxbjyLlF-2k"
   },
   "source": [
    "총 3만 91개의 문서가 존재합니다. 공백이 아닌 문서에 한해 상위 3개의 문서만 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "-H52M98_F9JP",
    "outputId": "ce1e9b1a-886a-4609-b8dd-57d9a0fad3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19  1990  52 1 22\n",
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다 독자제공 영상 캡처 연합뉴스  서울 연합뉴스 김은경 기자 사제 총기로 경찰을 살해한 범인 성모 46 씨는 주도면밀했다  경찰에 따르면 성씨는 19일 오후 강북경찰서 인근 부동산 업소 밖에서 부동산업자 이모 67 씨가 나오기를 기다렸다 이씨와는 평소에도 말다툼을 자주 한 것으로 알려졌다  이씨가 나와 걷기 시작하자 성씨는 따라가면서 미리 준비해온 사제 총기를 이씨에게 발사했다 총알이 빗나가면서 이씨는 도망갔다 그 빗나간 총알은 지나가던 행인 71 씨의 배를 스쳤다  성씨는 강북서 인근 치킨집까지 이씨 뒤를 쫓으며 실랑이하다 쓰러뜨린 후 총기와 함께 가져온 망치로 이씨 머리를 때렸다  이 과정에서 오후 6시 20분께 강북구 번동 길 위에서 사람들이 싸우고 있다 총소리가 났다 는 등의 신고가 여러건 들어왔다  5분 후에 성씨의 전자발찌가 훼손됐다는 신고가 보호관찰소 시스템을 통해 들어왔다 성범죄자로 전자발찌를 차고 있던 성씨는 부엌칼로 직접 자신의 발찌를 끊었다  용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기  신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다  김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시 33분께 풀숲에 숨은 성씨가 허공에 난사한 10여발의 총알 중 일부를 왼쪽 어깨 뒷부분에 맞고 쓰러졌다  김 경위는 구급차가 도착했을 때 이미 의식이 없었고 심폐소생술을 하며 병원으로 옮겨졌으나 총알이 폐를 훼손해 오후 7시 40분께 사망했다  김 경위는 외근용 조끼를 입고 있었으나 총알을 막기에는 역부족이었다  머리에 부상을 입은 이씨도 함께 병원으로 이송됐으나 생명에는 지장이 없는 것으로 알려졌다  성씨는 오패산 터널 밑쪽 숲에서 오후 6시 45분께 잡혔다  총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다  총 때문에 쫓던 경관들과 민간인들이 몸을 숨겼는데 인근 신발가게 직원 이모씨가 다가가 성씨를 덮쳤고 이어 현장에 있던 다른 상인들과 경찰이 가세해 체포했다  성씨는 경찰에 붙잡힌 직후 나 자살하려고 한 거다 맞아 죽어도 괜찮다 고 말한 것으로 전해졌다  성씨 자신도 경찰이 발사한 공포탄 1발 실탄 3발 중 실탄 1발을 배에 맞았으나 방탄조끼를 입은 상태여서 부상하지는 않았다  경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다  일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다\n",
      "테헤란 연합뉴스 강훈상 특파원 이용 승객수 기준 세계 최대 공항인 아랍에미리트 두바이국제공항은 19일 현지시간 이 공항을 이륙하는 모든 항공기의 탑승객은 삼성전자의 갤럭시노트7을 휴대하면 안 된다고 밝혔다  두바이국제공항은 여러 항공 관련 기구의 권고에 따라 안전성에 우려가 있는 스마트폰 갤럭시노트7을 휴대하고 비행기를 타면 안 된다 며 탑승 전 검색 중 발견되면 압수할 계획 이라고 발표했다  공항 측은 갤럭시노트7의 배터리가 폭발 우려가 제기된 만큼 이 제품을 갖고 공항 안으로 들어오지 말라고 이용객에 당부했다  이런 조치는 두바이국제공항 뿐 아니라 신공항인 두바이월드센터에도 적용된다  배터리 폭발문제로 회수된 갤럭시노트7 연합뉴스자료사진\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for document in corpus:\n",
    "  if len(document) > 0:\n",
    "    print(document)\n",
    "    i = i+1\n",
    "  if i == 3:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmviMaUAGEH3"
   },
   "source": [
    "soynlp는 비지도학습 형태소 분석기이므로 기존의 형태소 분석기와는 달리 학습 과정을 거쳐야 합니다. 이는 전체 코퍼스로부터 응집 확률과 브랜칭 엔트로피 단어 점수표를 만드는 과정이지요. WordExtractor.extract()를 통해서 전체 코퍼스에 대해 단어 점수표를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "H9wDUf8RGEsu",
    "outputId": "ef4de1b5-cd76-4f7b-8659-dbed9f0cbfd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 5.186 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(corpus)\n",
    "word_score_table = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4tAK15-GJiN"
   },
   "source": [
    "## soynlp의 응집 확률(cohesion probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgV9OQplGMMV"
   },
   "source": [
    "응집 확률은 내부 문자열(substring)이 얼마나 응집하여 자주 등장하는지를 판단하는 척도입니다. 응집 확률은 문자열을 문자 단위로 분리하여 내부 문자열을 만드는 과정에서 왼쪽부터 순서대로 문자를 추가하면서 각 문자열이 주어졌을 때 그 다음 문자가 나올 확률을 계산하여 누적곱을 한 값입니다. 이 값이 높을수록 전체 코퍼스에서 이 문자열 시퀀스는 하나의 단어로 등장할 가능성이 높습니다. 수식은 아래와 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "Jx_dW5mRGNMD",
    "outputId": "02b84240-f4b6-45c1-e72f-f7fd623e3920"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR8AAABLCAYAAABJP4MYAAAACXBIWXMAAA7DAAAOwwHHb6hkAAANjUlEQVR42u1dLZuyXBDmX5xINBKJRCKRSCQS+QlEIpFoNBqJRKLRSCQS7z1fKCoouK4iO/d1eb377rPKkRnu+TgzcwwQCATCB2DQLSAQCEQ+BAKByIdAIBCIfAgEApEPgUAgEPkQCAQiHwKBQCDyIRAIRD4EAuEb0aIucuRlQ+RDIBDehKZEnsbwLQPetibyIRAI70SNrUfkQyAQiHwIBAKRD5EPgUAg8iEQCOvBEXudcLb8GOn+SORDIBDWAyKff4S2TOGFO9R0K1YTGu1CD2nZEvkQluxJb+GbPrZHuhWrkyvzvlKuRD7/w+VBYjP4xDzr9H92PpgVY44DZBjGS15EPoR7zIMysWF4W7ycetoGVR4i2jd0mz8cfomdKSsu8b4AjMt+l+E3uWgin7VTT5XANmyk1YtVr8yRZhE8bv38HWWRPh9+5XANC8k78j/HPdI05Ncz+PWIfAjDWoLcNcCiPS58k+MOoevA3vgIoxBxGsHdBJjPITycI/JZjIdbRAyGk+Ew1YDsQziWBdsLEKYpIttBVs2TPZEPYVS5mLCGVwpVJhskeQbHMBHKkOlZEiHyWRSqlHu5BoLdlDCYk1WcIE0sGZLX3FDNKyok8iE88HoMN7/J9bRNg3oXwmAxCuGl11sePjHExVyXnchnkTJ38on5va6K+SgsFUKuA5JM2gP2eY584FUcWyIfwmMraEkrOEwMZWxoi6c8JIOF2NcNt4cNDkWBYuxV1b2kJpHP4rzdXQDD2Nx4u8POT4FIEE4lfoykMUqzAPmkuI3IhzDqUvP43xjL43AL6RgwZRZa5AoMsHCHXTxRaYl8lhxrcw+GG5aoeLzzdchga++3LWOYlg03mFCEKuf9qISzG6ZPDxwj8lkl9wiLxhVwTJFaoaAmYr0zUmUOmO0iiPaTq5/lbpdWQOZG/Of967fyCc+wD3aBqMHhnuzCC5+JfFbJPTEYJwUvJzr4jzjmjiwAjIplsw+RzwpRJSLksl5e20P4FgVQ+T7jNwkZIh/CE3ZP5nO+we0m/HHYbU+v+SHyIbwg5NcJR+/edmuFzHFgm9e9OiZs/nvnzmvDrt7DNvz3ISjnvCwDJLbQ5YbDgjtfiHzWF3PJfI8RF1OYCofM65FJjPuOeq2VWr0sfg3q6lomZCnFL7fCiXwIsyA6nIXSOdlEh1sWGD5HPnFJ93uxvo9OOv/lGFQin7+KXsoUflLM6hIWVcPhh8dWqGTz1BL7ZZPPMzJ4Nw751KK8X5kU7MJw1sweWTi68KTz68mnyuDYpvrifzHG4Q1oywS2naKarfU81vaZKlf/DGViH84khjeQT5W5cJyNCgf7eSWhJ2wDPy1u6ouel8Gbw5vkTR7g3KFh/P4Zutar+Tfko7454r8in3qHwDTA/D8aB9pWSGxrZqVv//nn6zM+NVmuIwcPk0t83uX5HPV1rnXikMlCxa7V4yUyWCP5QLdOTH2mjjmchTsAf0Y+yR+Tj8kZ/S9uar31BpsxZ7CXam2IPhEu6Ps+h/zeRD6yd0gkqW+Kj3prrl8lg3WSj9hCj9nE4sGTXB/JlMhnIVBdwb8Om0qx4/SJOpvbB3kp5FOllnpPMXb97n69SAZrJB95PW7Ywv1jw/bN5NMedkgCB24QIw092EGC4ni27oddgsANEMUhXMdHWtS3D4GbyAa0MI4ROCY2fnYZwx/38hpBJIZZuYh2x9PnV1mgrp1G8OwNNkzcxBr7yIZ5c1PvrKfeIzrloDLstzHCKEHkmTDd6HIMJPeq/IHKYJF/8F0HzPSQVQfsIh9+GPHvtIGfVbeKoGtt3p7r64rL5ijcW8hnvO5EdWEbsBM9AnREBqcVFBlCz1M65bpIimaB5FOjyEJ4Xog45nrMn4NXLVMlkpMJ8u0M0XKLTY3x5JYBV2/XdgpiyLvMiUHMBO4nA7nChKy/rdd9cYtbuuYU2ztGz6Lpa5z6j+QYyI1sdlS9STGKizzK+cFQNQzd/09Zz/H00Jyu1+pivL7myCTdtddQIeXKU7U6j2XYnFQa/RW8ES+jQsI+YL2fsXbvIJ+u8PFqyl6rdcAMeh7yoAyUnOUsals/yIKk2Oe96xvykcP6BZmqGig53N14oS7IOq4pYfUTIfjnyacbx9BfdI2qKHFoOpK4riNRYxnOyqu/eF/ZOiXXBHYa+dD0HnJLFcd124Qe9yqaVluSvDgpmRD46VqT1tM9NH0rcBsaqhqZqwfwkKvtXt0vY/WyoKqWYki4+nr3XB85liDlnt2017Zqv5d8ylj+PbM9BEGgXj7/OcqwLesLz3FQBuimMhp68qL2aL0AaTfOYcowe2EAmXn+jKkOpfDQhdf+kHzEbiNTenZaJvfcgxTnZVbIudd8bwkNf4/JjdxgqZaW12Ov+ivJR1ntMUXsitiumVwRwka7ywM5nwvy0URj8JAr6R4wdTyrfI+wHg47KTnb+GcluyKfaevpHpr+dxogH+nJDH9vRTSsJ3T9mWzo7/W/vbsKb6Hk0+V7ptQeDctAT+gbCSGmD7Nv0TRDJH5AHuQDfVDi2OAUSchlz5LH5KMN4XBOpkGZp8gi8f38B+0oY+s8yysm8rl+2LuH8xH5dDfmnrI3OJY75CKHYyqi6iKm6eTTree35NPVz/SUX4cSbHBXi8jn9j3THoJBGcg80NV2/MjDdiYfLrPIhGFGcljWcRfAtS2Y18P0u/eOkMtpTRPI56yL9d3NiAvy4XoUid1bqUcitPTh2Gy8Qn3d5NOFRO5lrUjLQy8xQlOz++YiI9iFOV0Y9Yh8uof5OgHZ4CBiOyGgvvXQ+ZmOYIbCrvvrmUY+KjwYsK5dIrf3tyo0ZHLbU1Y2X5gy1Vl+t8Xhv4RdXb7HSjGpbGdIBh353FywxfHYjJCPCJdKFOWRq+4WvpPx+22NdHq/lnxul3nEeZlX5CO+Q1mgFLOR+b9twpyHZWKy5H64OFDW7zh43D3zleRzTgZveo2DIrnqSjbSiT+rJwzxcLL+iZiPyOd8DSc97xYdtz48cVelgHrEJB/+c9HZBflMWs9E8pF5Hfe2QK/L9/QITq1BxPYiJLgWsEpOB+9uKe4e0iWRTzmn0XVMBjqXclFYWmMfO3C6XbK7I115GNMepEGwB5/a15CPJFp2tYZ6j9hxzudp3ZBPf5kND7f2cq7yaF5KkvOUbvUnyi4WQT44b7XbbiC3C8OLEnjuoWx5jO2orW3x32R3UEQl2itOpfQMGydCxuPxU8uFLK/Xybu6QBqIUntffs7pGkJh+XVD10Wgt1Sjrfh8NQqiG+tg2hH29YP1iMSk023Pi/dwq5HdrlF+ji7iCq9cn2YfgLHLc85b/j0904Hre0j29YB1cvH+QYJPbK/+FflIPeiN7ZCjN+4nWjvDMSQDyEStC8ePkQoZhxHyYsYwe/k9bWRVK9/THPqD8TMELOSf1/vdoZlPPnKZuTwTzY9TxKGHMMpR1O142DVE1nKYfztYyyNzj1MKMJ8pu1gK+fxP6JDzl7maz1XoLrfC+e9lMBJ26dM2ZJhsp9jl3oBX8SLPZ9Iyh8OuShOUSM6zcIst9+pua53U/XenWLX/W+H8xZAHr/2mMEuEYewqB/QudFMMv5l85stgeJi9SjizjfK25LHRFvdUw6G2nDHyUbtdsW/J+q4gvs29TScftduVcu9NeNtuxH8WFa4y4cy9b50Il3VBYph/OnDuushvsomD2zq5OsudZkjkM2B5RQ7JenIAsrCwpv+pwrczOSTlF5PPL2XwlMd4x/O578i8q71C5L3MXh7zEYHrXNv/ayz9dojRGPbpaJnpbxO7KgnKD1b8q0T4QA/VV5HPL2TwLN217dP3+x3kIzZjRHJ9smrpwk4j/k/zfFbkAY0Weo2+pUHz4T4a1fIxo5x/0ZMMn5DB29Wkecv0AnHE9azBdp0eLPj4JCKftVGmHl0xeYLd8ZJ8ikfeSJ98CrrfS0U30TJc8BEmRD6rixg1mUyZYNcesAvti9Mo3LQc8d7E5IAQdv/kCi9D1dD5PMtDjZ0/c6gckQ/h9yh1e8y9sQuqXureETlOeC7oE8cp3/1bOjpnaX6P0gG23G12Ip9VomtdWW5ZPWFB3i+RD+GlTrdONoZ0ZOm/RJf3W/o0SCKfVVo+PdphWuen6v6ee7TulPk5hM8E3slAYziRD+FN7KPm32wmFs7NLBGYPj+H8H7oWVlfMICfyGe1zo8rh6ndPX5GDG3zHdhsyoiGG/t6v5GT8CHuURMY3KW7PUQ+K4ace30/9CqTDcI8R9iNcGgOvU7voVfVm2xA5LPckCv4it1HIp/VQvRHiYZINclvONpq5Lxgg4WYn7oh8lmeyNU4Eisu8Q1bDUQ+a4ZunXDuuODCUoqpefXs3iYin+WJ2/uqEgsin9WnAGwYmxjD/ZkiOclDru0WsZOimhJ2tUQ+y/R6uDwsA3Zafc2SiXz+g1LaY/OkRRk+k9Mq0xnd48PzcwifhNxgsD87UYHIhzDAPwlsqnhecbwlDlA8H2ZJ5ENYlmXc+mALHixFeFqy2PozhowR+RA+4P/I6YBefqRbsSqj4slz7r+xzpzI558RUNM0oI6vFUn0i+VJ5EMgEIh8CAQCkQ+BQCAQ+RAIBCIfAoFAIPIhEAjfix/Ig1r79zwz0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"https://wikidocs.net/images/page/84111/soynlp.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_vszl7YG4uY"
   },
   "source": [
    "아직은 아리송 할 거에요. \"반포한강공원에\"라는 7의 길이를 가진 문자 시퀀스에 대해서 각 내부 문자열의 스코어를 구하는 과정은 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "LPJa_edNGyOX",
    "outputId": "1cc75649-4535-4512-d1be-d2a851eda334"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\"https://wikidocs.net/images/page/84111/soynlp2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXG0qmBBG76m"
   },
   "source": [
    "실습을 통해 직접 응집 확률을 계산해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u25oZKTCG1rP",
    "outputId": "7d5c27e7-87be-40fe-e8e1-d40ea8ceb745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08838002913645132"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한\"].cohesion_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-sekKNFNG-d3",
    "outputId": "007e93e2-92fb-4699-fac4-104709d38804"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19841268168224552"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한강\"].cohesion_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tRT7n6N3G_TI",
    "outputId": "1706fd48-1353-45d9-fd3c-af45fb646566"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2972877884078849"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한강공\"].cohesion_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hKE32nDKHHo7",
    "outputId": "2c810fc5-f145-44c8-a2eb-3cb4c7b69a62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37891487632839754"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한강공원\"].cohesion_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gVpqoRvfHI5K",
    "outputId": "1dda7e90-bc2c-4607-b16e-29c64f949659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33492963377557666"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"반포한강공원에\"].cohesion_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVfhi2tTHPVl"
   },
   "source": [
    "## soynlp의 브랜칭 엔트로피(branching entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QzzaSHi3HQC3"
   },
   "source": [
    "Branching Entropy는 확률 분포의 엔트로피값을 사용합니다.  이는 주어진 문자열에서 얼마나 다음 문자가 등장할 수 있는지를 판단하는 척도입니다. 이해를 위해 퀴즈를 내보겠습니다. 제가 어떤 단어를 생각 중인데, 한 문자씩 말해드릴테니까 매번 다음 문자를 맞추는 것이 퀴즈입니다.\n",
    "\n",
    "첫번째 문자는 \"디\"입니다. 다음에 등장할 문자를 맞춰보세요. 솔직히 가늠이 잘 안 가지요? \"디\"로 시작하는 단어가 얼마나 많은데요. 이걸 어떻게 맞추냐구요. 정답은 \"스\" 입니다.\n",
    "\n",
    "이제 \"디스\"까지 나왔네요. \"디스 \"다음 문자는 뭘까요? 벌써 정답 단어를 예측한 분도 있을테고, 여전히 가늠이 잘 안가시는 분도 있을 거에요. \"디스카운트\"라는 단어가 있으니까 \"카\"일까? 아니면 \"디스코드\"라는 단어가 있으니까 \"코\"인가? 생각해보니 \"디스코\"가 정답일 수도 있겠네요. 그러면 \"코\"인가? \"디스아너드\"라는 게임이 있으니까 \"아\"? 전부 땡땡땡! 이 단어들을 생각하신 분들은 전부 틀렸습니다. 정답은 \"플\"이었습니다.\n",
    "\n",
    "\"디스플\"까지 왔습니다. 다음 문자 맞춰보세요. 이제 좀 명백해지는군요. 이 정도 되면 헷갈리시는 분들은 거의 없을거에요. 정답은 \"레\"입니다. \"디스플레\" 다음에는 어떤 문자일까요? 너무 명백해서 문제라고 보기도 어려워졌어요. 정답은 \"이\"입니다. 제가 생각한 단어는 \"디스플레이\"였습니다!\n",
    "\n",
    "저는 지금 브랜칭 엔트로피를 시뮬레이션한 겁니다. 브랜칭 엔트로피를 주어진 문자 시퀀스에서 다음 문자 예측을 위해 헷갈리는 정도로 비유해봅시다. 브랜칭 엔트로피의 값은 하나의 완성된 단어에 가까워질수록 문맥으로 인해 점점 정확히 예측할 수 있게 되면서 점점 줄어듭니다. 실습해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WIitCxwbHRn3",
    "outputId": "0a6fe423-0cd8-4b8c-95fb-e2accae83aba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6371694761537934"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"디스\"].right_branching_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JnKStLHyHXam",
    "outputId": "1ca8ab95-88ad-4e33-d5be-5f1ee8017969"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"디스플\"].right_branching_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fzudrAAHccz"
   },
   "source": [
    "\"디스\" 다음에는 다양한 문자가 올 수 있으니까 1.63이라는 값을 가지는 반면, \"디스플\"이라는 문자열 다음에는 다음 문자로 \"레\"가 오는 것이 너무나 명백하기 때문에 0이란 값을 가집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yRKwW0q4HenU",
    "outputId": "3715fc7e-318d-4c32-cf06-6066fc2bfa72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"디스플레\"].right_branching_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GCLchyiFHgHA",
    "outputId": "01716d19-6bda-4cd0-aeb0-37db333a6f51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1400392861792916"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"디스플레이\"].right_branching_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ktRy49nHlcR"
   },
   "source": [
    "갑자기 값이 급증합니다. 그 이유는 문자 시퀀스 \"디스플레이\"라는 문자 시퀀스 다음에는 조사나 다른 단어와 같은 다양한 경우가 있을 수 있기 때문입니다. 이는 하나의 단어가 끝나면 그 경계 부분부터 다시 브랜칭 엔트로피 값이 증가하게 됨을 의미합니다. 그리고 이 값으로 단어를 판단하는 것이 가능하겠죠?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DigXtkNpHnuZ"
   },
   "source": [
    "## soynlp의 L tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-KO3A2HHsam"
   },
   "source": [
    "한국어는 띄어쓰기 단위로 나눈 어절 토큰은 주로 L 토큰 + R 토큰의 형식을 가질 때가 많습니다. 예를 들어서 \"공원에\"는 \"공원 + 에\"로 나눌 수 있겠지요. 또는 \"공부하는\"은 \"공부 + 하는\"으로 나눌 수도 있을 것입니다. L 토크나이저는 L 토큰 + R 토큰으로 나누되, 분리 기준을 점수가 가장 높은 L 토큰을 찾아내는 원리를 가지고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uXrktIsSHrHo",
    "outputId": "732b18b6-17fc-4e9c-fb20-22924c32e607"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('국제사회', '와'), ('우리', '의'), ('노력', '들로'), ('범죄', '를'), ('척결', '하자')]"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
    "l_tokenizer = Ltf.keras.preprocessing.text.Tokenizer(scores=scores)\n",
    "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nh-YlIvnHySl"
   },
   "source": [
    "## 최대 점수 토크나이저"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ml5hwIWTH0fh"
   },
   "source": [
    "최대 점수 토크나이저는 띄어쓰기가 되지 않는 문장에서 점수가 높은 글자 시퀀스를 순차적으로 찾아내는 토크나이저입니다. 띄어쓰기가 되어 있지 않은 문장을 넣어서 점수를 통해 토큰화 된 결과를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y6k2y_q3HuAY",
    "outputId": "2efac967-03a1-48aa-8f93-128215e4e0cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['국제사회', '와', '우리', '의', '노력', '들로', '범죄', '를', '척결', '하자']"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "maxscore_tokenizer = MaxScoretf.keras.preprocessing.text.Tokenizer(scores=scores)\n",
    "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "learning spoons 2강.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
